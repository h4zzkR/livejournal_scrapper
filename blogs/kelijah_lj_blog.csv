,title,text,tags
0,      NLP pipeline в чатботе - текущее состояние и задачи  ," NLP pipeline включает несколько отдельных питоновских пакетов. Эти пакеты реализуют часть типовой функциональности для NLP - токенизация, лемматизация, частеречная разметка и т.д. Эта группа может использоваться (и используется) независимо от  чатбота . Кроме того, несколько алгоритмов ""растворено"" в кодовой базе чатбота. Например, машобучаемый NER, модели синонимичности и релевантности и т.д. Далее - текущее состояние для пакетов из первой группы. rusyllab  - разбивка слова на слоги. Реализован простой жадный алгоритм разбивки на слоги. Предполагалось, что разбивка на слоги даст дополнительные фичи для некоторых ML моделей, в частности за счет выделения корня вместо стема. В настоящее время очень удачно применен в задаче генерации датасета для обучения спеллчекера, так как типовая ошибка расщепления слова тяготеет к границам слогов :""не большой"" вместо ""небольшой"" и т.д. rutokenizer  - сегментация текста на предложения, токенизация предложений на слова с учетом некоторых составных слов из  русской словарной базы . Под капотом - регулярки и табличные проверки исключений. Используется в различных прототипах и экспериментах, в том числе в  проекте нового парсера . ruword2tags  - грамматический словарь, содержащий теги для русского лексикона. Сделан как замена  прежнего грамматического словаря , конвертируется из его 5-миллионной словарной базы. Используется автономно в экспериментах как поставщик грамматических фич, например в ML моделях для спеллчекера. Также этот словарь используется в  rupostagger  и rusyntax. В этом же пакете есть ""flexer"" - инструмент для склонения и спряжения слов, он активно юзается в генеративной грамматике чатбота. Из проблем: к сожалению, в какой-то момент выяснилось, что на некоторых машинах git clone или pip install git+ из этого репозитория приводит к некорректно скачанному файлу базы данных. Что с этим делать, я пока не придумал. rupostagger  - part-of-tagger на ванильном машобуче. Обучается на достаточно большом датасете, около 800,000 токенов с частичной ручной валидацией. Используется во многих проектах, в том числе в чатботе. Лемматизатор  rulemma  работает поверх разметки, которую выдает этот модуль, для учета контекста в случае неоднозначной лемматизации. Основная проблема с этим модулем - достаточно медленно обучение, длящееся сутками. Для этой задачи у меня есть еще две альтернативные реализации, которые не выложены на гитхаб. rupostagger2  - нейросетевой вариант теггера, на основе рекуррентных сеток. Обучается на таком же датасете, что и rupostagger, плюс использует эмбеддинги слов. Обучается примерно за 2 часа на одной GTX 1080 Ti, дает немного лучшее качество, чем rupostagger. rupostagger3  - нейросететка плюс эмбеддинг предложения через BERT. Экспериментальная модель. Обучается тяжело, пока качество хуже, чем у rupostagger2. rulemma  - лемматизация с учетом грамматического контекста для случаев неоднозначности. Например, слово ""рой"" может быть императивной формой глагола или именем существительным. Это дает разные нормальные формы: ""рыть"" и ""рой"". Учет результатов частеречной разметки из rupostagger позволяет разрешать часть подобных неоднозначностей. ruchunker  - экстрактор именных группы (NP chunks). Облегчает в чатботе выделение фрагментов реплик пользователя. Реализован на  ванильном машобуче. Обучается на датасете из ~400,000 предложениях с размеченным NP. Не выложеные на гитхаб пакеты: rusyntax2  - парсер зависимостей. Нейросетевая рекуррентная модель, реализующая sequence labeling. Обучается на большом treebank'е с ручной разметкой. Позволяет, например, определить, какие зависимые прилагательные надо пересогласовывать при изменении формы существительного. rusyntax3  - аналогично rusyntax2, но реализован восходящий  shift-reduce парсер с бинарными правилами, в котором вместо ручных правил работает классификатор (shift or reduce). Обучается на treebank, который сначала приводится к цепочке действий для каждого предложения на базе известного синтаксического графа.",github||nlp
1,      NP чанкер и прототип шаблонизатора ответов для чатбота  ," В наборе NLP модулей для  чатбота  добавился очередной - NP chunker. Его прототип я уже кратко описывал  тут . Для удобства использования в разных проектах чанкер именных групп выделен в отдельный модуль  ruchunker . В чатботе он позволяет делать следующее. Допустим, пользователь вводит вопрос: H: Как ты относишься к  квантовым процессорам ? Если движок бота не может найти в базе фактов и в FAQ материал для ответа, то ему остается выдать некий  шаблонный ответ типа ""Нет соответствующей информации"" . Чтобы немного разнообразить реакцию бота, можно выделить в вопросе собеседника именную группу и использовать при генерации ответа: B: Мне ничего не известно про  квантовые процессоры Технически это выглядит как последовательность шагов: 1. NP чанкер выделяет именные группы. 2. Реплика собеседника сопоставляется с маской, при этом именные группы учитываются как единые элементы при вычислении расстояния Левенштейна. Одновременно при сопоставлении маски происходит присваивание сматченных именных групп неким переменным. 3. Генерируется ответ на основе шаблона, в котором указываются имена сопоставленных чанков из п.3. При этом может потребоваться просклонять и пересогласовать элементы чанка в нужную грамматическую форму. Соответствующее правило  выглядит вот так: 
             if:
                match:
                    - 'как я отношусь к NP1'
                    - 'что мне известно о NP1'
                    - 'расскажи мне о NP1'

            then:
                say:
                    - 'Мне ничего не известно про $NP1(ВИН)'
                    - 'Я ничего знаю о $NP1(ПРЕДЛ)'
                    - 'Я не знаю, что такое ""$NP1(ИМ)""'
                    - 'У меня нет информации о $NP1(ПРЕДЛ)'
 Этот механизм нужно будет отшлифовать рядом расширений. Например, добавить возможность ссылаться в шаблоне ответа на результаты NER. Тогда для входных реплик ""Какая погода будет  в пятницу "" и ""Какая погода будет  завтра "" можно в ответе подставлять упомянутый момент времени без привязки к его синтаксическому оформлению в виде предложной или наречной группы.",chatbot||chunker||named entry recognition||ner||существительное
2,      Датасет для тренировки NP chunker'а  ," В  репозиторий ""NLP Datasets""  выложен  датасет для тренировки NP чанкера . NP chunker - это вариант  shallow parser'а , извлекающего из предлождений группы существительного (noun phrases). Вот результаты разметки нескольких предложений для иллюстрации идеи: « ⟦  Школа   злословия   »  ⟧ учит прикусить ⟦  язык  ⟧ Сохранится ли ⟦  градус   дискуссии   в   новом   сезоне  ⟧ ? ⟦  Великолепная   «   Школа   злословия   »  ⟧ вернулась в ⟦  эфир  ⟧ после ⟦  летних   каникул  ⟧ в ⟦  новом   формате  ⟧ Потом ⟦  проект  ⟧ переехал с ⟦  «   Культуры   »  ⟧ на ⟦  НТВ  ⟧ Скобочки ⟦ и ⟧ добавлены при разметке для визуальной отбивки границ смежных чанков. Тренировочный датасет получен автоматической конвертацией tree bank'а из  проекта Грамматического Словаря . Выглядит датасет примерно так: 
 0 Но
1 справедливый
2 судья
0 обязан
0 выслушать
1 разные
2 стороны
2 и
2 все
2 точки
2 зрения
0 .
 
 Записи для разных предложений разделяются пустой строкой. Первое поле каждой записи содержит числовую пометку 0, 1 или 2: 0 - слово не входит в именную группу 1 - слово начинает новый NP chunk 2 - слово продолжает ранее начатый NP chunk Таким образом, смежные чанки разделяются меткой 2. По задумке модель NP чанкера будет использоваться в  чатботе  в новых диалоговых правилах как эффективный механизм извлечения информации из реплик собеседника, например: - Что такое [NP  виртуальная реальность ], скажи мне.",chatbot||chunker||chunking||dataset||nlp||существительное
3,      Небольшое исследование качества корпуса PARUS на гитхабе  ," По поводу вот этого корпуса  https://parus-proj.github.io/PaRuS/ Архив с корпусом в формате Conll после распаковки имеет размер около 130 Гб. То есть данных много. Закономерный вопрос - насколько качественны эти данные, учитывая, что ручной модерации они не подвергались в силу объема. Я сделал небольшой лексический анализ. Искал словоформы, которые отсутствуют в лексиконе  Грамматического Словаря . Видно, что данные в какой-то степени грязные. Например, есть ""существительные"" (лемма + слово): 2016-й 2016-го а да-а августой августой аврелие аврелий автоконцерный автоконцерны акий аким андре андреу ""Прилагательные"" (лемма + слово): инфосистема инфосистемы коврино коврино котеночей котеночьи мальдивый мальдив навыкать навыкате намерный намерен подо поже ""Наречия"": гимпа гимпу главное главное говорят говорят казнить казнено 30 су-30 33 су-33 34 су-34 35 су-35 38 ми-38 38 ил-38 39 ам-39 Есть и проблемы с токенизацией, например встречаются такие ""слова"": ­ожидается,­ нельзя…— неукомплекто- двух- делать- фильма— разоткровенничалась,- если,- есть,— говорила,— вдруг- если,— кстати.-",github||корпус||лексика
4,      Релиз чатбота: заготовки для будущих skill'ов  ," В  новом релизе чатбота  сделана группа важных взаимодополняющих изменений. 1) Расширен и частично переработан набор intent'ов. По результатам предварительного анализа типичных вопросов в датасете ""Mail.ru Ответы"", добавлены несколько новых интентов для частых запросов в чатботах, например 'определение объекта на фотографии', 'поиск книги по описанию', 'odqa - вопросы к Википедии' и т.д. 2) Для этих интентов сделаны заготовки сценариев, в которых в будущем можно будет реализовать соответствующие skill'ы с детальной обработкой вариантов запросов. Например, в ответ на реплику ""помоги решить задачу по математике"" чатбот сейчас выдаст: ""Мастер помощи с домашними заданиями еще не реализован!"". По этой реплике можно найти исходник соответствующего сценария в файле  rules.yaml . 3) Запуск новых сценариев для skill'ов происходит в случае, если не получилось найти ответ в базе фактов или FAQ. Например, для вопроса ""Что такое хрусталик?"" бот выдаст ответ из  FAQ , а для вопроса ""Что такое бензокаин?"" будет запущен odqa-сценарий. Тестовый диалог с чатботом выглядит так: B:> Добрый день H:> привет, помоги решить задачку по физике B:> Мастер помощи с домашними заданиями еще не реализован! H:> посоветуй, где купить мощный ноутбук B:> Сценарий рекомендаций по покупке еще не реализован! H:> что делать, если я потерял паспорт B:> Сценарий решения юридических вопросов еще не реализован! H:> Что такое бензокаин? B:> Сценарий поиска определений в Википедии еще не реализован! H:> что такое хрусталик B:> Хрусталик представляет собой прозрачное двояковыпуклое округлое эластичное образование H:> что такое Луна B:> Луна это естественный спутник Земли. H:> Что такое Церера B:> Церера - ближайшая к Солнцу и наименьшая среди известных карликовых планет Солнечной системы. H:> Что такое пояс Койпера B:> Сценарий поиска определений в Википедии еще не реализован! H:> какая температура считается опасной для ребенка? B:> Мастер помощи с по вопросам здоровья и медицины еще не реализован! H:> Как сбить температуру у ребенка? B:> Высокую температуру у ребенка можно сбить с помощью детского Нурофена",chatbot
5,"      Чат-бот 0.0.2.5: константы профиля, шаблонизатор фактов и правил, генератор скриптов для чит-чата  "," Две новые фичи в  этом релизе чатбота : 1)  Константы профиля , например имя бота в именительном падеже ""name_nomn"", задаются в одном  файле профиля  и могут автоматически подставляться в строки фактов, FAQ, правил. Шаблонизатор также позволяет учитывать константу рода ""gender"" для приведения реплик бота к согласованному с профилем виду. Пример использования константы можно увидеть в самом начале  файла с фактами : меня зовут $name_nomn Когда бот загружает содержимое этого файла, он подставляет фактические значения констант вместо $имя_константы. Таким образом, имя бота задается в одном месте. Аналогичный механизм действует для  функций шаблонизации . Константа с именем ""gender"" определяет грамматический род для бота, в данном случае женский. В том же  файле фактов  можно найти такую запись: Я $chooseAdjByGender(нужен, нужна), чтобы отвечать на вопросы посетителей чата Конструкция $chooseAdjByGender(нужен, нужна) позволяет выбрать одно из перечисленных прилагательных, фильтруя их по константе грамматического рода. Таким образом, реплики бота становятся более релевантными ""биологической"" природе бота. 2) Опробована автоматическая генерация правил скриптования бота из текстов диалогов. Это облегчает создание различных сценариев для читчата. Вместо утомительного написания сотен правил, можно набросать примеры диалогов, прогнать их через генератор скриптов, получить  множество правил примерно такого вида . С помощью такого подхода получаются вот такие сессии чит-чата: B:> Привет, давай общаться? H:> Привет, давай B:> Что предлагаешь обсудить? H:> давай музыку B:> Какие музыкальные жанры тебе по душе? H:> например джаз B:> Уважаю, хороший вкус! H:> А тебе что нравится? B:> я люблю компьютеры B:> Ты что из напитков предпочитаешь?",chatbot||chitchat||чатбот||читчат
6,      Чит-чат: игра-угадайка на новых правилах в чатботе  ," Чтобы проверить  расширенные возможности  rule-driven ядра  чатбота , я попробовал написать простую текстовую игру-угадайку. Получились вот такие диалоги: B:> День добрый H:> привет, ты кто? B:> я чатбот B:> Чем ты занимаешься? H:> а ты угадай B:> Давай попробую угадать, кто ты B:> ты учишься или работаешь? H:> ну, я учусь B:> Ты студент? H:> ага B:> Ура, я угадала :) B:> отлично поиграли! B:> Привет, буду рад поговорить H:> а ты кто? B:> я чатбот B:> Чем ты занимаешься? H:> давай ты угадаешь B:> Давай попробую угадать, кто ты B:> ты учишься или работаешь? H:> работаю я B:> Ты госслужащий? H:> нет B:> ты программист? H:> да, верно B:> Ура, я угадала :) B:> отлично поиграли! B:> Привет H:> а ты кто? B:> я чатбот B:> А ты кто? H:> давай ты угадаешь B:> Давай попробую угадать, кто ты B:> ты учишься или работаешь? H:> работаю я B:> Ты госслужащий? H:> нет B:> ты программист? H:> нет B:> Не угадала :( Исходный текст соответствующего сценария можно увидеть  тут, начиная со строки 10175 . Плюсы - как в любом rule-driven подходе с ""handcrafted"" правилами, можно достаточно точно задать сценарий. Минус - неудобно, даже для сценария с пятью состояниями получается длинная портянка с повторами. Полученный опыт трансформируем в следующие задачи для чатбота: 1) Надо попробовать генерацию скриптов на основе диалогов-примеров (что-то типа stories в RASA). 2) Нужен способ более экономного описания правил сценария.",chitchat||чатбот||читчат
7,      Изменения в движке чатбота  ," В движок  чатбота , в его rule-driven подсистему, добавлены две экспериментальные возможности. Собранный докер с этой версией бота  выложен тут . Обе возможности относятся к приоритетным правилам генерации реплики бота. Эти правила срабатывают  до  того, как в дело вступает стандартный механизм подбора ответа в FAQ или релевантного факта в базе знаний. В файле правил  rules.yaml  они находятся в секции с незамысловатым именем ""rules"". В  строке 537  можно увидеть правило, которое анализирует не только непосредственно последнюю реплику собеседника, но предшествующую реплику чатбота. Благодаря учету реплики чатбота можно выдать более-менее уместный ответ на чисто эмоциональное высказывание ""ничего себе"", которое в противном случае могло бы относится к чему угодно. Таким образом, становятся возможными диалоги такого типа: H:> ты человек? B:> я не человек H:> ничего себе B:> Это правда. Вторая возможность демонстрируется правилом в  строке 486 . Оператор state позволяет сохранить в пользовательской сессии произвольную текстовую строку как именованную переменную, а затем проверить проверить содержимое такой переменной. В результате можно в сессии накапливает некоторый ""опыт"", например определять, что пользователь уже не первый раз использует ругательства: B:> Привет H:> ты не человек? B:> я не человек H:> ну ты и дура B:> Ой, мне такие слова не нравятся H:> а ты все равно дура! B:> Жаль, что вы постоянно используете подобные выражения!",chatbot||chitchat||чатбот||читчат
8,      Читая логи чатбота  ," Пробежался глазами по логам чатбота одной очень, очень крупной компании. И вот что бросается в эти самые глаза. Процентов 15 сообщений сводится к "" мне нужен специалист а не робот "". Ну понятно, что чатбот несовершенен, иногда тупит и отвечает вариантами ""я есть Грут"". Но это временные, устранимые недостатки. Лет через пять, по мере улучшения чатботов и параллельного сокращения затрат на живые колл-центры, неизбежно появится и платная услуга ""Поговорить с живым оператором"". Второе следствие взросления технологии - взломы корпоративного чатбота через вербальный канал, а-ля "" Белая трость калибра 7.62",забавные моменты||чат-боты
9,      shallow парсинг и grammar inference для нормализации грязных данных в MDM системе?  ," В результате интерференции родилась такая мысль, надо ее застолбить :) Задача Вот, допустим, есть у нас некая  MDM система , которая помимо прочего в рамках  ETL процедуры  должна уметь забирать описания товара из какой-нибудь 1C. Данные, как это водится, грязные. Вводят их вручную менеджеры, операторы склада или бухгалтеры. А даже если вводят специально выделенные люди (aka ""эксперты НСИ""), то могут быть свои забавные способы впихнуть в короткую текстовую строку самую разную информацию. Хотя, казалось бы, для некоторых материальных сущностей эти описания регламентируются ГОСТами и т.д. В общем, надо эти описания привести к нормальному виду. Один из способов - выделить из грязных данных атрибуты сущности и затем заново собрать описание, уже по регламенту. Вот пример такого разбора для текстовой строки "" Круг h8 0,75 Г14955-77 / 20пс-А-75-ТО Г10702-16 "": 
 
 ОКВЭД2 
 24.10.2 
 
 
 
 Наименование изделия 
 Круг 
 
 
 
 Сопроводительный документ->Сокращённое наименование 
 ГОСТ 10702-2016 
 
 
 
 Длина ПП 
 
 
 
 
 Диаметр 
 0,75 мм 
 
 
 
 Испытание на горячую осадку 
 
 
 
 
 Прокаливаемость 
 
 
 
 
 Группа осадки 
 
 
 
 
 Материал->Марка материала 
 20пс 
 
 
 
 Удаление заусенцев 
 
 
 
 
 Серповидность 
 
 
 
 
 Обезуглероживание 
 
 
 
 
 Класс кривизны 
 
 
 
 
 Вид кромок 
 
 
 
 
 Качество химического состава 
 А 
 
 
 
 Контроль ударной вязкости 
 
 
 
 
 Стандарт на сортамент->Сокращённое наименование 
 ГОСТ 14955-77 
 
 
 
 Балл прокаливаемости 
 
 
 
 
 Состояние поставки 
 ТО 
 
 
 
 Точность проката 
 
 
 
 
 Категория (фасонный прокат) 
 
 
 
 
 Точность по длине 
 
 
 
 
 Группа по макроструктуре 
 
 
 
 
 Назначение 
 а 
 
 
 
 Квалитет 
 h8 
 
 
 
 Класс прочности 
 
 
 
 
 Травление 
 
 
 
 
 Группа отделки поверхности 
 А 
 
 
 
 Способ изготовления 
 
 
 
 
 Ультразвуковой контроль 
 
 
 
 
 Плоскостность 
 
 
 
 
 Твердость 
 
 
 
 
 Контроль макроструктуры 
 
 
 
 
 Гарантия свариваемости 
 
 
 
 Трудности Сейчас разбор сделан на старом добром машобуче - набор классификаторов, градиентный бустинг, нейросеточки, CRF и т.д. И как обычно, там где машобуч, там проблемы генерализуемости и интерпретируемости моделей. Попросту говоря, когда на вход модели приходят какие-то необычные данные, которых она не видела при обучении, имеем неиллюзорные шансы получить на выходе лютый мусор. Обычная схема борьбы с таким явлением - добавление новых данных в обучающий датасет, возможно с аугментацией. Но размеченные данные это всегда очень дорогая штука. В энтерпрайзе, да еще в MDM системе это проявляется крайне выпукло. Попросту говоря, мало кто захочет просто отдать разработчику свои данные. Данные, которые, кстати, могут быть частью коммерческой тайны и т.д. Интерпретируемость - вторая практическая беда. Я даже не говорю о нейросетках, которые обычно проще считать черным ящиком со злой нелинейной магией. В них небольшое изменение входной строки может перекинуть модель на какой-то дико далекий manifold. Поэтому очень трудно дать рекомендацию по аугментации или расширению датасета в случаях, когда модель явно лажает. Инструменты типа  SHAP  и  LIME  забавны, но лично мне не ""зашли"", больше времени всякий раз уходило на обход багов и анализ результатов анализа. Единственный надежный и практичный способ - обучать линейную модель и затем просто анализировать веса фич. Даже деревья решений в любом виде трудны для анализа, особенно если это ансамблевые модели. Матрица же весов линейной модели вкупе с конкретным входным примером позволяет дать четкий ответ - тут у нас такой-то ГОСТ, потому что модель из статистики обучающих данных учитывает ""в плюс"" такие признаки, а ""в минус"" такие, так что досыпайте примеров с такими-то атрибутами. Идея Все описанные выше проблемы типичны для NLP, в частности для синтаксического анализа. Обучив модель на каком-нибудь tree bank'е, нельзя рассчитывать на хорошее ее поведение. Небольшой мусор на входе, опечатки или необычный слить автора могут привести к нереальному бреду на выходе парсера. А вот почему бы не использовать тут старые добрые методы NLP? Как и тексты на естественном языке, текстовые строки описания номенклатуры в MDM обычно структурированы в какой-то степени. В частности, ГОСТом может задаваться порядок вписывания размеров, марки материала и т.д.. Даже ограничения могут быть похожими, например, запрет на  непроективность ,  однократность  заполнения слота и т.д. И вот это позволяет переформулировать задачу разбора строк в MDM как старую добрую задачу shallow парсинга, когда нам надо выделить, например,  составляющие . Более того, так как у нас есть размеченный датасет, так что, наверное, можно реализовать и какую-то форму  grammar inference , чтобы результатом работы была не модель-черный ящик со всем вышеперечисленными проблемами, а  набор правил разбора  для какого-нибудь простого LR-парсера. Вполне может оказаться, что интерпретация результатов в этом случае будет намного более простой.",grammar inference||mdm||shallow parser
10,      Нулевая связка в новом парсере  ," Продолжая  тему нового парсера  на замену  старому . Добавил в качестве эксперимента в этот парсер поддержку нулевой  связки , точнее любого  подразумеваемого  токена. Зачем? Может показаться странным, но отсутствие формально необходимого элемента в тексте доставляет больше проблем, чем, например, морфологическая неоднозначность. Возьмем два эквивалентных предложения "" Сегодня дождь. "" и "" Дождь сегодня. "". Если синтаксический анализатор не поддерживает нулевые связки (как, например, ванильный  CYK ), то надо решать, что будет вершиной в каждом из случаев. Допустим, мы решили, что вершиной становится существительное, как более значимый элемент: ""Дождь(сегодня)"". Сравним теперь результаты разбора со случаем, когда связка присутствует в явном виде "" Сегодня был дождь "". Зависимости в этом случае такие ""был(Сегодня, дождь)"". Видно, что по ребрам эти два случая совершенно не сопоставляются, и значит невозможно определять семантическую близость текста без дополнительных преобразований. А вот так выглядят сейчас результаты разборов для случая "" сегодня с самого утра сильный дождь "". Дерево зависимостей, с фиктивным токеном NULL: По синтаксическому графу видно, что "" сильный дождь "" является подлежащим, не смотря на отсутствие глагола. Составляющие: Можно сравнить с результатами для явно выраженной связки "" сегодня с самого утра  был  сильный дождь "":",bottom-up parsing||восходящий разбор||парсер||синтаксис||синтаксический анализатор||синтаксический разбор
11,"      Гугл: квантовое преимущество, искусственный интеллект, первые признаки сингулярности в google pay  "," Кто там мемично шутил про ""бигдата, аджайл, где карту получали, в то отделение и ступайте""? Ввожу обязательные параметры в Google Pay, подключаю виртуальную визу. На форме ввода нужно ввести почтовый индекс. Ввожу - ""неправильно заполнено поле индекса"". Переввожу, пробую другие соседние индексы, пробую сменить город и индекс на Вологду - толку 0. Гуглю проблему (тонкий британский юмор ситуации). Оказывается,  этому багу в гугл пэе много лет , но чинить его не торопятся. Да, нейросети, квантовое преимущество, искуственный интеллект - все в комплекте.  ",забавные моменты
12,      Неудачная попытка использования XGBRanker и LGBMRanker для задачи определения перефразировки  ,"  Под катом - особенности определения синонимичности фраз в языке, использование BERT, метрики для оценки моделей и проблема с задачей ранжирования. Постановка Одна из ключевых задач в  чатботе  заключается в том, чтобы для реплики пользователя найти наиболее подходящую эталонную фразу среди некоторого набора, например в  вопросах FAQ . Простые необучаемые метрики типа  расстояния Левенштейна-Дамерау  или  коэффициента Жаккара  не работают с синонимами, и не способны учитывать близость смысла слов. С метриками поверх векторных представлений слов с этим получше. Но все они в той или иной степени страдают от особенностей синтаксического оформления фраз в естественном языке. Например, короткое словечко ""не"" во многих случаях (хотя см.  пост 1  и  2 ) полностью меняет семантику фразы, но лишь незначительно изменяет посимвольную похожесть. Это делает результаты символьных метрик зачастую непригодными. Аналогичную эффект оказывают местоимения или наречия некоторых видов. Ведь понятно, что фразы ""Я сплю"" и ""Ты спишь"" относятся к разным субъектам и во многих ситуациях не должны считаться близкими, иначе чатбот будет страдать одной из форм  расстройства личности , будет путать себя и других. Кроме описанной выше нелинейности, существуют более тонкие эффекты ""нестационарности"", когда похожесть фраз определяется более широким контекстом диалога. В качестве иллюстрации вот такой фрагмент: (1)  - Ты решил задачу? (2)  - Я решаю задачу! В ответе (2) подразумевается отрицание ""Нет, но я решаю задачу"", индикатором которого служит показатель глагольного времени. Чтобы увидеть эти эффекты вживую, можно взять  простой код other_relevance_calculators.py . Он позволяет в консоли вводить фразы и выводит десяток ближайших к введенной, используя одну из метрик. К примеру, для фразы ""Я хожу в школу"" получаются такие результаты. Коэффициент Жаккара с шинглами длиной 3: 
 :> я хожу в школу

0.590909 в школу я не хожу
0.517241 я каждый день хожу в школу
0.500000 я спешу в школу
0.478261 я побегу в школу
0.476190 я шел в школу
0.434783 я пошел в школу
0.434783 я пошла в школу
0.360000 я ненавижу школу
0.357143 я отправился в школу
0.333333 миша ходит в школу
 Word mover distance: 
 :> я хожу в школу

0.811322 я шел в школу
0.791942 я пошел в школу
0.788527 я пошла в школу
0.780179 я отправился в школу
0.774977 в школу я не хожу
0.765454 я спешу в школу
0.763919 я побегу в школу
0.691840 я шел в библиотеку
0.671755 я вернусь в больницу
0.669050 я направляюсь в оранжерею
 Отсюда возникает идея построить supervised модель, которая будет учитывать эти особенности языка. Для обучения модели нужен размеченный вручную датасет, содержащий как минимум пары синонимичных предложений. У меня сейчас такой датасет содержит примерно 100 тысяч таких пар. Также могут быть полезны примеры несинонимичных фраз, например ""я сплю"" и ""ты спишь"". Часть этого датасета  лежит тут . Классификация В самом простом и прямом виде задача формулируется как бинарная классификация. Модель должна выдавать 1 для перефразировок и 0 для прочих пар. В качестве baseline модели можно взять линейный классификатор  LogisticRegression ,  соответствующий код лежит тут . Там реализован gridsearch для подбора параметров векторизации текстов и параметров самого классификатора - см. параметр запуска --run_mode gridsearch. В качестве признаков текста используется мешок шинглов или  sentencepiece -токенов, см. классы ShingleVectorizer и SentencePieceVectorizer. При обучении финальной модели (см.  параметр запуска --run_mode train) код также выводит в текстовый файл веса самых значимых позитивных и негативных фич. К сожалению, эти веса достаточно трудно интерпретировать: 
 бе п(a&b)  = 6.093737538020524
с си(a&b)  = 5.390922356511366
ю см(a-b)  = 5.080459984724804
вь м(b-a)  = 5.01616775741977
мое (a&b)  = 5.0100646323114315
трав(a&b)  = 5.009792399786643
мое(a-b)   = 4.954400872157704
вь м(a-b)  = 4.893422992556576
, ту(a&b)  = 4.844557511941288


...


жи -(a-b)  = -5.117691807078531
ые и(a&b)  = -5.256227649952226
шь з(a&b)  = -5.298547739146427
 я ?(a-b)  = -5.409425560268217
у см(a-b)  = -5.608569897069139
ьна\n(a&b) = -5.77466930492533
жи -(b-a)  = -6.1251675048097525
 ми(b-a)   = -6.5043540802299065
 ми(a-b)   = -6.721502181709472
 я ?(a&b)  = -7.257981008937467
 Суффикс (a&b) означает ситуацию, когда указанная подстрока встречается в обоих сравниваемых фразах. Суффиксы (a-b) и (b-a) означают, что подстрока встречается в одной и не встречается во второй фразе. Этот линейный классификатор работает на удивление хорошо, хотя, конечно, уступает более сложной модели, использующих эмбеддинги BERT с fine tuning. Код модели бинарного классификатора на базе BERT с fine tuning  лежит тут . Обертка для  BERT в tensorflow.hub  ради удобства с  Keras  выделена в  отдельный модуль . В параметрах класса BertLayer есть n_fine_tune_layers для задания количества дообучаемых словев. Я пробовал задавать от 1 до 3 слоев в fine tuning. Замечу, что модель на BERT требует  очень  много вычислительных ресурсов. Фактически обучение на ~300 тысячах позитивных и негативных пар идет примерно 2 часа при почти 100% утилизации GPU GTX 1080. Все вентиляторы на сервере раскручиваются на максимум, появляется шум, в общем, чувствуется, что 110 миллионов параметров в BERT это не шуточки. Ранжировка Возможна и альтернативная постановка задачи. Путь у нас есть пара синонимичных фраз "" Я хочу спать "" и "" Мне бы вздремнуть "". Добавляем к ним некоторое количество нерелевантных пар, например ""Я хочу спать"" & ""Я хочу снять"" и т.д. Пусть теперь модель учится выдавать для этого списка пар такие оценки, чтобы релевантная пара имела наивысшую оценку, а остальные - меньшие. Таким образом, нам нужна отранжировать список. Для такого рода задач есть специальные модели, в частности  XGBRanker  и  LGBMRanker . У них очень похожий API метода fit, требующий передать матрицу признаков X, оценки ранга для каждой пары y и вектор групп. Тут лежит код тренера . Оценка качества: precision@1, mean reciprocal rank Есть множество способов решения данной задачи, с разными ""естественными"" метриками. Например, бинарная классификация будет выдавать что-нибудь типа f1 метрики, и эта оценка будет ""локальна"" для пар. В некоторых случаях такая оценка синонимичности пары ничего не скажет с точки зрения использования в чатботе. Например, нам интересно, чтобы наиболее релевантный вопрос в FAQ был сопоставлен с максимальной оценкой, а остальные - ниже. Иначе говоря, если для релевантной пары будет выдана оценка 0.98, а конкурирующая нерелевантная пара даст ранг 0.99, то бот выберет неправильную запись. В условиях упомянутой нелинейности задачи всегда есть шанс, что какая-то нерелевантная пара вдруг выдаст локальный пик, испортив подбор записи в FAQ. Сравнение различных методик определения синонимичности тоже надо как-то привести к общему знаменателю. На мой взгляд, для этого подходят следующие оценки, используемые для поисковых систем. Во-первых, можно оценить, сколько групп (позитивная пара + негативные пары) после ранжирования дали в первой позиции именно позитивную пару. Эту метрику будем называть  precision@1  (см. для справки  метрики для поисковиков ). Чем ближе precision@1 к 0, тем чаще релевантные пары расцениваются моделью как синонимичные. Вторая оценка -  mean reciprocal rank , то есть среднее значение обраной позиции релевантной пары после ранжирования. Чем она ближе к 1, тем лучше модель выталкивает релевантную пару вверх (где rank=1) при ранжировании. Проблема с ранжировщиками Проблема с задачей в такой постановке, как ни странно, в том, что оба ранжировщика выдают слишком хорошие, неправдоподобно хорошие результаты. Например, линейный классификатор на LogisticRegression дает precision@1 около 0.944. Модель на базе классификатора LightGBM дает precision@1 около 0.986. Модель на базе XGBRanker выбивает precision@1 аж в 0.999.  Нет никаких сомнений, что такие высокие показатели ранжировщика - следствие какой-то утечки трейна в валидацию. Я пока не могу точно идентифицировать путь утечки, но есть следующее соображение. Для обучения ранжировщика нам нужно сформировать группы из одной позитивной и нескольких негативных сэмплов. Для некоторых позитивных сэмлов нет негативных пар, выбранных вручную, так что их приходится генерировать рандомным выбором второго предложения. Я подозреваю, что из-за недостаточно большого объема пула, из которого сэмплируются негативные фразы, получается, что некоторые негативные фразы в парах встречаются по нескольку раз в разных группах. И ранжировщик, возможно, учится просто идентифицировать эти негативные фразы, так как они встречаются всегда как чась негативных пар.",bert||перефразировки||чатбот
13,      Пример претензии к pymorphy2 в качестве поставщика морфологии для парсера  ," Одна из основных проблем при использовании pymorphy2 в качестве морфологического анализатора для  парсера  видна на следующем примере. Вот результаты анализа слов в тестовом предложении "" в огромном сарае лежало старое сено "": 
 #0 в                    PREP
#1 огромном             ADJF,Qual,neut,sing,loct~0.666666 | ADJF,Qual,masc,sing,loct~0.333333
#2 сарае                NOUN,inan,masc,sing,loct
#3  лежало                ADJS,neut,sing~0.5 | VERB,impf,intr,neut,sing,past,indc~0.5
#4 старое               NOUN,inan,neut,sing,nomn~0.25 | NOUN,inan,neut,sing,accs~0.25 | ADJF,Qual,neut,sing,nomn~0.25 | ADJF,Qual,neut,sing,accs~0.25
#5 сено                 NOUN,inan,neut,Sgtm,sing,nomn~0.5 | NOUN,inan,neut,Sgtm,sing,accs~0.5
 Смотрим на слово #3 ""лежало"". С формальной точки зрения краткая форма (ADJS) для прилагательного ""лежалый"" действительно будет ""лежало"". Но я даже без статанализа по корпусу уверен, что эта форма не употребляется вообще никогда. Поэтому достоверности 0.5 для варианта прилагательного и глагола выглядят  очень  странными. Более того, во многих других случаях веса альтернатив у pymorphy2 такие же необоснованные. Поэтому в парсере пришлось вообще отказаться от учета этих весов, полагаясь только на свою статистику. Но сделав такой шаг, сталкиваемся с другой напастью - предлоги. Вот список вариантов для ""в"", выдаваемый pymorphy2.parse(): 
 PREP
NOUN,inan,masc,Fixd,Abbr sing,nomn
NOUN,inan,masc,Fixd,Abbr sing,gent
NOUN,inan,masc,Fixd,Abbr sing,datv
NOUN,inan,masc,Fixd,Abbr sing,accs
NOUN,inan,masc,Fixd,Abbr sing,ablt
NOUN,inan,masc,Fixd,Abbr sing,loct
NOUN,inan,masc,Fixd,Abbr plur,nomn
NOUN,inan,masc,Fixd,Abbr plur,gent
NOUN,inan,masc,Fixd,Abbr plur,datv
NOUN,inan,masc,Fixd,Abbr plur,accs
NOUN,inan,masc,Fixd,Abbr plur,ablt
NOUN,inan,masc,Fixd,Abbr plur,loct
 Все падежные формы и оба грамматических числа существительного сильно замусоривают  пространство перебора  парсера. Для других одно- и двухбуквенных предлогов, союзов и частиц картина такая же неудобная. В первом листинге результатов для "" в огромном сарае лежало старое сено "" единственный вариант для ""в"" является как раз следствием подставленного ""костыля"", подавляющего 12 мусорных вариантов.",морфология||русский язык
14,      Bottomup парсер на чистом питоне  ," Раз в два-три года я пробую делать какой-то новый парсер для русского языка. Последний раз это была неудачная  попытка прикрутить reinforcement learning для shift-reduce парсера , обучаемого на корпусе эталонных разборов. В этот раз за полтора месяца сделан прототип  восходящего вероятностного парсера  на чистом питоне. Морфология - внешняя сменяемая, сейчас это pymorphy2. К ней у меня масса претензий, так что видимо буду менять на свою оптимизированную  ruword2tags . Чтобы было веселее, токенизация тоже вероятностная, поэтому парсер может попутно убирать лишние разрывы слов или слившиеся слова, работая еще и как spellchecker. Впрочем, для эффективной обработки длинных предложений в чатботе надо будет перед парсером делать частеречную разметку и снимать все морфологические неоднозначности. Правила разбора задаются в текстовом файле, например так: 
 # ЗЛАЯ СОБАКА ЛАЕТ
# ^^^^^^^^^^^
NP('прил + сущ') ~1.2 ->
   a=AP[case] # так как сущ. может быть в локативе или партитиве, то наружу вытолкнем падеж прилагательного
 + n=NP[number, gender, 3per, gen_slot]
 agr: adj_n(a, n)
; 
 По задумке веса правил будут автоматически подбираться по эталонному tree bank'у с помощью какой-то реализации  expectation-maximization алгоритма . Результаты выглядят так (спасибо  питоновской обертке для Graphviz  за чудеса автоматической отрисовки графов). Иерархия составляющих: Дерево зависимостей:",bottomup parser||dependency parser||glr||восходящий разбор||парсер||синтаксис||синтаксический анализатор||синтаксический разбор
15,      Расширение поддержки русского языка в Duckling  ,"  Duckling  - библиотека от Facebook, позволяющая извлекать из текста структурированные данные. Например, с ее помощью из строки ""смартфон стоит двенадцать тысяч рублей"" можно выделить числительное ""двенадцать тысяч"". Попутно для извлеченной информации делается некоторая нормализация, то есть получим представление в числовом виде ""12000"". Помимо других альтернативных инструментов, Duckling можно использовать в фреймворке чатботов RASA для  NER . Чтобы ""пощупать"" этот экстрактор, нужно скачать репозиторий, скомпилировать, запустить rest-сервис. После чего через браузер или curl можно прокачивать тексты и видеть json-результаты. Попробуем: git clone  https://github.com/facebook/duckling cd duckling stack init stack build stack exec duckling-example-exe Команда  stack  это тулинг для хаскеля, на котором собственно и написан утенок. Сборка первый раз будет идти долго, так как будут скачиваться пакеты зависимостей, перечисленные в  duckling.cabal . Последняя команда запускает rest-сервис на  https://github.com/facebook/duckling . Чтобы увидеть результаты разбора, можно в новой консоли выполнить: curl -v -XPOST  http://0.0.0.0:8000/parse  -H ""Content-Type: application/x-www-form-urlencoded; charset=utf-8"" --data 'locale=ru_GB&text=три' Почему locale=ru_GB, а не ru_RU? На фоне остальных нюансов это лишь мелкая загадка, стоит это воспринимать просто как данность. Результат работы будет такой: [{""body"":""три"", ""start"":0, ""value"":{""value"":3,""type"":""value""}, ""end"":3, ""dim"":""number"", ""latent"":false}] Видим, что в обработанной строке найдена подстрока, распознанная как ""число"" - об этом говорит поле ""dim"":""number"". Помимо посимвольной привязки этой подстроки вернулось также нормализованное значение ""value"": 3 Все бы неплохо, но с поддержкой русского в Duckling совсем не айс. Попробуем сменить именительный падеж числительного на другой: curl -v -XPOST  http://0.0.0.0:8000/parse  -H ""Content-Type: application/x-www-form-urlencoded; charset=utf-8"" --data 'locale=ru_GB&text=тремя' Упс - результат разбора пустой. Утенок не знает падежные формы русских числительных :( Извлечение происходит с помощью набора правил, написанных на хаскеле. Не самый плохой язык для парсинга, хотя и явно не мейнстрим. Рекомендую перед написанием своих правил немного освоиться с синтаксисом. Достаточным будет, например,  вот этот курс . Читать можно прямо в браузере, если не нужен именно pdf, достаточно открывать страницы в  этой папке . Исходники на хаскеле местами будут напоминать птичий язык из-за постоянного использования пунктуационных символов в качестве основных синтаксических маркеров, но до какого-нибудь  APL  хаскелю, к счастью, далеко, так что нескольких часов будет достаточно для освоения. Чтобы начать улучшать поддержку русских числительных, идем в  исходник с правилами . Как видим, правила для каждого типа извлекаемой информации вынесена в отдельный каталог, да еще и разнесена на подкаталоги для разных языков, когда это требуется. Если пробежаться глазами по упоминанию числительных в этом исходнике, быстро станет понятна как причина плохой поддержки русского языка, так и пути ее улучшения. Достаточно добавлять падежные формы, не забывая правильно расширять регулярки. У меня основной источник раздражения и тяжелой фрустрации при отладке были именно регулярки. Если не вдаваться в подробности, то рекомендую придерживаться правила - задавая формы в regex-паттерне, сначала указывайте самые длинные, чтобы они матчились в первую очередь, типа такого: ruleInteger3 = Rule { name = ""integer 2"" , pattern = [ regex ""(двумя|двум|двух|два|две|двоих|двоими|д воим|двое|пара|паре|парой|пару|парочку|п арочка|парочкой)"" ] , prod = \_ -> integer 2 } Ну и помните, что регулярки коварны, опечатки в паттернах никак не ловятся компилятором хаскеля. И если, например, написать вместо | двойную ||, то полчаса игры в гляделки по коду гарантированы. Кстати, чтобы упростить расширение, рекомендую с самого начала не лениться и использовать тесты, благо вся инфраструктура уже есть. Во-первых, идем в  исходник Corpus.hs , где собраны тесты для проверки разбора русскоязычных числительных. По аналогии с имеющимися тестами вписываем там свои, например: , examples (NumeralValue (400)) [""четыреста"", ""четырехсот"", ""четырёхсот"", ""четыремстам"", ""четырёмстам"", ""четырехстах"", ""четырёхстах""] Далее, после любых изменений в правилах запускаем тесты командой в консоли: stack test В общем, при некотором упорстве и аккуратности, разбор числительных можно выправить. У меня форк утенка для запроса curl -v -XPOST  http://0.0.0.0:8000/parse  -H ""Content-Type: application/x-www-form-urlencoded; charset=utf-8"" --data 'locale=ru_GB&text=триста миллионов семнадцать тысяч четыреста' дает: [{""body"":""триста миллионов семнадцать тысяч четыреста"",""start"":0,""value"":{""value"":30 0017400,""type"":""value""},""end"":43,""dim"":""n umber"",""latent"":false}] Приложив некоторые дополнительные усилия, можно ввести также поддержку новых типов информации, но об этом я расскажу как нибудь в следующий раз.",duckling||haskell||ner||rasa
16,      а вот простейшая seq2seq модель для генерации реплик в читчат боте что выдает  ," После обучения на объединенном датасете диалогов из Толоки + мои датасеты для чатбота, модель, не учитывающая контекст, а только текст заданного вопроса, выдает такую ""болтовню"": :>кто ты научный трудоголик :>как тебя зовут меня зовут андрей а тебя ? :>чем занимаешься я работаю с больнице :>какую музыку любишь я люблю русскую музыку :>где ты живешь в поселке :>а работаешь где в в в городе :>какое пиво предпочитаешь преферанс :>как отдыхаешь хорошо Не знаю, откуда взялась реплика про ""научного трудоголика"", но выглядит все не так уж плохо. Может быть, после тюнинга, качество дойдет до уровня, чтобы работать в качестве fallback-генератора реплик в чатботе для случаев, когда в базе фактов не нашлась информация для нормального ответа.",sequence2sequence||диалоги||чатбот||читчат
17,"      Классификация интентов в чатботе - сравнение моделей ELMO, BERT и char-level linear sklearn  "," Сравнение выполнялось по f1 weighted метрике на  датасете  с ~5100 сэмплов через 8-фолдовую кросс-валидацию. Чуть больше 70 интентов с большим дисбалансом. Финальные результаты: LinearSVC ~0.77 BERT        ~0.815 ELMo        ~0.817 Базовая модель использует символьные шинглы длиной от 2 до 6 символов и  LinearSVC  для классификации. Выбор классификатора и параметры векторизации делались через grid search.  Исходный код доступен тут . Классификатор на базе BERT использует  многоязычную модель из проекта Deep Pavlov . Векторы от BERT поступают в однослойную нейросетку. Параметры и архитектура сетки подбиралась через grid search. Исходник тренера  доступен тут . Я не выкладываю его в реп, так как получающаяся модель еще никак не используется в самом чатботе. Классификатор на базе ELMO аналогичен BERT, только используется  ELMOEmbedder  из проекта Deep Pavlov.  Исходник тренера доступен тут . При этом модель на LinearSVC намного менее требовательна к ресурсам при обучении и инференсе, поэтому я пока не хочу подцеплять в чатботе более качественную ELMo.",bert||chatbot||elmo||embeddings||vector space model||чатбот
18,      Изменения в порядке генерации ответов в чатботе  ," В коде  релиза 0.0.2.2  кроме всяких правок ошибок и более точных NLP моделек сделана одна существенная модификация в генераторе ответов. Раньше  чатбот  на вопросы, относящиеся к нему ""лично"", генерировал ответ общим алгоритмом, то есть искал релевантный факт в базе знаний, брал отуда необходимый фрагмент и строил ответ. Выглядело это примерно так: H:> как тебя зовут? B:> Вика Теперь чатбот выдает полный текст найденного факта в качестве ответа: H:> как тебя зовут? B:> Меня зовут Вика Это позволяет избежать некоторых ошибок генерации ответа (куда же без них в машобучаемых генеративных модельках :( ). С другой стороны, так как пополнение базы фактов записями, описывающими факты по самому чатботу в одном из предыдущих релизов стало ваозможно только через ручное редактирование базы фактов, то эти факты чистые, не содержат избыточной информации, поэтому ответы чатбота выглядят вполне уместно. Люди, конечно, в таких ситуациях стараются все-таки экономить усилия собеседника и дают более краткие ответы, но будем считать это просто компромисом по качеству.",chatbot||chitchat||диалоги||чатбот
19,"      Релиз чатбота 0.0.1 (альфа) - вербальные формы, сценарии и прочее  "," В проекте русскоязычного чатбота сделан релиз с большими изменениями в коде бота. В основном работа велась над возможность задавать поведение бота через вручную задаваемые правила - сценарии и вербальные формы. 1) Базовая (proof-of-concept) поддержка  вербальных форм . Пример описания вербальной формы смотрите в разделе ""forms"" в файле  rules.yaml . Вербальная форма активируется по имени каким-нибудь правилом, содержащим актор ""form"" - см. подстроку keyword: 'заказать|заказ' в rules.yaml. В форме описывается набор ""полей"" - слотов, которые бот будет запрашивать у собеседника. В ходе обработки реплики для слота бот выполняется извлечение информации штатным NER. Выглядит это так: 
 B:> Привет
H:> закажи что-нибудь поесть
B:> Что заказать?
H:> пиццу с анчоусами
B:> Сколько порций?
H:> три
B:> Заказываю: что=""пиццу с анчоусами"", сколько=""три""
 Если какая-то информация для заполнения слотов содержится в инициирующей реплике, то она будет использована вербальной формой без лишних вопросов: 
 B:> Здравствуй
H:> закажи пиццу с колбасой
B:> Сколько порций?
H:> одну
B:> Заказываю: что=""пиццу с колбасой"", сколько=""одну""
 2) Базовая (proof-of-concept) поддержка  сценариев  - наборов правил для взаимодействия с пользователем в рамках какой-то ""темы"". См. раздел ""scenarios"" в файле rules.yaml, где сейчас описан тестовый сценарий ""знакомство"", активирующийся на реплике, похожей на ""давай познакомимся"". Выглядит это так: 
 B:> меня зовут Вика
B:> Где ты живешь?
H:> в москве
B:> Тебе нравится в Москве?
H:> да
B:> Чем ты занимаешься?
H:> работаю программистом
B:> Программисты это круто
B:> Какое у тебя хобби?
H:> рыбалка
B:> Рыба - это хорошо
B:> О чем ты хотел бы меня спросить?
 3) Добавлена возможность задавать правила, срабатывающие на ключевые слова (и их грамматические формы) - см. правила с подстрокой keyword в файле rules.yaml. Тестовое правило срабатывает при вводе реплики, похожей на ""давай познакомимся"" и запускает сценарий ""знакомство"". 4) Добавлена возможность задавать правила, срабатывающие по регулярному выражению - см. правила с подстрокой regex. Тестовое правило срабатывает при вводе реплики ""летим на LV-426"": 
 H:> летим на LV-426
B:> Увлекаешься ужастиками?
 5) Новый алгоритм интерпретации ответов собеседника. Теперь нейросетевая модель LSTM+CRF предсказывает цепочку команд для генеративной грамматики, которая восстанавливает полный текст ответа собеседника из текстов вопроса и краткого ответа. В обучающем датасете сейчас примерно 8000 троек вопрос+краткий ответ+развернутый ответ. 6) Отказ от лемматизации через pymystem, переход полностью на свой лемматизатор из  пакета rulemma . 7) Расширенные обучающие датасеты: модель перефразировок учится на отобранных вручную ~156 тысячах пар предложений, модель релевантности вопроса и предпосылки на ~45 тысячах пар и так далее. И последние изменения связаны с большой возней, которую пришлось затеять после попытки воткнуть вторую gtx-980 в систему с 18-й убунтой и gtx-1080ti на борту. В силу непонятных обстоятельств, убунта категорически отказалась работать в такой конфигурации, что выражалось в любимом ""login loop"" при старте. Это когда после ввода пароля в стартовой экране гуя он мигает и выводится снова. При этом консольная часть работала без проблем - можно было запустить обучение на двух гпушках и т.д. Все попытки отредактировать конфиг xorg и так далее ничего не давали. После этого я достал старый ssd и накатил туда новую 19-й убунту. После установки новой CUDA нормально завелись. Послежний штрих - самая свежая версия tensorflow. Через некоторое время я заметил, что в питоновских прогах логирование стало каким-то странным. Формат сообщений был другим, в консоли сообщения дублировались. Выяснилось, что это появляется только при импорте TF. Обнаружился и  соответствующий issue . Пришлось вставлять в код костыль с удалением обработчика от ABSL, чтобы прекратить кашу на экране. Ну и попутно - я добавил расцветку сообщений лога с помощью проекта  coloredlogs , подсмотрев это в RASA. И последнее, связанное с разгоном системы. Небольшой эксперимент с включением в биосе MSI опций разгона цпу и памяти дал совершенно неожиданный эффект. С одной стороны, код на цпу стал явно быстрее. Но при обучении на гпу я начал замечать странности. Во-первых, катастрофически упала сходимость моделей, они просто перестали достигать на валидации обычной точности. Через некоторое время обозначилась и причина - изредка, раз в сутки, появлялись фатальные ошибки с floating point. То есть повышенная частота системы приводила к сбоям в блоках плавающей точки цпу. На этом эксперименты с разгоном я прекратил.",chatbot||chitchat||диалоги||чатбот
20,      Вербальные формы в чатботе: в ближайшем релизе  ," Написанный для  чатбота  код для поддержки вербальных форм будет поддерживать такие ценарии общения с пользователем (реплики человека отмечены H:, реплики бота B:): B:> День добрый H:> хочу заказать что-нибудь поесть B:> Что заказать? H:> пиццу с анчоусами B:> Сколько порций? H:> две",диалоги||чатбот
21,      Релиз чатбота 0.0.0.16 - встраивание движка в RASA  ," В рамках этого  релиза   чатбота  я серьезно переработал исходный код и ""обиблиотечил"" движок. Теперь бот можно встраивать в питоновский код, как это показано на  примере интеграции с RASA . Для встраивания бота необходимо зарегистрировать пакет командой, находясь в корне скачанного проекта: pip install . После этого в питоновском коде появится возможность вызвать ruchatbot.create_qa_bot (см.  строку 43 ). Пути к папкам с профилем и моделями надо, разумеется, указать свои. Файлы моделей нужно взять из  докер-контейнера . Далее, нужно привязать вызов  обработчика события  к какому-нибудь  интенту  в  историях  RASA. Я сделал это так. В nlu.md добавил интент ""вопросы_к_боту"": 
 ## intent:вопросы_к_боту
какой ты?
как тебя зовут?
как твое имя?
звать-то тебя как?
скажи, как ты относишься к бананам
... (еще много сэмплов) ...
 И в stories.md: 
 ## вызов внешнего чатбота
* вопросы_к_боту
- action_qa
 Не забываем объявить интент и обработчик в домене (файл domain.yml): 
 intents:
...
  - вопросы_к_боту
...

actions:
...
  - action_qa
...
 Также нужно правильно указать адрес сервиса событий в endpoints.yml, к примеру у меня так: 
 action_endpoint:
    url: ""http://localhost:5055/webhook""
 После настройки и ""rasa train"" запускаем сервис обработки событий: 
 python -m rasa_sdk.endpoint --actions actions -p 5055
 Если все правильно сделано, то в логе увидим сообщения о загрузке чатбота: Далее, запускаем консоль RASA командой ""rasa shell"", задаем вопрос боту, видим ответ:",chatbot||chitchat||rasa||чатбот||читчат
22,      Мысли по поводу интеграции движка чатбота с RASA  ," В рамках рабочей задачи я сделал  кастомный компонент  для RASA, который выполняет классификацию интентов для фразы с помощью нейросетевой модели, работающей поверх русского BERT. В целом, все достаточно просто, если знать про некоторые технические нюансы. Например, не стоит делать ленивую загрузку модели в методе process, лучше это делать в конструкторе. И надо аккуратно относится к исключениям в process, иначе pipeline RASA склонен где-то зависать (там все на корутинах, как я понимаю). По смутным ощущениям, этот классификатор работает лучше, чем штатная модель SklearnIntentClassifier с добавкой символьных шинглов (CountVectorsFeaturizer), или чем EmbeddingIntentClassifier. Хотя намного тяжелее по памяти, конечно. Итак, теперь у нас есть следующие возможности интеграции с RASA, проверенные своими руками и примерами кода: 1) Кастомные обработчики событий ( Custom Actions ). Каждый такой обработчик оформляется в виде класса и может делать всякие полезные вещи, основываясь на свойствах сообщения. В самом простом варианте обработчик может вернуть текст ответной реплики. Обработчики работают в самом конце пайплайна, то есть получают уже обработанное сообщение с определенным интентом, выделенными entities и т.д. 2) Кастомные компоненты для пайплайна ( Custom Components ). Работают ""внутри"" пайплайна и могут выставлять какие-то признаки для обрабатываемого сообщения, например значения entities, модифицировать текст сообщения и т.д.",chatbot||rasa||чатбот
23,"      Оценки для задачи ""бинарная классификация - является ли реплика продолжением диалога""  "," Сделал оценки нескольких методов для определения, является ли реплика допустимым продолжением диалога. Датасет - Толока. Взято 100,000 реплик. (Был еще контест в 2018 от Я с похожей задачей, тамошний датасет, по-моему, грязноват в сравнении с Толокой.) В качестве истории бралась одна предшествующая фраза другого собеседника. Негативные сэмплы добавлялись в количестве 1 на 1 позитивный. Оценки получены кроссвалидацией на 3х фолдах. Baseline -  LinearSVC  на символьных шинглах roc auc=0.55 LightGBM на символьных шинглах ruc auc=0.645 Нейросетка поверх  pretrained ruBERT из deeppavlov  roc auc= 0.709",bert||диалоги||чатбот
24,      Немного болтовни с чатботом 0.0.0.13  ," В  новом релизе чатбота  в движке сделаны некоторые правки, чтобы получались (иногда) вот такие диалоги: 
 B:> Привет!
B:> День добрый
H:> привет
B:> Привет, о чем поговорим?
H:> меня зовут Илья
B:> Моего создателя тоже зовут Илья
H:> это круто
B:> :)
H:> а тебя как зовут
B:> вика
H:> приятно познакомиться
B:> Взаимно
H:> ты кто
B:> чатбот
H:> круто
B:> :)
H:> кто такой чатбот
B:> Чатбот это компьютерная программа, способная отвечать на вопросы пользователя, задаваемые на естественном языке.
B:> я чатбот
H:> а я программист
B:> Я уважаю программистов
H:> я разрабатываю чатботы
B:> Чатботы это круто
H:> что ты любишь
B:> вопросы
B:> животных я люблю
H:> а я люблю компьютеры
B:> Чем ты занимаешься с компьютерами ?
 Это уже намного ближе к обычной болтовне незнакомых людей, как, например, в этом датасете  Toloka Persona Chat Rus . То есть меньше механичности, больше импровизации и проактивности. Хотя косяков пока многовато - иногда (кхм, частенько) бот выдает малорелевантные реплики, иногда модели генерации текста поставляют мусор. Чтобы справится с этими косяками, нужна модель для оценки того, насколько реплика вписывается в общий дискурс диалога. Я попробовал сделать черновую модельку на базе  ELMO из deeppavlov  ( ElmoEmbedder ) плюс  линейный регрессор  для предсказания вектора следующей реплики, чтобы через cosine между предсказанным и фактическим вектором оценивать уместность реплики. Результат в целом нулевой, так как по метрике precision@k предсказанный вектор с трудом попадает в top-40% фраз, из которых одна - действительно релевантная. Следующая попытка - нейросетевой регрессор поверх BERT. Я проверил на  ruBERT из deeppavlov  плюс  keras-bert",bert||chatbot||deeppavlov||чатбот
25,      Профили в чатботе  ," В  новом релизе   чатбота  я добавил ""профили"" - текстовые файлы (json), в которых указываются пути к файлам с  фактами  и  правилами . С их помощью, думаю, будет проще создавать разные ""характеры"". В этих же профилях в будущем будут доступны тонкие настройки характера бота (ну не прямо как  тут , конечно, хотя...). Сейчас сделан  базовый отладочный профиль , который позволяет чатботу отвечать на десяток простых вопросов о самом себе, примерно так: 
 B:> День добрый
H:> кто ты
B:> чатбот
H:> что такое чатбот
B:> Чатбот это компьютерная программа, способная отвечать на вопросы пользователя, задаваемые на естественном языке.
H:> зачем нужны чатботы
B:> Чатбот используется для ответов посетителям сайтов, мессенджеров и социальных сетей.
H:> спасибо за пояснения
B:> пожалуйста
H:> как тебя зовут
B:> вика
H:> ты человек
B:> нет
H:> а меня зовут Илья
B:> Илья, хочешь что-нибудь рассказать мне?
H:> да
H:> как меня зовут?
B:> илья
 В этом профиле сменено имя чатбота - теперь это ""Вика"", раз уж виртуальные собеседники традиционно женского пола. Из более мелких изменений отмечу изменение формата датасета с интентами. Чтобы было проще экспериментировать параллельно с  RASA , я сделал почти такой же формат. Далее, теперь чатбот считает все реплики, относящиеся к нему лично, вопросами. Попросту говоря, если ввести "" ты человек "", то не смотря на отсутствие формальных признаков вопросительной модальности, движок бота не будет рассматривать это как утверждение, подлежащее занесению в базу знаний. Бот обработает реплику как вопрос, что в случае дефолтного профиля приведет к ответу ""нет"". А вот если сказать ему "" меня зовут Илья "", то это будет считаться фактом, который сохраняется в базе знаний. Это видно из тестового диалога - чатбот потом может ответить, как зовут его собеседника.",диалоги||чатбот
26,"      NER датасет из каггла ""text-normalization-challenge-russian-language""  ","  Вот эти данные  для entity типа DATA содержат огромное количество строк типа Проверено 1 января 2016 . International Renaissance Foundation. Проверено 16 января 2016 . Смотрим телевизор . | 16 января 2016 Проверено 21 февраля 2016 . Текмаш отметил 160 летие . | 21 февраля 2016 Уверен на 100%, что данные получены простой конвертацией викиданных из русской Википедии. Возможно, для некоторых моделей NER перекос в статистике паттернов будет снижать немного их качество. Ну и мусора там, конечно, прилично: People ( 27 августа 2001 ) . Deadline.com ( 17 ноября 2014 ) . ESCToday ( 19 марта 2012 ) . и т.д.",dataset||kaggle||ner
27,"      RASA, spacy, русский язык и NER  "," После трех дней осады и борьбы, у меня заработала связка из текущей версии  RASA  и spacy (я взял  готовые модели для русского языка , спасибо Юрию за помощь :) ). Кроме того, я сделал конвертор для своего  NER датасета  в формат для обучения Spacy NER. После пары часов получилось дообучить спейсовский NER, взяв за основу  код отсюда : 
 Sentence: ""Сегодня неплохая погода.""
Shape    Vocab    POS    Text      Lemma     Entity          Dep     Head
-------  -------  -----  --------  --------  --------------  ------  ------
Xxxxx    +        ADV    Сегодня   сегодня   когда: Сегодня  advmod  погода
xxxx     +        ADJ    неплохая  неплохой                  amod    погода
xxxx     +        NOUN   погода    погода                    ROOT    погода
.        +        PUNCT  .         .                         punct   погода
 Затем получилось в своем custom action обработчике, настроенном на intent ""прогноз_погоды"", получить извлеченный entity: 
 class ActionHelloWorld(Action):

    def name(self) -> Text:
        return ""action_weather""

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:

        try:
            sinopsis_date = next(tracker.get_latest_entity_values(u'когда'), None)
            dispatcher.utter_message(u""Прогноз погоды на дату: {}"".format(sinopsis_date))
        except:
            dispatcher.utter_message(u""Прогноз погоды - слот даты не найден"")

        return []
 В итоге получилось черновое решение с обработкой реплики ""Какая погода будет завтра?"": 
 Your input ->  какая погода будет завтра?                                                                                                    
Прогноз погоды на дату: завтра
 
",chatbot||named entry recognition||ner||spacy||чат-боты||чатбот
28,"      Еще датасеты со словосочетаниями, короткими и неполными предложениями  "," В добавок к  этому , залил в  репозиторий  старые (2015 год) залежи. В то время они были собраны для проверки синтаксияеского парсера. Например,  S+V+INSTR.zip  содержит сэмплы типа ""Я вертел ими"", в которых творительный падеж актанта однозначен, то есть эти сэмплы однозначно определяют соответствующий слот у глаголов. Еще любопытный пример - конструкции с  местоимениями ""я"" и ""ты"" в роли подлежащего и личным глаголом свидетельствуют о том, что глагол употребляется с одушевленным субъектом. Сейчас хочу использовать эти данные для обучения языковых моделей чатбота, но, возможно, они кому-то еще пригодятся. Disclaimer: все датасеты собраны автоматически, без ручной выверки, поэтому содержат некоторое количество шума. Архив  PRN+PreposAdj+V.zip  содержит сэмплы вида: 
 Я на автобус опоздаю
Я из автобуса пришел
Мы из автобуса вышли
Я из автобуса вышла
Я из автобуса видел
Я на автобусах езжу
Они на автобусах приезжают
Мы на автобусах объездили
 Архив  adv+verb.zip  содержит пары наречие+глагол в личной форме: 
 ПРЯМО АРЕСТОВАЛИ
ЛИЧНО атаковал
Немо атаковал
Ровно атаковала
Сегодня АТАКУЕТ
Ближе аттестует
Юрко ахнул
 Архив  adj+noun.zip  содержит сэмплы типа: 
 ПОЧЕТНЫМ АБОНЕНТОМ
Вашим абонентом
Калининским абонентом
Калининградских аборигенов
Тунисских аборигенов
Байкальских аборигенов
Марсианских аборигенов
Голландские аборигены
 Архив  prep+noun.zip  содержит такие паттерны: 
 У аборигенных народов
У аборигенных кобыл
Из аборигенных пород
С помощью аборигенов
На аборигенов
Для аборигенов
От аборигенов
У аборигенов
 Архив  S+V.zip  содержит образцы такого вида: 
 Мы абсолютно не отказали.
Мужчина абсолютно не пострадал.
Они абсолютно совпадают.
Михаил абсолютно не рисковал.
Я абсолютно не выспалась.
Они абсолютно не сочетаются.
Я абсолютно не обижусь...
 В архиве  S+V+INF.zip  находятся такие образцы: 
 Заславский бахвалился превратить
Ленка бегает поспать
Она бегает умываться
Альбина бегает мерить
Вы бегаете жаловаться
Димка бегал фотографироваться
 Архив  S+V+INDOBJ.zip  содержит автоматически собранные паттерны подлежащее+глагол+предлог+существительно е: 
 Встревоженный аббат пошел навстречу мэру.
Бывший аббат превратился в настоятеля.
Старый Абдуррахман прохаживался возле дома.
Лопоухий абориген по-прежнему был в прострации.
Высокий абориген вернулся с граблями;
Сморщенный абориген сидел за столиком.
 В архиве  S+V+ACCUS.zip   находятся сэмплы такого вида: 
 Мой агент кинул меня.
Ричард аккуратно поднял Диану.
Леха аккуратно снял Аленку...
Они активируют новые мины!
Адмирал активно поддержал нас.
 Архив  S+V+INSTR.zip   содержит сэмплы: 
 Я вертел ими
Они вертели ими
Вы вертели мной
Он вертит нами
Она вертит тобой
Она вертит мной
Он вертит ими
Она вертит ими
 Архив  S+INSTR+V.zip  содержит такие сэмплы: 
 Я тобой брезгую
Они ими бреются
Они ими вдохновляются
Мы ими вертим
Она тобой вертит
Он мной вертит
Он ими вертит
 
",датасеты
29,      Датасет с сэмплами подлежащее+глагол+предлог+существительное  ," Обнаружил у себя датасет ( файл в репе 3 Мб ) с большим списком сэмплов такого вида: 
 Они сражались за Родину
Я до сих пор нахожусь под впечатлением
Куваев набрал на клавиатуре
Они всю ночь колотили в дверь
Ганс приступил к экранизации
Мы не спешим с представлением
Я расскажу с позиции
Я столкнулся с моделью
Я спросил у ясеня
Макс столкнулся с проблемами
Мы связались с Владимиром
Я купил через Интернет
Я приехал в Тайвань
Грэм представил на суд
",dataset||русский язык||синтаксис||сказуемое
30,      Собранные русские словарные базы и исполнимые файлы для Грамматического Словаря  ," В репозиторий  https://github.com/Koziev/GrammarEngine  выгружены полные актуальные сборки русской словарной базы для 64-битных Windows и Linux. Историческая ремарка - необходимость в разных версиях словаря под вин и лин объясняется такой замечательной особенностью C++, как отсутствие гараний размера основных типов данных. В частности, wchar_t для вин для большинства компиляторов имеет размер 2 байта, для лин - 4 байта. Для начала использования под Windows вообще не нужно компилировать ничего - репозиторий содержит все необходимое. Если запустить  exe64\lexicon.exe , то можно в консоли проверить поиск слов в лексиконе. Запустив  scripts\syntax\console_syntax.cmd , можно посмотреть, как разбираются простые предложения в rule-based синтаксическом парсере. Пересборка словарной базы выполняется скриптом  scripts\dictionary\russian.cmd Для работы в Linux нужно собрать исполнимые файлы. Процесс сборки описан в  README.md . Ничего особого там нет, просто набор приседаний со скачиванием и установкой зависимостей и запуском сборки в CMake. Но есть и проблема - под VisualStudio 2017 перестал собираться один из компонентов  Парсера",грамматический словарь||русский язык
31,"      Текущие задачи, решенные в чатботе плохо или не решенные вообще  "," Зафиксировал текущее состояние всех алгоритмов  чатбота  релизом  0.0.0.12 . Как и раньше, это proof-of-concept, работающий на очень ограниченном domain'е, прежде всего ""здрасьте - как вас зовут"". В релизе добавлены новые  правила  и доработан workflow чатбота, что позволяет отрабатывать такие тестовые диалоги: 
 B:> Добрый день
H:> меня зовут Аркадий
B:> Аркаша, хочешь что-нибудь рассказать мне?
H:> я люблю компьютерные игры
B:> В какую игры ты играешь сейчас?
H:> а тебя как зовут?
B:> кеша
H:> как зовут меня?
B:> аркадий
 А теперь -  перечень задач, решенных в чатботе плохо или не решенных вообще . (*) Низкое качество  Интерпретатора , он часто выдает мусор, мешая последующим моделям в pipeline. (*) Верификатор синтаксиса и модератор семантики - пока плохо ранжирует сгенерированные фразы по их валидности (грамматичность + разумность с точки зрения common sence). (*) Нет модели entailment'а, чтобы оценивать, насколько хорошо реплика вписывается в канву диалога. (*) Нет обучения просто на реальных диалогах. (*)  Генеративная грамматика  работает достаточно медленно, надо переводить на PyPy, скорее всего. (*) Нет правил описания ""workflow"" в диалоге. (*) Сетевая подсистема отсутствует -  текущая реализация веб-сервиса на Flask  ненадежна с tensorflow и нужно делать генерацию реплик асинхронной, например через фоновый воркер на  Redis  + push уведомления веб-клиента о сгенерированных ответах чатбота. Кроме того, возможно следует проанализировать интеграцию с сетевой частью  RASA , чтобы не писать велосипеды.",чатбот
32,      Побочный эффект от генеративной грамматики: режим шаблонизатора  ," Фрагмент тестового диалога с экспериментальной версией  чатбота  (H:> реплики человека, B:> реплики бота) 
 B:> Привет
H:> добрый день
B:> Добрый день
H:>  меня зовут Илья 
B:>  Илья , хочешь что-нибудь рассказать мне? 
H:> я люблю компьютерные игры
B:> С кем ты играешь в компьютерные игры?
H:> а тебя как зовут?
B:> кеша
H:> ты кто?
B:> чатбот кеша
H:> а как меня зовут?
B:> илья
 Выделенный фрагмент - это пример работы движка  генеративной грамматики . Получив от собеседника фразу ""меня зовут Илья"", чатбот согласно штатному  workflow  определяет ее модальность (утверждение), сохраняет в базе знаний (это видно по последней паре вопрос- ответ, когда бот вспоминает запомненную информацию), а затем запускается одно из правил генерации ответной реплики. Генерация происходит так. Берутся слова последней реплики собеседника, складываются в мешок (wordbag), затем запускается генерация вариантов с подстановкой форм этих слов. Правило для данного случая написано так, что подставляется одушевленное существительное, то есть - имя собеседника. Это, конечно, не всегда будет давать такой хороший результат, но для прототипа вполне годно.",chatbot||генеративная грамматика||генеративная модель||генерация текста||чатбот
33,      Генеративная грамматика для проактивного чатбота  ," Для реплики собеседника  генеративная грамматика  создает целый набор вопросов и просто реплик. В некоторых случаях одна только N-граммная языковая модель позволяет неплохо отсеять откровенную бессмыслицу и оставить более-менее разумные фразы: 
 :> утром я играл на компьютере
0.999950 Хорошо, что ты сказал про компьютеры
0.999950 Хорошо, что ты сказал про компьютер
0.999753 Ты знаешь, как работает компьютер?
0.999753 Ты знаешь, как устроен компьютер?
0.998650 Как ты относишься к компьютерам?
0.998511 У кого ты учился играть с компьютером?
0.998178 А есть польза от компьютера?
0.992660 Давно ли ты играешь с компьютером?
0.992660 Часто ли ты играешь с компьютером?
0.992660 Как часто ты играешь с компьютером?
0.992660 Насколько хорошо ты играешь с компьютером?
0.982137 В ком ты играешь с компьютером?
0.982137 Из чего ты играешь с компьютером?
0.980257 С чем ты играешь?
0.980257 С кем ты играешь?
0.973532 У тебя есть компьютер?
0.967923 Ты хотел бы играть с компьютером?
0.948142 Тебе нравится играть с компьютером?
0.948142 Ты любишь играть с компьютером?
0.948093 Что хорошего в компьютере?
 Планирую поэкспериментировать с этим подходом в  чатботе .",chatbot||генеративная грамматика||генеративная модель||генерация текста||чатбот
34,"      Твердое ""может быть"" в вопросно-ответной системе  "," В догонку к  предыдущему  - еще пример обмена репликами, когда буквальное значение и подразумеваемое противоположны: - Хотите повторить? - Почему бы и  нет ? Ответ (кстати, в форме вопроса, хе-хе) содержит ""нет"", но однозначно подразумевает ""да"". Даже так - он полностью синонимичен ""да"": - Хотите повторить? -  Да .",забавные мелочи||чатбот
35,"      Наглядный пример, почему семантика - это не логика  "," Добавляю в чатбот обработку некоторых сценарией ""персонального ассистента"" и ""мажордома"". Среди прочего - команда на проверку почты: 
 B:> Добрый день

H:> нет ли новой почты?
B:> Фиктивная проверка почты в функции on_check_email

H:> новая почта есть?        
B:> Фиктивная проверка почты в функции on_check_email
 Можно заметить, что и утвердительная форма вопроса, и отрицательная имеют одинаковую семантику. В данном контексте это просто разные способы попросить собеседника проверить почту. Они вызывают одинаковую поведенческую реакцию. Ответ тоже будет одинаковым, не взирая на лексическую отрицательность вопроса. Кстати, очень распространенный паттерн в русской речи (в английской тоже, про остальные не помню), шлющий задорный привет  логическим языкам",chatbot||чатбот
36,      прототип движка для entity extraction в чатботе  ," В  код чатбота  добавлен движок (черновой proof-of-concept прототип) для  entity extraction . В качестве тестового примера сделана обработка запросов для прогноза погоды: 
 B:> Здравствуй
H:> подскажи, какая завтра утром будет погода
B:> Прогноз погоды на момент времени "" завтра утром "" сгенерирован в функции on_weather_forecast для демонстрации
H:> а сегодня вечером что у нас с погодкой ожидается?
B:> Прогноз погоды на момент времени "" сегодня вечером "" сгенерирован в функции on_weather_forecast для демонстрации
 Текст ответа ""Прогноз погоды на момент ...."" зашит в функции-заглушке  on_weather_forecast в console_chatbot.py:87 
 def on_weather_forecast(bot, session, user_id, interpreted_phrase):
    when_arg = bot.extract_entity(u'когда', interpreted_phrase)
    return u'Прогноз погоды на момент времени ""{}"" сгенерирован в функции on_weather_forecast для демонстрации'.format(when_arg)
 По плану - добавление в entity extraction модуль извлечение сущности ""как_долго"", чтобы обрабатывать вопросы типа "" Сколько еще будет дождь идти? "". Кусочек текущего тренировочного датасета  лежит тут . Для сборки  tsv файла  я использую  prepare_entities_dataset.py . Тренировка модели лежит в  nn_entity_extractor.py . Алгоритм - рекуррентная нейросетка +  CRF .",chatbot||crf||keras-contrib||ner||чатбот
37,"      Генеративная модель чатбота, основаная на правилах  "," Добавил для эксперимента в  движок чатбота  поддержку генеративной грамматики ( описание тут ) для создания реплик в ответ на не-вопрос собеседника: 

 B:> Добрый день
H:> я поиграл в компьютерную игру
B:> Как называется эта компьютерная игра?
 Последняя реплика бота не задается нигде явно, но создается движком генеративной грамматики по заданным шаблонам. В файле  rules.yaml  это правило выглядит так: 
     - rule:
        if:
            text: 'ты поиграл в компьютерную игру'
        then:
            generate:
                - 'Как называется эта подлежащ,жен ?'
                - 'Как называется этот подлежащ,муж ?'
                - 'Как называются эти подлежащ,мн ?'
                - 'Как называется подлежащ,ед ?'
                - 'Как называются подлежащ,мн ?'
 Опорная часть правила (if text ....) сопоставляется с фразой собеседника с помощью модели синонимичности, а продуктивная часть содержит варианты шаблонов генерации с нетерминальными токенами. Все нетерминалы заданы в отдельном файле и выглядят так: 
 подлежащ0,ед = [сущ,им,ед,одуш] [сущ,им,ед,одуш]
подлежащ0,ед = [сущ,им,ед]
подлежащ0,ед = [прил,им,ед,муж,~кр] [сущ,им,ед,муж]
подлежащ0,ед = [прил,им,ед,жен,~кр] [сущ,им,ед,жен]
подлежащ0,ед = [прил,им,ед,ср,~кр] [сущ,им,ед,ср]
подлежащ0,ед = [нареч,модиф_прил] [прил,им,ед,муж,~кр] [сущ,им,ед,муж]
подлежащ0,ед = [нареч,модиф_прил] [прил,им,ед,жен,~кр] [сущ,им,ед,жен]
подлежащ0,ед = [нареч,модиф_прил] [прил,им,ед,ср,~кр] [сущ,им,ед,ср]

подлежащ1,ед = подлежащ0,ед
подлежащ1,ед = подлежащ0,ед род_доп
подлежащ1,ед = подлежащ0,ед предл_доп

подлежащ,ед = 1 подлежащ1,ед
подлежащ,ед = подлежащ1,ед
...
 Правила рекурсивно задают грамматику русского языка, точнее небольшого его подмножества. Мне очень не нравится, что эти правила пришлось описывать руками, но unsupervised режим получения грамматики по эталонным текстам пока у меня нет. Алгоритм берет фразу человека, складывает ее слова в мешок, добавляет однокоренные слова и грамматические формы, а затем с помощью правил грамматики формирует множество вариантов предложений. Из них рандомно выбирается одна, с учетом вероятностей сгенерированных фраз. Важное достоинство этого алгоритма - рандомизация диалога, который перестает выглядеть механическим и безвариантным. Например: 
 B:> Добрый день
H:> а я сегодня в компьютерные игры играл
B:> В какую игры ты играешь сейчас?
 Хотя, конечно, это не делает его чем-то умнее  пресловутой китайской комнаты .",chatbot||генеративная модель||генерация текста||чатбот
38,      Большой рефакторинг чатбота: все правила в одном файле и модель определения intent'ов  ," В репозиторий  https://github.com/Koziev/chatbot  залита текущая версия чатбота с множеством изменений и исправлений. Правила для чатбота Среди главного - все правила теперь в одном YAML-файле  rules.yaml Почему в качестве формата выбран yaml? Я взвесил + и - трех альтернативных подходов. 1) Полностью свой формат, разбираемый каким набором инструментов для контекстно-свободной грамматики. Я так делал в предыдущих проектах на C# и C++. Достоинство подхода - можно делать красивую грамматику, не упираясь в ограничения XML/json/yaml форматов. 2) XML, JSON или YAML в качестве формата. XML по понятным причиным отпадает, хотя лет 10 назад я и видел сторонние ""языки"" на базе XML представления, и сам делал. Неудобно. JSON гораздо лучше. Но балансировать фигурные скобки без хорошего текстового редактора неудобно, а иногда даже подсветка не помогает. YAML гораздо читабельнее и проще в редактировании, на нем и остановился. 3) Зачем придумывать новый язык для записи правил, если уже есть Питон и его средства для динамического выполнения кода, например штатная либа  parser ? Самый большой минус по результатам экспериментов - слишком сильная завязка на контекст выполнения (надо знать имена переменных, через которые передается входная информация для питоновского кода), плюс некоторые неприятности с юникодными строками. Порядок описания различных правил описан комментариями прямо в rules.yaml, там же сейчас есть рабочие простые примеры. Например, если в текущем релизе ввести вопрос ""Какая сейчас погода"", то увидим: 
 H:> какая сегодня будет погода
B:> Прогноз погоды сгенерирован в функции on_weather_forecast для демонстрации
 Ответ бота просто сгенерирован функцией weather_forecast в модуле  console_chatbot.py , вызываемый из правила в rules.yaml. Предполагается, что после введения модели определения entities это правило будет учитывать дату и место для прогноза. Порядок применения правил 1) Если есть история диалога (>1 реплики), то реплика собеседника прогоняется через модель интерпретации для восстановления полной фразы, раскрытия анафоры, гэппинга и т.д. 2) Среди comprehension правил (секция comprehensions в rules.yaml) ищется достаточно близкий вариант фразы в if блоке. Если правило нашлось, то вместо исходной фразы дальше будет обрабатываться then-фраза из найденного правила. Таким образом выполняется  нормализация . Например, императивная реплика ""Доложи погоду на завтра!"" может быть нормализована в вопросительную форму ""Какая завтра будет погода?"". 3) Определяется intent с помощью обученного на  датасете data/intents.txt  классификатора. Датасет сейчас крошечный, но его можно легко расширять своими правилами и переобучать модель - см. далее. 4) Определяется грамматическая модальность - является ли реплика вопросом, утверждением или приказом. 5) Для приказов: пытаемся найти правило для обработки (секция rules в rules.yaml) и выполняем его. При поиске используется либо определенный intent (if-часть содержит ключевое слово intent), либо проверяется синонимичность с помощью модели синонимичности. Если правило не найдено, то вызывается дефолтный обработчик - пользовательская функция, зарегистрированная в on_process_order. Если и он не обработал приказ, то будет сказана фраза ""unknown_order"" в rules.yaml 6) Для утверждений: пытаемся найти правило обработки (секция rules в rules.yaml) и выполнить его. Далее, факт сохраняется в базе знаний. Наконец, пытаемся найти smalltalk-правило: это правило в группе rules (rules.yaml), в котором опорная часть (if) и результативная часть (then) заданы с ключевым словом text. Ищется правило, в котором опорная часть максимально синонимична входной фразе, если найдено - чатбот скажет фразу, которая указана в then-ветке. 7) Для вопросов: сначала проверяется, нет ли похожего (модель синонимичности) вопроса среди FAQ-правил (файл  faq2.txt ). Если есть - выдается содержимое найденного FAQ-правила. Иначе начинается процедура генерации ответа. С помощью модели релевантности (см. отдельный раздел про ее дообучение и валидацию) ищутся максимальной релевантные предпосылки в файлах  premises*.txt . Если не найдена достаточно релевантная предпосылка, то выдается фраза ""no_relevant_information"" из rules.yaml. В ходе генерации ответа может потребоваться ответить ""да"" или ""нет"". Эти фразы находятся в rules.yaml в разделе ""answers"". Верификация модели синонимичности С помощью скрипта  scripts/query2_lgb_synonymy.sh  можно искать примеры неверной работы модели синонимичности. В консоли вводится фраза, для которой модель вычисляет похожесть к набору фраз из датасетов. Результаты, ранжированные по убыванию похожести, выводятся в консоль. Если среди найденных фраз с похожестью > 0.5 есть явно ошибочные, их можно внести как негативные примеры (в файл paraphrases.txt или в собранный датасет  synonymy_dataset.csv ), затем переобучить модель скриптом  scripts/train_lgb_synonymy.sh Модель определения intent'а С помощью модели intent'а можно присвоить фразе собеседника одну метку из набора возможных и далее обрабатывать фразу с учетом этой метки правилами (раздел rules в rules.yaml). Данные для обучения находятся в текстовом файле  data/intents.txt . Его формат прост и описан в комментарии в начале файла. После модификации этого файла необходимо собрать датасет с помощью  PyModels/preparation/prepare_intents_dat aset.py , затем запустить обучение классификатора с помощью  scripts/train_intent_classifier.sh",chatbot||чатбот
39,      auto-FAQ чатбота и планы по intent/entity extraction движку  ," 1. Я немного автоматизировал процесс  hard negative mining  для  чатбота , добавил  найденные негативные сэмплы  в датасеты и переобучил все модели. Заодно расширил тестовый диалог, в котором проверяется модель синонимичности. Теперь чатбот умеет кое-что о себе рассказывать: 
 B:> Привет, буду рад пообщаться
H:> как тебя зовут, дружище?
B:> кеша
H:> кто ты такой?
B:> Интеллектуальный автономный робот
H:> ты чатбот?
B:> да
H:> Зачем нужен чатбот?
B:> Чатбот может осуществлять техническую поддержку пользователей
H:> На каких условия можно использовать этот чатбот?
B:> Лицензионное соглашение данного чатбота разрешает использовать его в любых проектах
H:> Где еще можно почитать о тебе?    
B:> Мое описание можно найти по ссылке https://github.com/Koziev/chatbot
H:> Как можно добавлять в чатбот свои новые правила?
B:> Исходные тексты чатбота открыты и доступны для модификации. Новые правила можно добавлять через переобучение языковых моделей на своих датасетах.
H:> Где можно посмотреть твои исходные тексты?
B:> Мои исходные тексты доступны в репозитории https://github.com/Koziev/chatbot/tree/master/PyModels
H:> Что отмечается 12 декабря?
B:> день конституции
H:> о чем я могу говорить с тобой?
B:> Я готов отвечать на вопросы о себе
H:> сколько в марте дней?
B:> 31
H:> сколько сейчас времени?
B:> 14 часов 34 минуты
H:> как ты относишься к религии?
B:> равнодушен к религии
H:> какой сейчас месяц?
B:> май
H:> Сейчас май, это правда?
B:> да
H:> сегодня понедельник?
B:> нет
H:> какой сегодня день недели?
B:> вторник
 2. Дальше в планах стоит активный ресерч в направлении подходов определения intent'а и entity extraction. Типа  такого , но без hand crafted rules, а только на машобуче и датасетах. Делать просто NER не будем, надо кое-что более интересное. Прежде всего, хочется иметь возможность, например, извлекать из вопросов пользователя про погоду любые детерминанты времени: все, что отвечает на вопрос "" когда "". Не все такие детерминанты определяются обычным NER, например для  Natasha  некоторые важные случаи не ловятся:",chatbot||named entry recognition||текущие планы||чатбот
40,      Кастомизация чатбота: переобучение модели релевантности  ,"  Модель релевантности  - алгоритм, который для двух заданных фраз (предпосылка и вопрос), определяет, содержит ли предпосылка всю информацию, необходимую для ответа на вопрос. Добавление новых сэмплов и переобучение При добавлении новых фактов в базу знаний может возникнуть ситуация, что модель релевантности не знакома с новой лексикой и сильно ошибается при поиске подходящего факта. В этом случае модель релевантности нужно переобучить, добавив новые сэмплы в обучающий датасет. Обучающий датасет - это текстовый tab-separated файл  premise_question_relevancy.csv . В колонке premise находятся предпосылки (факты), question - вопросы. Колонка relevance содержит 1 для нелевантных пар, 0 для нерелевантных. Таким образом, чтобы модель считала предпосылку и вопрос релевантными, надо добавить к этому датасету запись с relevance=1. Следует избегать добавления повторов, так как это будет приводить к искажению оценок точности при обучении. После изменения файла premise_question_relevancy.csv нужно запустить обучение скриптом  .../script/train_lgb_relevancy.sh . Обучение идет примерно полчаса. В результате в каталоге .../tmp будут созданы новые файлы lgb_relevancy.*, содержащие правила модели релевантности. Контроль качества Любые ошибки при работе модели релевантности негативно сказываются на общем качестве диалогов, поскольку многие другие части чатбота используют результаты выбора предпосылок из базы знаний в качестве входной информации. Чтобы контролировать качество этой модели, желательно верифицировать ее работу на тестовых вопросах и наборе тестовых предпосылок. Для выполнения этой верификации мы используем простой консольный скрипт  query2_lgb_relevancy.sh . Он загружает текущую обученную модель релевантности и список предпосылок из базы знаний ( .../data/premises*.txt ) и тренировочного датасета (.../data/premise_question_relevancy.csv) . Затем с консоли вводится проверочный вопрос, модель вычисляет его релевантность по всем предпосылкам и выводит список из нескольких самых релевантных. Если в этом списке есть явно нерелевантные предпосылки с высокой оценкой (допустим, выше 0.5), то есть смысл добавить такие предпосылки с вопросом в качестве негативных примеров в датасет premise_question_relevancy.csv и переобучить модель релевантности. Грамматическое лицо в датасете При добавлении сэмплов в обучающий датасет и при контроле качества модели следует учитывать следующий нюанс. Информация в базе знаний чатбота хранится “от первого лица”. Например, запись “Меня зовут Алиса” в базе знаний относится именно к чатботу. Факты, относящиеся к собеседнику, формулируются от второго лица: “Тебя зовут Илья”. Именно в таком виде эти факты хранятся в датасете premise_question_relevancy.csv. Также, поступающие на вход модели релевантности вопросы собеседника тоже конвертируются в “эгоцентричную” модель мира. Если мы спрашиваем чатбот “Как тебя зовут”, то на вход модели релевантности поступает вопрос “как меня зовут”. Эту конверсию надо учитывать при ручной проверке качества, вводя вопросы в query2_lgb_relevancu.sh. Например: -inkoziev@inkoziev-MS-7B17:~/github/chat bot/scripts$  ./query2_lgb_relevancy.sh 39078 premises loaded from ../data/premise_question_relevancy.csv nb_premises=39297 question:>  как меня зовут 0.9995 меня зовут Кеша 0.9994 меня зовут дмитрий …",chatbot||nlp||чатбот
41,      Датасет для тренировки модели синонимичности  ," В репозиторий добавлена часть  датасета для тренировки модели синонимичности . Чтобы переобучить модель после изменений этого датасета, нужно выполнить скрипт  train_lgb_synonymy.sh . Аналогичный  датасет для модели релевантности вопроса и предпосылки  был выложен ранее. Переобучение этой модели запускается скриптом  train_lgb_relevancy.sh",chatbot||перефразировки||синонимы||чатбот
42,      Генеративная модель формирования ответов интегрирована в движок чатбота  ," (В продолжение темы "" Машина Хомского "") В  основной код чатбота  перенесен весь алгоритм построения ответа с помощью "" вероятностной машины Хомского "".  Движок построения ответа  перекроен, чтобы эффективно использовать новые сеточные модели, в частности  модель оценки релевантности ответа  при заданных предпосылках и вопросе. Докер-контейнер с новой версией",chatbot||генеративная модель||генерация текста||чатбот
43,      Баг при запуске нейросетевых моделей с tensorflow под Flask.  ," В какой-то момент перестал работал  flask-сервис   чатбота . Видимо, после обновления tensorflow. Симптом - падает при вызове метода predict для загруженной модели с диагностикой типа: ValueError: Tensor Tensor(""output_2/Sigmoid:0"", shape=(?, 1), dtype=float32) is not an element of this graph. Если вывести граф модели - с ним все в порядке. В консольном варианте ошибка не воспроизводится. По совету  GraphGrailAi  в  https://github.com/Koziev/chatbot/issues/14  добавил в код (например  тут ) такой workaround: 
 with   self .graph.as_default():
    y = self.model.predict( ... )
 и бот ожил. Подробное обсуждение бага в  https://github.com/tensorflow/tensorflow/issues/14356 . Возможно, где-то еще в коде потребуется аналогичная правка. Кроме того, заметил, что загруженные модели как-то очень активно потребляют память на gpu'шке, норовя выйти на рубеж OOM. Возможно, придется урезать  леща  сложность моделек для прода.",chatbot||tensorflow||чатбот
44,"      Планы по новой генеративной модели чат-бота (""Машина Хомского"")  "," Готовлю к переносу в  код чатбота  новый генератор ответов на основе  генеративной грамматики  с обвесом из нескольких нейросеток. Далее - небольшие подробности о решаемой задаче. Генератор ответа в чатботе принимает на вход найденные в базе фактов предпосылки (в общем случае от 0 до 2-3), заданный вопрос, и формирует ответ. Если не рассматривать случаев, когда ответом являются слова “да” или “нет”, то генератор должен взять некоторые слова ( attention  модель), сложить их в ""мешок"", иногда просклонять или проспрягать, добавить служебные слова, затем выстроить в правильном порядке (предлоги перед именной группой и т.д.).  Например: предпосылка:  Ты позабыла свой обет вопрос:  О чем ты забыла? ответ:  О своем обете Кстати, генерация ответа из мешка слов - задача, которая активно используется для тренировки практических языковых навыков у детей в первом-втором классе школы. В текущей реализации основная проблема связана с моделью посимвольной генерации (авторегрессионная модель с выбором одного следующего символа на каждый вызов). Эта модель сейчас обучается по двое суток и нередко выдает искаженный текст. Как мне кажется, хорошей альтернативой будет новая модель на основе генеративной грамматики. В свое время  эта концепция Хомского  неплохо так встряхнула дескриптивное болото лингвистики со всеми этими  каритивами , так почему бы не попробовать ее для чатбота? Тем более что генеративная грамматика чрезвычайно проста в реализации. Мы предполагаем, что есть набор правил генерации, применяемых рекурсивно, и позволяющих генерировать любые синтаксически валидные фразы языка. Если не гнаться за полнотой покрываемого языкового поля и ограничиться неким подмножеством, например из ответов длиной от 1 до 5 слов, то получается компактный набор правил. У меня получилось примерно 200 правил для генерации русских ответов. Важным достоинством генерируемых этими правилами фраз является их  грамматическое качество . В большинстве случаев получаются вполне валидные цепочки слов, хотя  их осмысленность - отдельная тема . Недостатки генеративной модели являются продолжением ее достоинств. Самый главный недостаток - модель вычислительно тяжёлая. Для типичного сочетания предпосылки и вопроса создаётся несколько тысяч вариантов ответа, из которых только несколько оказываются осмысленными перефразировками правильного ответа. Тем не менее, будучи оснащена хорошо обученной дискриминативной моделью валидации вариантов ответа, описываемая архитектура обладает хорошей выразительной силой. В некоторых случаях результат ее работы выглядит как простое копирование слов из предпосылки, хотя на самом деле сначала был сформирован мешок слов, из которого сгенерированы синтаксически валидные варианты, один из которых и показан: premise:>  кристалл обладает природным антибактериальным действием question:>  обладает кристалл чем ? answer= Природным антибактериальным действием  (0.993309288901) Без каких-либо переделок эта же архитектура может выполнять подбор формы слов, например - склонение: premise:>  Я дружу с Мишей question:>  как зовут моего друга ? answer= Миша  (0.0527198509705) Ошибки, которые делает архитектура, тоже интересны. Поскольку это ""машина управляемых текстовых галлюцинаций"", то результат сильно зависит от дискриминаторной части, которая отбирает наиболее подходящие варианты. Иногда она пропускает что-то слишком креативное: premise:>  в степи за станцией стоят зенитки question:>  зенитки где находятся ? true answer= в степи за станцией predicted answer= Степи за станцией перегона  (0.114703481843)  (ERROR) Не говоря уже о банальных ошибках согласования, от которых на самом деле не застрахован и обычный человек: premise:>  коля покачал головой question:>  коля покачал чем ? true answer= головой predicted answer= Голову  (0.731233797589)  (ERROR) Или вот типичная ошибка из-за невнимательности: premise:>  гриша подозрительно поглядел на барятина question:>  поглядел подозрительно гриша на кого ? true answer:  на барятина predicted answer= На гришу  (2.94164681944e-08)  (ERROR)",chatbot||генеративная модель||генерация текста||грамматика||русский язык||чатбот
45,      Изменения в грамматическом словаре касательно составных существительных  ," В продолжение  работы над составными прилагательными , в  грамматическом словаре  выполнена чистка русского лексикона от большого количества составных существительных. Мотивация отчасти та же - много составных существительных образуется добавлением префиксов типа ""альфа"" к обычному существительному. Чтобы работать с такими составными существительными, в словаре была введена  специальная служебная категория слов ПРЕФИКС_СОСТАВ_СУЩ . Размер словника сокращается, семантика не размывается, а потенциальное покрытие лексиконом увеличивается. Кроме того, из лексикона убрано много составных существительных, в которых первая часть является формой именительного падежа другого существительного, например  рок-концерт  и не меняется в ходе склонения основной, второй части. Наконец, было удалено некоторое количество мусора из слов типа "" балка-игла "", где обе части составного существительного являются нормальными существительными сами по себе и склоняются синхронно с агрегатом. Синтаксический анализатор прекрасно справляется со всеми этими случаями (см. соответствующие правила разбора в  rus_sa_noun_core.sol ), даже если первая часть составного существительного вообще неизвестна.",лексикон||русский язык||существительное
46,      Изменения в грамматическом словаре касательно составных прилагательных  ," В "" грамматическом словаре русского языка "" закончена большая чистка русского лексикона. Из словарной базы убраны почти все составные прилагательные такого вида ""ярко-зеленый"", ""багрово-красный"" и т.д. В итоге словарь стал меньше, но мощность описываемой им лексики - больше. Далее - пояснения мотивации и последствия. Русский язык, конечно, далек от немецкого или некоторых скандинавских в плане  свободы словообразования  с помощью слияния. Но есть отдельные очень продуктивные и частотные способы, среди них - образование составных прилагательных с помощью присоединения частиц-модификаторов к базовому прилагательному: "" ярко -зеленый"". Чтобы учесть в словаре это словообразование, можно добавлять все частотные варианты составных прилагательных. Так делается, например, в Викисловаре - см.  страничку ярко-зеленый , и в некоторых других русских лексических системах описания. Проблема с этим подходом очевидна - распухание лексикона, проблема с заданием семантики для составных прилагательных. Одно только сочетание с ""ярко-"" дает несколько десятков формально новых прилагательных! Другой путь, на котором я остановился - отдельное определение  списка частиц , и рассмотрение составных прилагательных как multiword units. В грамматическом словаре они вынесены в отдельную часть речи с названием  ПРЕФИКС_СОСТАВ_ПРИЛ  (см.  файл sg_rus_main.sol ). Сделано это, кстати, судя по changelog'у, в 2015 году. Сейчас таких частиц менее двух тысяч, но лексикографический анализ 80-Гб корпуса ( быстренько сделанный скриптик на питоне ) дает список из ~40 тысяч частиц. Полученный список с частотами и примерами составных прилагательных прикреплен к  гисту . Надо заметить, что отнюдь не все сочетания префиксов и прилагательных употребимы, например частицы типа ""сине"" используются только для цветовых прилагательных и т.д. Поэтому нельзя оценивать количество потенциальных формально как декартово произведение двух подмножеств. Тем не менее, введенный в грамматическом словаре способ потенциально более эффективен. Сопутствующие изменения будут в ближайшее время в остальных проектах, включая  ruword2tags ,  rupostagger ,  rulemma  и  rutokenizer .",грамматический словарь||лексика||прилагательное||русский язык
47,      Кастомизация чат-бота без переобучения моделей  ," Главная фишка архитектуры  чатбота  состоит в том, что это  retrieval-based модель  (наполовину). Для ответа на вопрос ""Как тебя зовут?"" и ""Сколько сейчас времени?"" чатбот ищет в базе фактов нужную информацию и на ее основе строит ответ (за построение ответа отвечает  генеративная модель ).  В частности, это означает, что имя чатбота нигде не ""зашито"" в языковых моделях, и его можно сменить, просто отредактировав  текстовый файлик . Переобучать никакие модели после этого не нужно! Открываем файл, ищем там две строки: меня зовут Кеша Я чатбот Кеша Отредактируем их: меня зовут Степа Я чатбот Степа Запускаем  чатбот - теперь он уверен, что его зовут именно ""Степа"": 
 H:> да как же тебя звать-то?
B:> степа
H:> тебя зовут кеша?
B:> нет
H:> тебя зовут степа?
B:> да
 Аналогичный процесс, только автоматический, происходит при обработке вопроса ""Сколько сейчас времени?"". Запись о текущем времени добавляется в базу фактов автоматически перед каждым поиском релевантных фактов, поэтому чатбот всегда знает текущее время, а также текущую дату и день недели. Добиться такого эффекта с примитивной генеративной seq2seq моделью, конечно, невозможно.",chatbot||чатбот
48,      Аугментация и генерация NLP датасетов с помощью ruword2tags.RuFlexer  ," В библиотеку  ruword2tags  добавлен новый класс RuFlexer, содержащий инструменты для генеративных текстовых моделей. Сейчас этот класс предоставляет единственный метод find_forms_by_tags для подбора форм слова с заданными тегами. Например, чтобы найти форму слова ""кошка"" для творительного падежа множественного числа, надо написать примерно такой код: 
 import  ruword2tags

flexer = ruword2tags.RuFlexer()
flexer.load()

forms = flexer.find_forms_by_tags( u'кошка' , [( u'ПАДЕЖ' ,  u'ТВОР' ), ( u'ЧИСЛО' ,  u'МН' )])
 print ( list (forms))
 Зачем это может пригодиться? Для аугментации и генерации текстовых датасетов в NLP. Как нетрудно  убедиться , для русского языка количество доступных датасетов под многие NLP задачи очень ограничено, особенно если сравнивать с английским языком. Причем для типовых задач типа анализа сентимента или частеречной разметки что-то еще можно найти в сети, а вот для более специфичных задач все совсем грустно. Ну а если задача вообще редкая или экспериментальная, то шансы на  халяву  готовый датасет просто нулевые. Возьмем, к примеру, такую задачку. У нас некий алгоритм выдает тестовые фразы на заданную тему, по многу вариантов для каждого исходного мешка слов. Среди них есть как вполне нормальные, так и немного корявые фразы типа: Ты любишь есть на яблочки. Для отсева невалидных вариантов можно использовать 2- и 3-граммы, но они все равно пропускают часть таких случаев, особенно для редкой лексики (вдруг я люблю маракуйю, а яблоки не ем? то-то же). Одно из решений проблемы - анализировать дерево зависимостей и проверять статистику сочетаемости актантов с конкретным глаголом-сказуемым. Другой способ - нейросетевая модель детектора валидности предложения, которая заодно отсекала бы бессмыслицу типа "" Я люблю в яблоки "". В обоих случаях нам нужны сэмплы с правильными и неправильными предложениями. И в отличие от других ситуаций тут нельзя просто нагенерировать негативных примеров через подстановку/замену рандомных слов в правильных фразах, так как вышеупомянутый алгоритм выдает в общем-то синтаксически валидные фразы, в которых случайных слов не бывает. Составлять такой датасет руками - адская вещь. В этом тоже есть грустная ирония NLP. Кто хочет, может попробовать написать хотя бы 100 разных предложений с ошибками (""Тебе наплевать близ наших картинок"" и т.д.). Увы, креативность - не самая сильная черта человеческого языкового движка, и через некоторое время автор такого нонсенса скатывается в вариации на тему какого-то одного случая, а потом вообще бросает занятие. А сэмлов надо много, особенно для нейросетевого классификатора. Тысячи. Тут может помочь аугментация, в частности шаблонная генерация негативных сэмплов из годных предложений (см. например  https://medium.com/@jetbootsmaker/fountain-%D0%B0%D1%83%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F-%D0%B4%D0%BB%D1%8F-%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2%D1%8B%D1%85-%D0%B4%D0%B0%D1%82%D0%B0%D1%81%D0%B5%D1%82%D0%BE%D0%B2-8d4c6940864f ). Самый простой подход такой. Берем фразу с предлогом, заменяем предлог на рандомный, при необходимости пересогласуем зависящие от предлога элементы группы существительного. Примеры работы этого алгоритма: Исходное предложение: "" Почему ты уверен в своей правоте "" Результаты генерации: 
 Почему ты уверен подобно своей правоте
Почему ты уверен вроде своей правоты
Почему ты уверен наравне со своею правотою
Почему ты уверен без оглядки на свою правоту
Почему ты уверен предо своею правотою
Почему ты уверен в честь своей правоты
Почему ты уверен среди своей правоты
Почему ты уверен параллельно своей правоте
 Исходное предложение: "" Ты решилась на местный вариант шавермы. "" Результаты генерации: 
 Ты решилась внутрь местного варианта шавермы.
Ты решилась наперерез местному варианту шавермы.
Ты решилась по направлению к местному варианту шавермы.
Ты решилась обо местный вариант шавермы.
Ты решилась средь местного варианта шавермы.
Ты решилась согласно местному варианту шавермы.
Ты решилась за местный вариант шавермы.
Ты решилась следом за местным вариантом шавермы.
Ты решилась сроком на местный вариант шавермы.
Ты решилась кроме местного варианта шавермы.
 Как видно, в большинстве случаев результат генерации остается синтаксически валидным, но бессмысленным. Это-то и позволяет использовать результат генерации для валидации или даже для обучения, особенно если вручную промодерировать созданные фразы (забавно, что это намного проще, чем  выдумывать  свои фразы). Код генератора на Питоне с использованием библиотек  ruword2tags ,  rulemma ,  rupostagger  и  rutokenizer :  https://gist.github.com/Koziev/cd7ee3c0b9a264d147e787126eb7059a PS:  Юрий Бабуров  подкинул еще хорошую статью по теме аугментации в NLP:  https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610",dataset||nlp||генеративная модель||генерация текста||предлог||русский язык
49,      Добавлена обработка OOV слов в лемматизаторе rulemma  ," В питоновской библиотеке  rulemma  добавлена обработка несловарных (out-of-vocabulary) слов. Большинство OOV-слов образуются по относительно небольшому количеству словоизменительных правил русского языка, так что модель неплохо справляется с ними. При этом используются результаты частеречной разметки, чтобы снимать неоднозначности типа  крокодил - проходил . В качестве примера можно посмотреть на разбор фразы "" Мяукая, голодные кошки ловят жирненьких  хрюнделей "": 
 import  rutokenizer
 import  rupostagger
 import  rulemma

lemmatizer = rulemma.Lemmatizer()
lemmatizer.load( '../tmp/rulemma.dat' )

tokenizer = rutokenizer.Tokenizer()
tokenizer.load()

tagger = rupostagger.RuPosTagger()
tagger.load()
 print ( 'Loading finished' )

sent =  u'Мяукая, голодные кошки ловят жирненьких хрюнделей'
 tokens = tokenizer.tokenize(sent)
tags = tagger.tag(tokens)
lemmas = lemmatizer.lemmatize(tags)
 for  word, tags, lemma, *_  in  lemmas:
     print ( u'{:15} \t {:15} \t {}' .format(word, lemma, tags))
 Результат: 
 Мяукая          мяукать         VERB|VerbForm=Conv
,               ,               PUNCT
голодные        голодный        ADJ|Case=Nom|Degree=Pos|Number=Plur
кошки           кошка           NOUN|Case=Nom|Number=Plur
ловят           ловить          VERB|Mood=Ind|Number=Plur|Person=3|Tense=Notpast|VerbForm=Fin
жирненьких      жирненький      ADJ|Case=Acc|Degree=Pos|Number=Plur
 хрюнделей         хрюндель          NOUN|Case=Acc|Number=Plur 
 Как видно, и частеречная разметка, и лемматизатор корректно обработали слово ""хрюнделей"".",github||python||лемматизатор||русский язык
50,      Обновления в грамматическом словаре (GrammarEngine и ruword2tags)  ," В проектах  GrammarEngine ,  ruword2tags  и  rulemma  в ходе разработки и отладки  чатбота  сделаны следующие изменения: 1) Пара сотен новых словарных статей, преимущественно из домена химии, металлургии, технологии. 2) Добавлена информация о малоупотребимости некоторых кратких форм прилагательных. На этом остановлюсь поподробнее - см. под катом. Если взять  SQL вариант грамматического словаря  и сделать выборку таким запросом: 
 select E1.name as 'лемма прил', F1.name as 'форма_прил', E2.name as 'лемма_глаг', F2.name as 'форма_глаг'
 from sg_class C1 -- прилагательные
 join sg_entry E1 on E1.id_class=C1.id
 join sg_form F1 on F1.id_entry=E1.id
 join coord_pairs P1 on P1.id=F1.id_dims and P1.str_pairs like '% КРАТКИЙ %' and P1.str_pairs like '%ЧИСЛО:ЕД%'
 join sg_class C2 on C2.name='ГЛАГОЛ'
 join sg_entry E2 on E2.id_class=C2.id
 join sg_form F2 on F2.id_entry=E2.id and F2.name=F1.name -- совпадающие формы глагола и прилагательного
 join coord_pairs P2 on P2.id=F2.id_dims and P2.str_pairs like '%ЛИЦО:1%'
 where C1.name='ПРИЛАГАТЕЛЬНОЕ' 
 То можно увидеть, что более почти две тысячи кратких форм прилагательного совпадают с формой глагола 2 лица множественного числа. При этом форма прилагательного практически не употребляется: удовлетворимый    удовлетворим     --------   удовлетворить    удовлетворим Есть и обратные примеры, когда краткая форма прилагательного более употребима и экранирует омонимичную форму глагола - "" различим "". Иногда оба варианта употребляются примерно равночастотно - "" видим "". Наличие таких омонимов в словаре обычно не мешает, например, выполнять частеречную разметку, так как языковая модель неплохо выбирает правильную часть речи на основе контекста. Но для  генеративной модели  в чатботе наличие этих форм заставляет код проверять дополнительные варианты создаваемых фраз, при том что многие из этих слов достаточно частотны и просто исключить их из лексикона чатбота нельзя. В общем, такие малоупотребимые формы слов вносятся в специальную таблицу словарной базы. Исходный список можно увидеть в файле  rus_wordform_frequency.sol . А теперь про соответствующее изменение в библиотечке  ruword2tags  (это питоновский вариант грамматического словаря для быстрого прототипирования в NLP). В новой версии из словарной базы исключены такие малоупотребимые формы слов. Аналогичные изменения сделаны также в библиотеке  rulemma .",глаголы||грамматический словарь||прилагательное||русский язык
51,      Странная разница в скорости pickle.load в Python 2 и 3  ," В ходе экспериментов с оптимизацией загрузки словаря в  проекте ruword2tags  столкнулся с неожиданным эффектом. Контекст такой: 1) Код, генерирующий словарную базу, написал на Python 3. 2) Результат работы этого кода - несколько списков и графов ( trie ), сохраняемых через pickle с протоколом 2 для поддержки совместимости в 2 и 3 версиях. 3) В пакет входит небольшой набор тестов. Для запуска нужно запустить питон в командной строке и затем: 
 import ruword2tags
ruword2tags.run_tests()
 Основное время в тесте затрачивается на pickle.load для загрузки структур словаря. 4) ruword2tags работает в обеих версиях питона с одним и тем же pickle-файлом. Вероятно, к концу этого года я сам перестану использовать вторую версию и отстрелю ее поддержку, но пока это нужно. 5) Неожиданный эффект заключается в том, что во  2й версии питона pickle.load работает примерно 60 секунд, в 3й - 6 секунд",python
52,      Релиз чатбота 0.0.0.5  ," Докер-образ чатбота 0.0.0.5  выложен в репозитории .  Там же  выложены все актуальные языковые модели и исходники бота. Основное изменение - некоторая оптимизация процесса запуска чатбота. Я внес небольшие изменения в проект грамматического словаря ( ruword2tags ), чтобы можно было загружать не  полную русскую словарную базу  из 2.5 миллионов словоформ, а только небольшое подмножество, которое фактически встречалось в обучающих датасетах. Сопутствующие правки сделаны также в  проекте частеречной разметки rupostagger . Также я поправил некоторые баги в моделях интерпретации. Ну и разумеется общее улучшение языковых моделей, переобученных по расширенным датасетам. В частности, сейчас в checklist'е проверки бота есть целый набор для проверки FAQ-режима бота: 
 B:> Привет, буду рад поговорить
H:> Как работают атомные часы?
B:> Атомные часы (молекулярные, квантовые часы) — прибор для измерения
времени, в котором в качестве периодического процесса используются
собственные колебания, связанные с процессами, происходящими на уровне
атомов или молекул.

H:> Что нужно для приготовления омлета?
B:> Рецепт омлета кажется простым даже для школьника: взбить яйца
с молоком или сливками, добавить соль, вылить яичную смесь на смазанную
маслом раскаленную сковороду и жарить несколько минут под закрытой
крышкой на среднем огне.

H:> Кто такой Пушкин?
B:> Пушкин Александр Сергеевич — русский поэт, драматург и прозаик,
заложивший основы русского реалистического направления, критик и
теоретик литературы, историк, публицист; один из самых авторитетных
литературных деятелей первой трети XIX века.

H:> Куда грачи осенью улетают?
B:> Когда осенью количество пищи резко сокращалось, грачи собирались
в стаи и откочевывали со средней полосы России на юго-запад.

H:> Как делают мыло?
B:> Получение мыла основано на реакции омыления — гидролиза сложных
эфиров жирных кислот (в частности, жиров) со щелочами, в результате
которого образуются соли щелочных металлов и спирты.

H:> Что приводит к образованию облаков?
B:> Как и туманы, облака возникают в результате конденсации водяного
пара в жидкое и твёрдое состояния.

H:> Какой вес бывает у осьминогов?
B:> Масса осьминогов достигает 50 кг. Есть сведения, что осьминог
Дофлейна может достигать длины 960 см и массы 270 кг.

H:> Какой цвет имеет кровь у осьминогов?
B:> У осьминога голубая кровь.

H:> Съедобны ли абрикосовые косточки?
B:> Абрикосовую косточку также можно есть. Более того, она обладает
рядом полезных свойств.
 
",chatbot||диалоги||чатбот
53,      Новый небольшой тестовый диалог в чатботе (релиз 0.0.0.4)  ," После расширения обучающих датасетов, переобучения языковых моделей и небольших правок в коде самого чатбота начал отрабатывать тестовый диалог: 
H:> Что-то я себя неважно чувствую
B:> Что у тебя болит?
H:> зуб
B:> Записать тебя к стоматологу?
H:> да
B:> Выполняю команду ""запиши меня к стоматологу""
 Релиз чатбота 0.0.0.4  выложен в репозиторий.",chatbot||диалоги||чатбот
54,      Тестовый диалог с чатботом для новой версии  ," Для предстоящей новой версии  чатбота  прогнал тестовый диалог. Мои реплики помечены меткой H, реплики чатбота - B: 
 B:> День добрый
H:> Привет, как тебя зовут?
B:> кеша
H:> Кеша, а ты кто?
B:> чатбот кеша
H:> А меня зовут Миша, я человек
B:> Привет, Миша!
H:> Ты умеешь складывать числа?
B:> да
H:> Кеша, а можешь помочь мне с арифметикой?
B:> да
H:> Сколько будет 3 плюс 2?
B:> 5
H:> Спасибо, Кеша!
B:> Пожалуйста
H:> А еще по русскому языку можешь помочь?
B:> да
H:> Что такое имя существительное?
B:> Существительное — самостоятельная часть речи, обозначающая предмет, лицо или явление и отвечающая на вопросы «кто?» или «что?».
",chatbot||диалоги||чат-боты||чатбот
55,      Docker-образ чатбота v.0.0.0.1-alpha  ," Как оказалось, github позволяет очень просто  делать релизы  больших бинарных файлов до 2Гб размером. Поэтому я попробовал собрать docker-образ  чатбота  и оформил его как  релиз 0.0.0.1 . Для запуска тестовой версии чатбота под линуксом теперь достаточно скачать этот релиз, затем выполнить две команды: docker image load -i chatbot.tar.gz docker run -ti -e PYTHONIOENCODING=utf-8 chatbot Через некоторое (довольно большое - код и архитектура не оптимизированы категорически) время бот загрузит все модели и напечатает приглашение. Далее можно пробовать небольшой набор тестовых вопросов из длинного чеклиста: Привет, как тебя зовут? Наверное, ты робот, да? Что ты любишь делать? Ты в шахматы умеешь играть? А в шашки? Ты знаешь, что такое белый карлик? Если исключить отладочную информацию, будет примерно такой результат: 
 H:> Ты знаешь, что такое белый карлик?
B:> Белые карлики — проэволюционировавшие звёзды с массой, не превышающей предел Чандрасекара (максимальная масса, при которой звезда может существовать как белый карлик), лишённые собственных источников термоядерной энергии.
",chatbot||github||чатбот
56,      Новая версия датасета с русскоязычными диалогами (130 Мб)  ," Выложил в репозиторий  архивчик с текстовым файлом  - 130 Мб русскоязычных диалогов, извлеченных из большого корпуса (художественная литература всех жанров, документалистика и еще всякое): - Андрюха! Да чего же теперь будет? - Что надо, Арбузик, то и будет! - Мне бы Шиповника... - Какого еще Шиповника?",датасеты||диалоги
57,      Датасет для раскрытия анафоры в русскоязычном тексте  ," В репозитории  https://github.com/Koziev/NLP_Datasets/tree/master/Anacoref  выложен питоновский код, который обрабатывает датасет из соревнования  http://www.dialog-21.ru/evaluation/2014/anaphora/ . Результат работы этого скрипта имеет такой вид: 
 1 159 Кругом кругом R 
1 166  она  она P-3fsnn  одинокую дачу 
1 170 была быть Vmis-sfa-e 
1 175 обнесена обнесена Vmps-sfpsp 
1 184 высоким высокий Afpmsif 
1 192 забором забор Ncmsin 
 
 Местоимение "" она "" раскрывается в словосочетание "" одинокая дача "", которое есть где-то в предшествующем тексте. Я не стал пока делать пересогласование раскрытых ссылок, оставил это на второй этап. Вместе с датасетом из  соревнования AGRR-2019  (детектирование и раскрытие гэппинга) эти данные могут быть очень полезны для тренировки  чатбота , для модуля интерпретации (понимания) реплик собеседника в свободном стиле общения. Код моего решения для AGGR-2019 лежит в  отдельном репе",dataset||python||анафора||датасеты||чатбот
58,      На SNA Images застрял...  ," В разделе ""Картинки"" на  https://mlbootcamp.ru/round/18/tasks/  не могу подобрать хорошее расширяемое решение :(",mlbootcamp||соревнования
59,      Нейросетевое решение AGRR-2019  , Код с пояснениями для чисто нейросетевого решения задачи  https://github.com/dialogue-evaluation/AGRR-2019  выложен в репозитории  https://github.com/Koziev/AGRR-2019 Решение с BERT,crf||vector model||vector space model||word2vec||нейросети||соревнования
60,      дилемма с BERT в AGRR-2019   ," По результатам тестов классификатора предложений для  https://github.com/dialogue-evaluation/AGRR-2019 , возникла дилемма. С одной стороны, базовая нейросетевая модель выбивает на этой задаче более 90% точности при кросс-валидации. С другой стороны, крайне урезанная BERT (обучена на 100,000 парах предложений, урезана до 2 heads и другие усечения) плюс fine tuning дала почти 85%. По ощущениям, повысив сложность BERT хотя бы до 4 или 6 heads, можно поднять и точность последующей классификации. Но усеченная BERT обучалась на GTX 1080 Ti более суток. То есть любые улучшения потребуют несколько суток прогона. С другой стороны, эту обученную русскую BERT можно будет использовать и в других конкурсах. А до дедлайнов по AGRR осталось совсем немного. Вот и вопрос - стоит ли оно того, при наличных вычислительных ресурсах. PS (15-02-2019): Увеличил сложность BERT до 4х heads, переобучил на тех же 100,000 парах предложений.  Точность классификации предложений для задачи AGRR на кроссвалидации выросла до ~91%",bert||vector model||vector space model||нейросети||соревнования
61,"      Посимвольная генерация ответа в чатботе - иногда это похоже на детский лепет, реально  "," Просматриваю результаты валидации для нейросетевой модели генерации ответа  чатбота  по заданной предпосылке (факту) и вопросу. Что бросилось в глаза - много ошибок в ""детском стиле"", когда примерно подобран ритмический рисунок или чередование гласных и согласных ответа, причем длина слов передана достаточно правильно. Дети обычно так и говорят, когда еще не вполне овладели языковыми средствами, но вырабатываемое  миндалиной   ожидание негативных последствий ошибки  не выросло до блокирующего уровня. Кстати, касательно чередования гласных и согласных не грех вспомнить, что  марковские процессы  возникли 100 с лишним лет назад именно как результат изучения статистики чередования букв в Евгении Онегине, о чем есть даже небольшой абзац в вики: Сам Марков для иллюстрации своих результатов исследовал зависимость в чередовании гласных и согласных в первых главах «Евгения Онегина» и «Детских годов Багрова-внука» Далее - избранные результаты валидации с ошибками генерации. Premise - это найденная релевантная предпосылка, question - заданный вопрос, model answer - требуемый эталонный ответ, pred. answer - сгенерированный сеткой ответ: 
 --------------------------------------------------
premise      =тайский кот приглашает даму в гости
question     =в гости кто приглашает даму
model answer =тайский кот
pred. answer =лайский кот  <-- ERROR!
--------------------------------------------------
premise      =женя удивленно смотрит на тимура
question     =на кого женя смотрит
model answer =на тимура
pred. answer =на тюмура  <-- ERROR!
--------------------------------------------------
premise      =талантливый поэт создает правила
question     =создает правила какой поэт
model answer =талантливый
pred. answer =тачантиивый  <-- ERROR!
--------------------------------------------------
premise      =лесник мельком посмотрел на сына
question     =на кого мельком лесник посмотрел
model answer =на сына
pred. answer =на мына  <-- ERROR!
--------------------------------------------------
premise      =лицо викниксора налилось кровью
question     =налилось кровью что
model answer =лицо викниксора
pred. answer =лицо викликсора  <-- ERROR!
--------------------------------------------------
premise      =маленькие британцы ищут новую семью
question     =что маленькие британцы ищут
model answer =новую семью
pred. answer =говую демью  <-- ERROR!
--------------------------------------------------
premise      =девчонки ждут заботливых родителей
question     =девчонки кого ждут
model answer =заботливых родителей
pred. answer =заботливых ходителяй  <-- ERROR!
--------------------------------------------------
premise      =талантливый поэт создает правила
question     =создает какой поэт правила
model answer =талантливый
pred. answer =тавантиивый  <-- ERROR!
--------------------------------------------------
premise      =горынычи быстро двигались
question     =двигался кто быстро
model answer =горынычи
pred. answer =борыньчи  <-- ERROR!
--------------------------------------------------
premise      =в среду с утра был легкий морозец
question     =какая погода была в среду утром
model answer =легкий морозец
pred. answer =варкай морглор  <-- ERROR!
",генерация текста||забавные моменты||чатбот
62,      rupostagger - простой пакет для частеречной разметки русскоязычных предложений  ," Привел в порядок и выложил  пакет rupostagger  - простую (и не SOTA) реализацию алгоритма для разметки слов тегами. Пакет не делает ничего, кроме разметки, поэтому токенизацию надо делать самостоятельно. Я использую пакет под 2 и 3 веткой питона, под Windows и Linux. Батарейки (обученная русская языковая модель)  входят  в комплект, ничего самостоятельно обучать не надо. Также используется русская словарная база - отдельный  пакет ruword2tags , и  слогоделитель rusyllabs ,  они указаны в requirements.txt. После установки ( pip install git+ https://github.com/Koziev/rupostagger ) использовать так: import rupostagger  

 tagger = RuPosTagger()
tagger.load()
for word, label in tagger.tag(u'кошки спят'.split()):
 print(u'{} -> {}'.format(word, label)) Результат работы метода RuPosTagger.tag - список пар (слово, строка_с_тегами): 
 кошки -> NOUN|Case=Nom|Gender=Fem|Number=Plur
спят -> VERB|Mood=Ind|Number=Plur|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act Как видно, теги отделяются символом вертикальной черты. Каждый тег, кроме части речи, состоит из наименования тега и его значения, разделенные знаком =. Я не стал бить строку и выдавать питоновский список тегов, поскольку под капотом теггер получает именно строку, а накладные расходы на манипуляции со списками могут быть и не нужны. Например, если нужно проверить, что слово - существительное, тогда достатночно вызвать startswith('NOUN|'), и так далее. Набор тегов взят из  Universal Dependencies .",nlp||part-of-speech tagging||pos tagger||python||русский язык||частеречная разметка
63,      rusyllab - русский слогоделитель для замены SentencePiece  ," В субботу на скорую руку сделал на питоне конвертор моего старого набора правил деления на слоги из  проекта русского словаря . Результат работы конвертора -  код на питоне, оформленный в виде стандартного пакета rusyllab . Слогоделитель нужен для экспериментов с представлением текста на уровне между отдельными буквами и словами. Представление на уровне букв приводит к длинным цепочкам, которые не очень хорошо обрабатываются рекуррентными моделями. А представление на уровне слов дает слишком разреженные 1-hot матрицы, чтогодится не для всех адгоритмов машобучения. Компромисс возможен через деление слов на subword units. Классическая лингвистика предлагает в этом случае делить на морфемы. Но для русского языка это осложняется различными ""нелинейными"" эффектами между морфемами при их сочетании. Компромисс - деление на  слоги , которые в некоторых случаях хорошо отражают морфемную структуру и семантику. В пакете rusyllab включен простой greedy алгоритм, использующий вручную составленные правила. Во многих случаях он неплохо справляется со своей задачей. Кроме того, само по себе наличие ошибок слогоделения не влияет на работу downstream алгоритмов машобуча, поскольку эти ошибки детерминированы и повторяются консистентно при обработке тех же слов. Установка : 
 pip install git+https://github.com/Koziev/rusyllab
 Использование : 
 import rusyllab

sx = rusyllab.split_words(u""Голодная кошка ловит мышку"".split())
print('|'.join(sx))
 Результат работы : 
 Го|лод|на|я| |кош|ка| |ло|вит| |мыш|ку Функция rusyllab.split_words получает на входе список слов и возвращает список токенов. Каждый токен это либо слог, либо пробел для разделения слов. Таким образом, список токенов можно склеить обратно в почти исходное предложение. Для сравнения вот так выглядит разбивка через SentencePiece, обученный на большом русскоязычном корпусе (об этом см.  предыдущий пост ): 
 ▁|Г|о|ло|д|ная|▁ко|шка|▁лов|ит|▁мы|шку",nlp||python||sentencepiece||русский язык||слогоделитель
64,      Дислексия в чатботе с Трансформером  , Небольшой забавный момент с результатами работы модели Трансформера в чатботе ( предыдущий пост о модели ). Фрагмент листинга с целевыми (true) и сгенерированными (model) ответами на вопросы: true-> платье                        model->  платье платье true-> сторону цивилизации           model->готовредтелредизации цивилизации цивилизации цивиллейвиллейсателсателса двилтелектелектелекредтелредничек true-> няньки                        model-> няньнькинькиньняньня true-> отлично                       model->  отлично отлично true-> 23 часа 44 минуты             model-> 23мар 4мар4 минуты армия саммарская 4 часа 23 часатолны true-> балхаш                        model-> балхашашачахаха true-> другой                        model->  другой другой другой другой отчая другой другой другой другой настроение true-> на ребят                      model->  на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребят на ребята ребят true-> ученье                        model-> ученье ученье ученье у внимание true-> интереснейшие архитектурные памятники model-> интерес компьютершие архахскохрапные арнейжию дюканные тректельно банкуканекгаюшекунную семейекх,nlp||transformer||нейросети||чатбот
65,      Transformer и 30 тысяч сэмплов контекст-вопрос-ответ для русскоязычного чатбота  ," Пытаюсь оценить перспективность использования  keras-варианта Трансформера  для задачи генерации реплики русскоязычного чатбота на основе контекста и вопроса. Проверил разные варианты представления текста, в том числе отдельные слова и рекомендуемый авторами  SentencePiece . Параметры Трансформера варьировал в поисках оптимума, учитывая небольшой объем датасета - примерно 30 тысяч сэмплов. Результат пока -  негативный",nlp||question answering||transformer||нейросети||чатбот
66,      Как SentencePiece токенизирует русскоязычный текст  ,"  SentencePiece  - питоновская библиотека для unsupervised tokenization. Для японского и и китайского, видимо, является  очень хорошей альтернативой  токенизаторам с handcrafted rules (типа  MeCab , который и я когда-то использовал). А для английского языка дает в нейросетевых моделях (гугловский трансформер и BERT) такую приятную вещь, как заранее фиксированный размер словаря. А как выглядит результат токенизации для русскоязычного текста, учитывая темную сторону русского языка - слишком богатое словоизменение? Далее - краткие результаты эксперимента. 1.  Модель обучалась  на части моего 120Гб корпуса текстов. На 64 Гб оперативки удалось обучаться примерно на 40 млн предложений. Обучение выполнялось командой: spm_train --input=/home/inkoziev/Corpus/word2vecto r/ru/w2v.ru.corpus.txt --model_prefix=ru_raw --vocab_size=20000 --input_sentence_size=40000000 --character_coverage=1.0 --num_threads=8 --model_type=bpe Параметры подробно описаны на странице библиотеки, в частности размер словаря задается как  --vocab_size=20000, а  --model_type=bpe определяет алгоритм сегментации. 2.  Вывод результатов токенизации  делаю с помощью простого кода, который ожидает ввода разбираемого предложения с консоли:  
 import  sys
 import  sentencepiece  as  spm

sp = spm.SentencePieceProcessor()
rc = sp.Load( ""/home/inkoziev/github/sentencepiece/ru_raw.model"" )
 print ( 'SentencePiece model loaded with status={}' .format(rc))

 while True :
    text = raw_input( ':> ' ).decode(sys.stdout.encoding).strip().lower()
    px = sp.EncodeAsPieces(text)
     print ( '{} pieces:' .format( len (px)))
     for  i, p  in  enumerate (px):
         print ( u'{:<2d} {}' .format(i, p))
     print ( ' \n\n ' )
 3.  Результаты : :>  голодная черная кошка резво ловит серую мышку 15 pieces: 0  ▁голо 1  д 2  ная 3  ▁чер 4  ная 5  ▁ко 6  шка 7  ▁рез 8  во 9  ▁ло 10 вит 11 ▁сер 12 ую 13 ▁мы 14 шку :>  миша ест котлету 7 pieces: 0  ▁ми 1  ша 2  ▁е 3  ст 4   ▁кот 5  лет 6  у :>  голодный кот резво ловит мышку 9 pieces: 0  ▁голо 1  дный 2   ▁кот 3  ▁рез 4  во 5  ▁ло 6  вит 7  ▁мы 8  шку :>  тощий голодный кот жадно ест котлету 12 pieces: 0  ▁то 1  щий 2  ▁голо 3  дный 4   ▁кот 5  ▁жа 6  дно 7  ▁е 8  ст 9   ▁кот 10 лет 11 у Символ _ добавляется самой библиотекой вместо пробелов (об этом более подробно сказано в доке). Бросается в глаза вносимая такой токенизацией дополнительная ""полисемия"" токенов, например  _кот  является частью таких слов, как ""кот"" и ""котлета"". К сожалению, это еще немного снизит интерпретируемость моделей.",nlp||sentencepiece||unsupervised feature learning
67,      Тренировка BERT на русском корпусе: непривычно видеть такую кривую обучения  ," В порядке эксперимента обучаю упрощенную модель  BERT  (урезал число heads и т.д.) на свое русском корпусе. То, что обучается медленно - факт. Но дело не в этом. Вот как выглядят кривые loss (на обучающей выборке) и val_loss (на валидационной): Примерно так же продолжаются кривые до 100 эпох - это пока мой предел по времени. 50-100 эпох без видимого overfitting'а это как-то слишком чудесато... PS: На 134-й эпохе сработал early stopping после 5 неулучшений. Понятно, что если поставить patience=10, то наверняка обучение протянется еще. Сейчас кривая обучения приняла такой вид:",bert||language model||nlp||vector space model||нейросети
68,      Ачивку привезли  , ,
69,      Как будет выглядеть восстание машин на самом деле  ," На заметку любителям ""сингулярности"", поклонникам историй про скайнет и прочей ""science fiction"". Об этом Голливуд не снимет блокбастер, японцы не нарисуют мангу. Потому что такая правда незрелищна. И от этого будет еще обиднее, когда  ЭТО  начнется на самом деле. Сегодня имел удовольствие поймать в логах работы веб-сервиса, работающего с СУБД Oracle, ошибку с текстом (текст чесслово не мой, он такой из ораклового клиента прилетел в C# код): ORA-01460: затребовано нереализованное или неразумное преобразование",oracle||забавные мелочи||забавные моменты
70,      Влияние объема негативного сэмплинга для качество модели определения релевантности вопроса  ," В таблице показана зависимость метрик качества  модели определения релевантности предпосылки и вопроса на базе градиентного бустинга и bag-of-shingles  от количества добавляемых негативных пар. Параметр  n_negative_per_positive  определяет количество добавляемых при  подготовке датасета  негативных сэмплов на один позитивный. Метрика  f1  описывает качество на валидационной части датасета (F1 score). Намного более полезна метрика  eval_acc  - точность выбора предпосылки для вопроса среди множества альтернатив. Для этой метрики создан  отдельный небольшой датасет , содержащий неизвестные при обучении сэмплы. 
 n_negative_per_positive f1     eval_acc
1                       0.987  0.51
2                       0.985  0.64 
3                       0.984  0.61
4                       0.980  0.61
5                       0.983  0.63
10                      0.980  0.65
20                      0.976  0.68
50                      0.968  0.67
 Видны два тренда - f1 ухудшается, но метрика eval_acc улучшается, то есть модель все-таки становится лучше при работе с новыми данными в режиме ранжирования.",чатбот
71,      Слишком хороший f1 и roc-auc score в моделях релевантности/синонимичности с triple loss  ,"  1. Что выдает модель сама по себе Как работают эти модели? В качестве обучающих данных используются триады, содержащие опорное предложение, нерелевантное предложение и релевантное предложение. Для модели синонимичности эта тройка может выглядеть так: (anchor) кошка ловит мышку (positive) на мышку охотится кошка (negative) дети играют в кошки-мышки Функция потерь, в  исходниках  незатейливо названая triplet_loss, представляет из себя комбинацию из евклидова расстояния для пар векторов (anchor, positive) и (anchor, negative). Все делает модель - учится генерировать для предложений такие вектора, чтобы для пары (anchor, positive) расстояние было меньше, чем для (anchor, negative). Это можно сказать и так, что модель учится ранжировать группу из двух предложений. Выдываемые по ходу обучения значение функции потерь, к сожалению, малоинформативны. Не считая, само собой, того факта, что меньшее значение означает лучшее качество. Вот так примерно выглядит кривая обучения для  модели синонимичности  ( ссылка на тетрадку ): Нет никакой возможности понять, насколько хороша модель, которой при валидации выходит на уровень loss=0.1 или 0.01. Отсюда и желание выдать какую-то другую, более интерпретабельную, оценку точности. 2.  Расчет точности ранжирования в триплетах Сначала я сделал примитивный подсчет точности ранжирования в триплетах: 1) берем список сэмплов для валидации 2) прогоняем предложения через модель, получаем векторы для anchor, positive и negative 3) вычисляем расстояния между векторами для (anchor, positive) и (anchor, negative) 4) если |anchor-positive| < |anchor-negative|, то успех, иначе ошибка, соответственно увеличиваем счетчики успехов или ошибок 5) в конце просто выводим долю успешных п.4 среди всех сэмплов - получается некая оценка ошибки. Например, для модели детектора синонимов и перефразировок получается ~0.97...0.99 при повторных запусках. Уже понятнее. Но и такая оценка не позволяет напрямую понять, как модель будет работать в чатботе при выборе ближайшего предложения среди множества кандидатов. 2. AUC ROC метрика Пробуем изменить расчет. 1) рассматриваем пары (anchor, positive) как сэмплы с label=1, а пары (anchor, negative) как сэмплы с label=0 2) прогоняем пары предложений чез модель, получаем векторы предложений в паре, расчитываем косинус между векторами. Это будет оценка близости, находящаяся в диапазоне -1, 1. 3) выбираем значение порога threshold 4) если у пары предложений cosine получился больше порога, то считаем, что модель выдала label=1, иначе label=0 5) пройдя по всем парам, вычисляем recall и precision для текущего theshold. 6) повторяя для разных threshold, получаем таблицу - см. ниже. По сути, мы ""врукопашную"" реализуем  sklearn.metrics.precision_recall_curve . Получается примерно так: 
 threshold precision recall
0.0 0.497504634251 1.0
0.02 0.502491718277 0.999942676985
0.04 0.509328739525 0.999942676985
0.06 0.51750326332 0.999942676985
0.08 0.528383618078 0.99988535397
0.1 0.541982597887 0.999770707939
0.12 0.559537943206 0.999598738894
0.14 0.581169805032 0.999598738894
0.16 0.605900545575 0.999484092863
0.18 0.632836037606 0.999369446833
0.2 0.662006079027 0.998796216681
0.22 0.69438462152 0.998051017484
0.24 0.72767577063 0.997305818286
0.26 0.762410103491 0.996617942104
0.28 0.795255758575 0.9954714818
0.3 0.824806053972 0.993407853253
0.32 0.853550076585 0.990255087418
0.34 0.881037658616 0.987044998567
0.36 0.905146476643 0.982975064488
0.38 0.923923056082 0.977414732015
0.4 0.940383014155 0.971109200344
...     ...             ...
0.76 0.999497234791 0.455832616796
0.78 0.999442741711 0.411235310977
0.8 0.999536965581 0.371223846374
0.82 0.999479166667 0.330008598452
0.84 0.999607843137 0.292232731442
0.86 0.999776536313 0.256463169963
0.88 1.0 0.22562338779
0.9 1.0 0.196503296073
0.92 1.0 0.172714244769
0.94 1.0 0.152937804529
0.96 1.0 0.139065634852
0.98 1.0 0.131842934938
1.0 1.0 0.0290627687016
 Я не очень люблю roc auc метрику, так как она кмк плохо интерпретируются, но с помошью  sklearn.metrics.roc_curve  по вышеописанным расчетным значениям можно получить и нарисовать нечто такое: Если верить этим результатам, модель определения синонимичности работает невероятно точно. Площадь под ROC кривой, рассчитанная с помощью  sklearn.metrics.roc_auc_score , дает результат ~ 0.992 .",sklearn||нейросети||перефразировки
72,      Небольшое сравнение качества двух сетевых моделей определения синонимичности фраз  ," Модель №1 - нейросетка с triple loss  nn_synonymy_tripleloss.py Модель №2 - нейросетевой бинарный классификатор  nn_synonymy.py Модели обучаются на идентичном датасете, содержащем ~60 тысяч пар синонимичных предложений. При тестировании каждая модель ранжирует предложения из тестового списка по близости к вводимой строке. Выводится 10 ближайших предложений. Результаты для модели №1 
 
 phrase:>  к стоматологу меня запиши 
0.9565  запиши меня к стоматологу 
0.9242 запиши меня к окулисту
0.8771 запиши меня к врачу
0.8415 запиши меня к моему психотерапевту
0.8188 можно ли заплатить за изоленту наличными
0.8028 ты уже в четвертый перешла
0.7972 здраствуй
0.7620 ты ей письмо написал
0.7613 у тебя появилась кое какая информация
0.7599 аварийное освещеньице включи


phrase:>  вызови такси 
0.9018  вызвать такси 
0.8933 вызови скорую помощь
0.8870 вызови скорую
0.8366 скору вызови
0.8053 вызвать скорую
0.7687 запусти главный сервак
0.7684 зайти в лифт
0.7659 выполни отключение резервного сервака
0.7566 заставь работать главный сервак
0.7453 отключи резервный сервак


phrase:>  гороховый супчик разогрей 
0.9071  разогреть гороховый суп 
0.8623 разогреть пиццу
0.8588 разогреть щи
0.8492 сварить зеленый чай
0.8347 разогреть борщ
0.8195 сварить рисовую кашу
0.8116 сварить перловую кашу
0.8093 сварить кофе
0.8047 подогреть пиццу с грибами
0.8034 подогреть пиццу с колбасой

phrase:>  вызови, пожалуйста, скорую 
0.9211  вызови скорую 
0.8995 вызови скорую помощь
0.8754 вызвать скорую
0.8386 заставь работать главный сервак
0.8217 выключить фоновую музыку
0.8207 заказать пиццу с анчоусами
0.8161 скору вызови
0.8134 включить спокойную фоновую музыку
0.8112 хочешь заказать две пиццы
0.8095 заставь неисправный сервак выключиться

phrase:>  будь добр, свет в коридоре включи 
0.9116  включить свет в коридоре 
0.8949 включить свет в туалете
0.8888 включить свет в ванной
0.8836 выключить свет в коридоре
0.8658 выключить свет в туалете
0.8610 выключить свет в ванной
0.8509 идти в оранжерею
0.8452 войди в лифт
0.8424 иди в оранжерею
0.8387 проверь заряд батареи в ноутбуке

phrase:>  зеленого чаю завари мне 
0.9226  сварить зеленый чай 
0.8964 сварить рисовую кашу
0.8813 сварить перловую кашу
0.8735 сварить манную кашу
0.8608 еда в школе вкусная
0.8571 тебе хочется заказать две пиццы
0.8562 заказать пиццу с анчоусами
0.8515 разогреть гороховый суп
0.8510 разогреть щи
0.8497 сварить геркулесовую кашу

phrase:>  рисовую кашку мне сделай 
0.9431  сварить рисовую кашу 
0.9268 сварить перловую кашу
0.9161 сварить манную кашу
0.8988 приготовить рисовую кашу
0.8966 сварить геркулесовую кашу
0.8708 сварить зеленый чай
0.8578 тебе хочется заказать две пиццы
0.8524 заказать пиццу с анчоусами
0.8511 сварить кофе
0.8386 разогреть пиццу

phrase:>  в лифт пожалуйста войди 
0.9434  в лифт войди 
0.9176 войди в лифт
0.8797 в лифт зайди
0.8720 включить свет в коридоре
0.8601 включить свет в туалете
0.8585 идти в оранжерею
0.8406 включить свет в ванной
0.8379 дверку в коридор открой
0.8326 открыть дверку в коридор
0.8282 выключить свет в коридоре

phrase:>  в оранжерею топай 
0.9083  иди в оранжерею 
0.9020 идти в оранжерею
0.8959 в оранжерею иди
0.8852 пройди в оранжерею
0.8561 в лифт войди
0.8553 войди в лифт
0.8470 дверку в коридор открой
0.8279 открой дверь в коридор
0.8229 зайди в помещение лифта
0.8186 открыть дверку в коридор


phrase:>  завари мне черный чай 
0.9664 сварить зеленый чай
0.9040 сварить рисовую кашу
0.9034 сварить перловую кашу
0.9032 тебе хочется заказать две пиццы
0.8752  приготовить крепкий черный чай 
0.8719 сварить манную кашу
0.8603 сварить геркулесовую кашу
0.8580 приготовить рисовую кашу
0.8574 хочешь заказать две пиццы
0.8526 сварить кофе


phrase:>  свари мне кофе 
0.9117  сварить кофе 
0.8791 сварить манную кашу
0.8523 сварить рисовую кашу
0.8462 заказать пиццу с анчоусами
0.8458 сварить перловую кашу
0.8414 тебе хочется заказать две пиццы
0.8390 у тебя горло болит
0.8288 тебе 5 лет
0.8246 тебе 6 лет
0.8234 сварить зеленый чай

phrase:>  включи спокойную музыку 
0.9257  включить спокойную фоновую музыку 
0.8250 включи аварийное освещение
0.8141 включи главный серверок
0.8130 выключить фоновую музыку
0.7922 включи главный сервак
0.7884 а давай поиграем
0.7858 а давай сыграем
0.7789 давай поиграем
0.7729 вызвать скорую
0.7674 открой входную дверь

phrase:>  имя свое назови 
0.9736  назови свое имя 
0.7917 ты ведь говорил мне
0.7857 ты уже это говорил
0.7842 мы с тобой не знакомы
0.7813 ты же нам говорил
0.7803 ты нас кое чему научишь
0.7727 ты ей письмо написал
0.7650 ты ж нам говорила
0.7644 и ты его выучил
0.7628 ты уже мне говорил


phrase:>  шагни вперед 
0.8491 поверни вправо
0.8304 сделать два шага вперед
0.8281 войди в лифт
0.8259 поверни влево
0.8145 включить свет в коридоре
0.8091  сделать один шаг вперед 
0.8060 включи главный серверок
0.8054 в лифт войди
0.8043 запусти главный сервер
0.7960 включить свет в ванной


С ОПЕЧАТКАМИ:

phrase:>  в аранжирею топай 
Word аранжирею missing in wordchar2vector model
0.8560  в оранжерею отправляйся 
0.8413 ты уже в четвертый перешла
0.8340 запиши меня к окулисту
0.8333 в лифт войди
0.8308 ты ходишь в школу
0.8269 в лифт зайди
0.8260 помрешь ты от голода
0.8249 ты кушаешь в школе
0.8176 запиши меня к стоматологу
0.8144 включить свет в туалете

phrase:>  в каридоре свет включи 
Word каридоре missing in wordchar2vector model
0.9148 включить свет в туалете
0.9031  включить свет в коридоре 
0.9030 выключить свет в туалете
0.8886 выключить свет в коридоре
0.8792 включить свет в ванной
0.8629 выключить свет в ванной
0.8555 войди в лифт
0.8464 в лифт войди
0.8454 проверь заряд батареи в ноутбуке
0.8430 включи резервный генератор
 Результаты для модели №2 
 phrase:>  к стоматологу меня запиши 
0.9997 запиши меня к моему психотерапевту
0.9997 ты немного неточно написала
0.9991 ты приготовил вам сюрприз
0.9989 ты просишь прощения за кучу вопросов
0.9976 а ты будешь капитаном
0.9973  запиши меня к стоматологу 
0.9972 ты обязательно мне перезвонишь
0.9960 тебе не нравится читать книги
0.9954 ты не любишь книги читать
0.9936 ты с радостью ответишь на все ваши вопросы

phrase:>  вызови такси 
0.9990  вызвать такси 
0.9978 зайди в лифт
0.9943 в лифт зайди
0.9903 зайти в лифт
0.9793 войди в лифт
0.9262 зайди в помещение лифта
0.9209 войти в лифт
0.8931 доложи про обстановку на базе
0.8647 что происходит на первой палубе
0.7210 расскажи об обстановке на базе


phrase:>  гороховый супчик разогрей 
0.9997  разогреть гороховый суп 
0.9992 сварить рисовую кашу
0.9987 разогреть пиццу
0.9974 сварить кофе
0.9973 подогреть пиццу с грибами
0.9972 приготовить рисовую кашу
0.9874 сварить зеленый чай
0.9824 тебе хочется заказать две пиццы
0.9798 подогреть пиццу с колбасой
0.9596 сварить перловую кашу

phrase:>  вызови, пожалуйста, скорую 
0.9988  скору вызови 
0.9985 а давай сыграем
0.9980 вызови скорую
0.9974 проверить баланс телефона
0.9971 давай поиграем
0.9971 а давай поиграем
0.9968 доложи про обстановку на базе
0.9968 отменить входящий звонок
0.9966 вызови скорую помощь
0.9935 давай поиграем в шашки

phrase:>  будь добр, свет в коридоре включи 
0.9984 ты села на табуретку
0.9967 включить свет в ванной
0.9914 разогреть пиццу
0.9911 выключить свет в ванной
0.9899 включить свет на кухне
0.9870 включить свет в туалете
0.9857 выключить свет в туалете
0.9836 тебе хочется заказать две пиццы
0.9796 выключить свет на кухне
0.9712  включить свет в коридоре 

phrase:>  зеленого чаю завари мне 
0.9999 приготовить крепкий черный чай
0.9998  сварить зеленый чай 
0.9969 подогреть пиццу с колбасой
0.9839 разогреть щи
0.9800 разогреть пиццу
0.9565 найти рецепт приготовления грибного супа
0.9479 заказать пиццу с анчоусами
0.9308 ты со сметанкой любишь
0.8939 сварить геркулесовую кашу
0.8789 разогреть гороховый суп


phrase:>  рисовую кашку мне сделай 
0.9977 ты кофе любишь
0.9970 ты макароны любишь
0.9944 разогреть щи
0.9938 ты хочешь пиццу
0.9907 ты жирное любишь
0.9894 сварить манную кашу
0.9870 сегодня ты вымоешь посуду
0.9863 пиццу ты очень любишь
0.9826 ты мяско любишь
0.9764 ты очень любишь квас

phrase:>  в лифт пожалуйста войди 
0.9991  зайти в лифт 
0.9988 войди в лифт
0.9987 зайди в лифт
0.9976 войти в лифт
0.9970 в лифт зайди
0.9951 дверку в коридор открой
0.9923 включить свет в коридоре
0.9914 выполни вход в лифт
0.9914 в лифт войди
0.9907 включить свет в туалете


phrase:>  в оранжерею топай 
0.9991  пройди в оранжерею 
0.9979 иди в оранжерею
0.9978 идти в оранжерею
0.9939 в оранжерею отправляйся
0.9915 ты достанешь пять бутылок
0.9906 в оранжерею иди
0.9867 можно ли отравится синей изолентой
0.8853 сколько стоит рулон изоленты
0.7908 приготовить рисовую кашу
0.6792 где изготавливается синяя изолента


phrase:>  завари мне черный чай 
1.0000  приготовить крепкий черный чай 
1.0000 сварить зеленый чай
0.9999 подогреть пиццу с колбасой
0.9969 заказать пиццу с анчоусами
0.9963 найти рецепт приготовления овощного рагу
0.9922 разогреть пиццу
0.9913 найти рецепт приготовления грибного супа
0.9808 подогреть пиццу с грибами
0.9747 ты со сметанкой любишь
0.8690 сварить кофе

phrase:>  свари мне кофе 
0.9999  сварить кофе 
0.9997 разогреть пиццу
0.9983 тебе хочется заказать две пиццы
0.9967 хочешь заказать две пиццы
0.9944 разогреть щи
0.8929 приготовить крепкий черный чай
0.8003 ты кофе любишь
0.6969 сварить зеленый чай
0.5370 подогреть пиццу с колбасой
0.4409 ты хочешь пиццу

phrase:>  включи спокойную музыку 
0.9975 ты измерила их ширину
0.9883  включить спокойную фоновую музыку 
0.9843 ты очень любишь гвозди
0.9842 ты хочешь волшебную палочку
0.9818 ты просто обожаешь лыжи
0.9747 ты хорошо плаваешь
0.9716 учушься ты прилично без троек
0.9700 ты любишь пасмурную погоду
0.9650 ты любишь движение
0.9520 ты неплохо водишь машину

phrase:>  имя свое назови 
0.9999  назови свое имя 
0.9994 ты помнишь об этом
0.9991 сейчас ты нам расскажешь
0.9985 ты ответишь на ваш вопрос
0.9974 сейчас ты мне расскажешь
0.9966 как тебя зовут
0.9965 сейчас ты нам объяснишь
0.9959 сейчас ты объяснишь все
0.9955 ты на урок опоздаешь
0.9948 это ты сказал себе

phrase:>  шагни вперед 
0.9925  сделать один шаг вперед 
0.9803 сделать два шага вперед
0.8831 поверни влево
0.8749 поворот влево
0.8540 остановись
0.8445 подождать одну минуту
0.5059 ты боишься уколов
0.4220 ты окончательно запуталась
0.4209 вызвать скорую
0.3793 подождать две минуты

phrase:>  в аранжирею топай 
Word аранжирею missing in wordchar2vector model
0.9991 спать хочешь
0.9885 хочешь спать
0.9850 скору вызови
0.9819 в лифт войди
0.9646 вызвать скорую
0.9508 вызови скорую
0.9389 а давай сыграем
0.9150 а давай поиграем
0.8921 что творится на базе
0.8795 войди в лифт

phrase:>  в каридоре свет включи 
Word каридоре missing in wordchar2vector model
0.9763 сколько стоит рулон изоленты
0.9706 открой дверь в коридор
0.9569 дверку в коридор открой
0.9481 открыть дверь в коридор
0.9316 ты села на табуретку
0.9026 идти в оранжерею
0.8755 можно ли отравится синей изолентой
0.8609 открыть дверку в коридор
0.8202 выполни вход в лифт
0.8079 зайди в помещение лифта
",neural nets||vector model||vector space model||нейросети||перефразировки
73,      Сравнение i7-4790K + NVidia GTX 980 vs i7-9700K + NVidia GTX 1080 Ti на нейросетевой задаче  ," В отличие от тестов на  userbenchmark.com  сравнивнение сделано на реальной практической задаче  nn_wordcopy3.py . Предметная область - NLP. Данные для обучения одинаковые. Программное окружение в обоих случаях практически идентично - Ubuntu, Python 2, текущие версии tensorflow, CUDA 9.0. В обоих случаях видно, что все ядра CPU загружены, хотя и не полностью. Формально оба CPU держат 8 потоков, но у i7-9700 это 8 реальных ядер, а у i7-4790 4 ядра с гипертредингом. Но основная нагрузка лежит на GPU. Машина №1 i 7-4790K, 32 Гб памяти DDR3, NVidia GTX 980, материнская плата MSI H97 GAMING . Детальная инфа (выдача sudo lshw и nvidia-smi): 
     product: MS-7918 (To be filled by O.E.M.)
    vendor: MSI
    version: 1.0
    serial: To be filled by O.E.M.
    width: 64 bits
    capabilities: smbios-2.8 dmi-2.7 vsyscall32
    configuration: administrator_password=disabled boot=normal chassis=desktop family=To be filled by O.E.M. frontpanel_password=disabled keyboard_password=disabled power-on_password=disabled sku=To be filled by O.E.M. uuid=00000000-0000-0000-0000-D8CB8A6FE07A
  *-core
       description: Motherboard
       product: H97 GAMING 3 (MS-7918)
       vendor: MSI
       physical id: 0
       version: 1.0
       serial: To be filled by O.E.M.
       slot: To be filled by O.E.M.
     *-firmware
          description: BIOS
          vendor: American Megatrends Inc.
          physical id: 0
          version: V1.7
          date: 12/24/2014
          size: 64KiB
          capacity: 15MiB
          capabilities: pci upgrade shadowing cdboot bootselect socketedrom edd int13floppy1200 int13floppy720 int13floppy2880 int5printscreen int9keyboard int14serial int17printer acpi usb biosbootspecification uefi
     *-cpu
          description: CPU
          product: Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz
          vendor: Intel Corp.
          physical id: 3d
          bus info: cpu@0
          version: Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz
          slot: SOCKET 0
          size: 4155MHz
          capacity: 4400MHz
          width: 64 bits
          clock: 100MHz
          capabilities: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts flush_l1d cpufreq
          configuration: cores=4 enabledcores=4 threads=8
        *-cache:0
             description: L1 cache
             physical id: 3e
             slot: CPU Internal L1
             size: 256KiB
             capacity: 256KiB
             capabilities: synchronous internal write-back
             configuration: level=1
        *-cache:1
             description: L2 cache
             physical id: 3f
             slot: CPU Internal L2
             size: 1MiB
             capacity: 1MiB
             capabilities: synchronous internal write-back unified
             configuration: level=2
        *-cache:2
             description: L3 cache
             physical id: 40
             slot: CPU Internal L3
             size: 8MiB
             capacity: 8MiB
             capabilities: synchronous internal write-back unified
             configuration: level=3
     *-memory
          description: System Memory
          physical id: 42
          slot: System board or motherboard
          size: 32GiB
        *-bank:0
             description: DIMM DDR3 Synchronous 1600 MHz (0,6 ns)
             product: DDR3 1600 2OZ
             vendor: Fujitsu
             physical id: 0
             serial: 0000C437
             slot: ChannelA-DIMM0
             size: 8GiB
             width: 64 bits
             clock: 1600MHz (0.6ns)
        *-bank:1
             description: DIMM DDR3 Synchronous 1600 MHz (0,6 ns)
             product: DDR3 1600 2OZ
             vendor: Fujitsu
             physical id: 1
             serial: 0000C447
             slot: ChannelA-DIMM1
             size: 8GiB
             width: 64 bits
             clock: 1600MHz (0.6ns)
        *-bank:2
             description: DIMM DDR3 Synchronous 1600 MHz (0,6 ns)
             product: DDR3 1600G 2OZ
             vendor: Fujitsu
             physical id: 2
             serial: 00002C4E
             slot: ChannelB-DIMM0
             size: 8GiB
             width: 64 bits
             clock: 1600MHz (0.6ns)
        *-bank:3
             description: DIMM DDR3 Synchronous 1600 MHz (0,6 ns)
             product: DDR3 1600G 2OZ
             vendor: Fujitsu
             physical id: 3
             serial: 00002C7C
             slot: ChannelB-DIMM1
             size: 8GiB
             width: 64 bits
             clock: 1600MHz (0.6ns)


+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.130                Driver Version: 384.130                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 980     Off  | 00000000:01:00.0 Off |                  N/A |
| 34%   61C    P2    82W / 195W |   3869MiB /  4038MiB |     89%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1235      G   /usr/lib/xorg/Xorg                           105MiB |
|    0      1683      G   compiz                                        37MiB |
|    0      2437      C   python                                      3713MiB |
+-----------------------------------------------------------------------------+
 Машина №2  i7-9700K ,  64 Гб памяти DDR4 ,  NVidia GTX 1080 Ti , материнская плата  MSI Z390 CARBON GAMING Выдача sudo lshw и nvidia-smi: 
     продукт: MS-7B17 (Default string)
    производитель: Micro-Star International Co., Ltd.
    версия: 1.0
    серийный №: Default string
    разрядность: 64 bits
    возможности: smbios-2.8 dmi-2.8 smp vsyscall32
    конфигурация: boot=normal chassis=desktop family=Default string sku=Default string uuid=00000000-0000-0000-0000-00D8611296B4
  *-core
       описание: Материнская плата
       продукт: MPG Z390 GAMING PRO CARBON (MS-7B17)
       производитель: Micro-Star International Co., Ltd.
       физический ID: 0
       версия: 1.0
       серийный №: IA16401559
       слот: Default string
     *-firmware
          описание: BIOS
          производитель: American Megatrends Inc.
          физический ID: 0
          версия: 1.00
          date: 09/03/2018
          размер: 64KiB
          capacity: 15MiB
          возможности: pci upgrade shadowing cdboot bootselect socketedrom edd int13floppy1200 int13floppy720 int13floppy2880 int5printscreen int9keyboard int14serial int17printer acpi usb biosbootspecification uefi
     *-memory
          описание: Системная память
          физический ID: 39
          слот: Системная плата или материнская плата
          размер: 64GiB
        *-bank:0
             описание: DIMM DDR4 Синхронная 2133 MHz (0,5 ns)
             продукт: CMU64GX4M4C3000C15
             производитель: AMI
             физический ID: 0
             серийный №: 00000000
             слот: ChannelA-DIMM0
             размер: 16GiB
             разрядность: 64 bits
             частота: 2133MHz (0.5ns)
        *-bank:1
             описание: DIMM DDR4 Синхронная 2133 MHz (0,5 ns)
             продукт: CMU64GX4M4C3000C15
             производитель: AMI
             физический ID: 1
             серийный №: 00000000
             слот: ChannelA-DIMM1
             размер: 16GiB
             разрядность: 64 bits
             частота: 2133MHz (0.5ns)
        *-bank:2
             описание: DIMM DDR4 Синхронная 2133 MHz (0,5 ns)
             продукт: CMU64GX4M4C3000C15
             производитель: AMI
             физический ID: 2
             серийный №: 00000000
             слот: ChannelB-DIMM0
             размер: 16GiB
             разрядность: 64 bits
             частота: 2133MHz (0.5ns)
        *-bank:3
             описание: DIMM DDR4 Синхронная 2133 MHz (0,5 ns)
             продукт: CMU64GX4M4C3000C15
             производитель: AMI
             физический ID: 3
             серийный №: 00000000
             слот: ChannelB-DIMM1
             размер: 16GiB
             разрядность: 64 bits
             частота: 2133MHz (0.5ns)
     *-cache:0
          описание: L1 кэш
          физический ID: 43
          слот: L1 Cache
          размер: 512KiB
          capacity: 512KiB
          возможности: synchronous internal write-back unified
          конфигурация: level=1
     *-cache:1
          описание: L2 кэш
          физический ID: 44
          слот: L2 Cache
          размер: 2MiB
          capacity: 2MiB
          возможности: synchronous internal write-back unified
          конфигурация: level=2
     *-cache:2
          описание: L3 кэш
          физический ID: 45
          слот: L3 Cache
          размер: 12MiB
          capacity: 12MiB
          возможности: synchronous internal write-back unified
          конфигурация: level=3
     *-cpu
          описание: ЦПУ
          продукт: Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz
          производитель: Intel Corp.
          физический ID: 46
          сведения о шине: cpu@0
          версия: Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz
          серийный №: To Be Filled By O.E.M.
          слот: U3E1
          размер: 4600MHz
          capacity: 4900MHz
          разрядность: 64 bits
          частота: 100MHz
          возможности: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d arch_capabilities cpufreq
          конфигурация: cores=8 enabledcores=8 threads=8


GPU:

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:01:00.0 Off |                  N/A |
| 34%   63C    P2   128W / 280W |  10806MiB / 11178MiB |     79%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1865      G   /usr/lib/xorg/Xorg                           226MiB |
|    0      2078      G   /usr/bin/gnome-shell                         196MiB |
|    0      2435      G   /proc/self/exe                                70MiB |
|    0      3013      G   /opt/teamviewer/tv_bin/TeamViewer             24MiB |
|    0      3641      G   /usr/lib/firefox/firefox                       2MiB |
|    0      8516      C   python                                     10281MiB |
+-----------------------------------------------------------------------------+

 
 В итоге, на первой машине одна эпоха обучения занимает ~27 секунд. На второй машине ~7 секунд. То есть вторая машина  почти в 4 раза быстрее",benchmark||gtx 1080||nlp||nvidia
74,      Реализация линейной регрессии МНК с autograd - библиотекой для символического дифференцирования  ," Случайно наткнулся недавно на  Autograd  - питоновскую либу, которая умеет для функции, заданной исходным текстом в коде, получить функцию же частной производной по указанному аргументу. Всякие tensorflow, pytorch и theano это, конечно, тоже делают под капотом. Но autograd делает это с любой питоновской функцией. Магия. Я не смог удержаться от небольшого эксперимента с написанием реализации метода наименьших квадратов для линейной регрессии. Код берет набор пар (x,y), примерно соответствующих некоторой прямой линии (см. calc_y).  Функция loss - это целевая функция для МНК. Именно ее autograd дифференцирует по каждому из аргументов a и b. Далее - грязная реализация градиентного спуска. Код на гитхабе Второй вариант сделан из какого-то примера для autograd, и позволяет достаточно безболезненно увеличивать порядок полинома: Код на гитхабе Ну и для сравнения - решение линейной регрессии МНК на Keras: Код на гитхабе",autograd||python||регрессия||численные методы
75,      Императивный режим общения с чатботом  ," После некоторых расширений  вопросно-ответного движка  появилась возможность строить диалоги в таком духе: Ему, конечно, еще далеко до полноценного  дом-бота  (не путать с  дон-ботом !), к тому же иногда движок ведет себя как  килбот . Но пока все это работает совершенно без использования грамматического словаря, исключительно на сочетании  нейросетевых моделей  и word2vec представлений.",chatbot||neural nets||vector model||vector space model||чат-боты||чатбот
76,      Чатбот в игре: начало диалога с первым персонажем  ," У  бота  немного не хватает плавности диалога и проактивности. Плюс у меня есть большие претензии к реализации модели релевантности, да и к остальным моделям тоже. Сеттинг - игрок обнаруживает себя в закрытом помещении в незнакомом месте и начинает выяснять обстановку через диалог с ботом. Отладочный диалог: 
 H:> где я нахожусь?
B:> ты находишься на лунной научной базе

H:> кто я?
B:> ты доктор Верховцев

H:> что я должен сделать?
B:> ты должен включить главный сервер

H:> где главный сервер?
B:> главный сервер находится в серверной

H:> главный сервер сейчас включен?
B:> главный сервер сейчас обесточен

H:> серверная открыта?
B:> Дверь в серверную закрыта на ключ

H:> кто может войти в серверную?
B:> Рембот стоит у входа в серверную

H:> что такое рембот?
B:> рембот - автономный ремонтный робот

H:> я могу давать команды ремботу?
B:> ты можешь отдавать команды ремботу

H:> кто ты?
B:> я - твой киберассистент
 
",игроботы||чат-боты||чатбот
77,      redmine2code  ," Вот давно есть проектик  pix2code  -  Generating Code from a Graphical User Interface Screenshot. Но еще очень нужен  redmine2code . Чтобы из редмайна (или с другого трекера, не суть) бралась очередная таска, парсилась, и генерился патч к коду, либо прототип нового функционала. Потом компиляция, прогон тестов, комит. Обучать на своем же коде, или на данных из всего корпоративного трекера.",
78,      Condition random fields + word2vec + wordchar2vec для частеречной разметки без feature engineering'а  ," Ингридиенты: 1)  CRFSuite ,  реализующий старый и добрый linear chain CRF 2) размеченный корпус для русского языка (например из  Universal Dependencies ) 3) набор векторов word2vec (я использую, как всегда,  gensim , обучаемый на корпусе в ~150 Гб текстов разного характера, вплоть до блогов) 4) обученную модель  wordchar2vec Далее формируем обучающий корпус, используя компоненты векторов w2v и wc2v в качестве весов фич для CRF. Отрицательные и положительные значения компонентов бьем на отдельные фичи. Обучаем и получаем при валидации точность  около 95% на токен  для русского языка. Это при том, что тегами являются для значимых частей речи сочетания собственно части и речи и набора морфологических признаков. Никакого feature engineering'а, никаких сложных процедур выявления признаков слов. Для иллюстрации - фрагмент листинга с результатами валидации, видты эталонные метки (true=) и то, что выдает модель (pred=): 
 все                  true=PRON                                               pred=PRON
шло                  true=VERB|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act pred=VERB|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act
совсем               true=ADV                                                pred=ADV
не                   true=PART                                               pred=PART
так                  true=ADV                                                pred=ADV
,                    true=PUNCT                                              pred=PUNCT
как                  true=CONJ                                               pred=CONJ
хотелось             true=VERB|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid pred=VERB|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid
бы                   true=PART                                               pred=PART
.                    true=PUNCT                                              pred=PUNCT


электростанцию       true=NOUN|Case=Acc|Gender=Fem|Number=Sing               pred=NOUN|Case=Acc|Gender=Fem|Number=Sing
пустили              true=VERB|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act pred=VERB|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act
,                    true=PUNCT                                              pred=PUNCT
и                    true=CONJ                                               pred=CONJ
побережье            true=NOUN|Case=Nom|Gender=Neut|Number=Sing              pred=NOUN|Case=Loc|Gender=Neut|Number=Sing <-- ERROR
,                    true=PUNCT                                              pred=PUNCT
веками               true=NOUN|Case=Ins|Gender=Neut|Number=Plur              pred=NOUN|Case=Ins|Gender=Neut|Number=Plur
не                   true=PART                                               pred=PART
видевшее             true=ADJ|Case=Nom|Degree=Pos|Gender=Neut|Number=Sing    pred=ADJ|Case=Nom|Degree=Pos|Gender=Neut|Number=Sing
ничего               true=PRON                                               pred=PRON
подобного            true=ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing    pred=ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing
,                    true=PUNCT                                              pred=PUNCT
будто                true=PART                                               pred=CONJ <-- ERROR
переродилось         true=VERB|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid pred=VERB|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid
заново               true=ADV                                                pred=ADV
.                    true=PUNCT                                              pred=PUNCT
 Исходник черновой реализации тренера:  https://github.com/Koziev/chatbot/blob/master/PyModels/postagger/train_postagger.py",character language model||crf||crfsuite||gensim||pos tagger||vector model||vector space model||word2vec||частеречная разметка
79,      Leveraging Random Label Memorization for Unsupervised Pre-Training (оверфиттинг как благо)  ,"  Идея Статья от 05.11.2018 ( https://arxiv.org/pdf/1811.01640.pdf ) описывает способ предварительной тренировки сеток на неразмеченных данных (формально в supervised режиме с рандомно перемешанными целевыми значениями). Идея простая - заставить нейросеть запомнить случайно присвоенные метки. Чтобы такой агрессивный overfitting удался, сетка должна выявить статистически устойчивые паттерны во входных данных. После этого можно обучать сетку уже по нормальному датасету, пользуясь тем, что низкоуровневые фичи уже выявлены и веса первых слоев сетки сформированы. Способ выглядит очень дешевым, так как можно взять произвольное количество текстов (если речь про NLP), не обременяя себя точной разметкой. Кроме того, модификация сещуствующих тренеров для моделей должна быть простой, так как способ не затрагивает архитектуру сетки. Это скорее  дидактический  лайфхак. Проверка Разумеется, никакие общие рассуждения не заменят практическую проверку. Поэтому надо взять какую-то модель и попробовать на ней. Я в последнее время очень плотно увяз в  distance metric learning  для проверки релевантности вопросов и предпосылок для  вопросно-ответной системы , поэтому решил проверить сначала на модели  nn_relevancy_tripleloss.py . Подробности по этой модели есть тут  https://kelijah.livejournal.com/245759.html . Суть модели в том, что формируемые ею векторы должны быть близки (в формальном, математическом смысле) для релевантных вопросов и предпосылок, и далеки для нерелевантных. Неприятная сторона модели заключается в том, что на имеющемся датасете (несколько десятков тысяч пар релевантных вопросов и документов) сетка учится очень неустойчиво. Даже для самой простой архитектуры с минимальным количеством параметров достигаемая точность при финальной валидации меняется на многие проценты, при особом везении до 15%. Чтобы сделать pretrain, берем весь обучающий набор троек (anchor, positive, negative). Распиливаем на составляющие, и генерируем рандомные тройки в практически неограниченном количестве. Обучение на таком датасете с шумом вместо расстояний показывает на первых десяти-двадцати эпохах уменьшение loss'а, то есть сетка действительно пытается запоминать шум. В статье из описания можно понять, что авторы случайно меняют метки после каждой эпохи pretrain'а. Я срезал этот угол, генерируя весь рандомный датасет заранее - см.  со строки 391 . После нескольких эпох предобучения сетка тренируется по реальному датасету. Таким образом, влияние pretrain'а заключается в том, что вместо исходных рандомных весов обучение начинается в подогнанном под реальные сэмплы ландшафте. К сожалению, серия экспериментов  не продемонстрировала какого-либо положительного эффекта  от предтренировки для данной конкретной архитектуры и задачи. Ссылки на материалы Leveraging Random Label Memorization for Unsupervised Pre-Training Deep Semantic Similarity Model FaceNet: A Unified Embedding for Face Recognition and Clustering Lossless triplet loss Similarity learning",neural nets||sent2vec||triple loss||vector space model
80,      Динамическое создание атрибутов - штатная фича Питона и малоизвестная фича C#  ," Любой, кто начинает изучать Питон, быстро узнает такую фичу языка, как создание нового атрибута объекта в результате присваивания: 
 class  Class1( object ):  pass
 o = Class1()
o.attr1 =  '1234'
 print (o.attr1)
 В строке 3 у объекта o добавляется новый атрибут, строка '1234'. Удобно, элегантно и позволяет выстрелить себе в ногу, если дрогнет рука. Кстати, обойтись вместо пользовательского класса Class1 штатным object в этом сценарии не получится по той причине, что у экземпляров класса object нет  атрибута __dict__ , который и позволяет динамическое добавление атрибутов. Для шарпистов (про плюсы вообще умолчим) вышеописанное может выглядеть немного пугающе. Но ирония в том, что в C# есть свой штатный, документированный и удобный способ добавления атрибутов (полей или даже методов) для объекта класса, причем без чернокнижной рефлексии. Правда, не любого класса, а  ExpandoObject : 
dynamic o  =   new  System . Dynamic . ExpandoObject ( ) ; 
o . attr1  =   "" 1234 "" ; 
Console . Write ( "" {0} "" ,  o . attr1 ) ; 
 В строке 3 происходит то же самое, что в питоновском коде - в экземпляр o добавляется новый член класса, строковое поле.",c||python||забавные мелочи
81,      неудачная попытка использовать либу NNSharp для запуска Keras-модели в C#  ," Репозиторий проекта:  https://github.com/adamtiger/NNSharp Файлы со скриптом тренировки простейшей рекуррентной модели на Keras и использование в C#:  https://gist.github.com/Koziev/ce781f1acd9df0bb34a7e5d89411bb1e Сразу надо сказать, что входящий в NNSharp скрипт  KerasModeltoJSON.py  может работать только с так называемыми  sequential моделями Keras . Более удобные и функционально более гибкие  functional модели  вызывают ошибку в строке 29, когда делается попытка получить размеры данных на первом слое. У functional моделей может быть несколько входов, поэтому этот подход не работает. Тем не менее, я сделал простейшую sequential модель, которая вычисляет сумму 10 случайных чисел от 0 до 10. И в C# мне не удалось получить адекватные результаты. В частности, сумма десяти нулей дает результат, существенно отличающийся от выдачи самой Keras модели после обучения.",c||keras||python
82,      Неудачные эксперименты с triple и contrastive loss архитектурами для определения перефразировок  ,"  1. Постановка задачи Нужна модель, которая определяет, эквивалентны ли два фрагмента текста (предложения) семантически.Правила синтаксиса и морфологии допускают очень большую свободу выражения латентной семантики, поэтому простая похожесть цепочек символов недостаточно хороша для некоторых случаев: Автора денно и нощно охраняют усиленные полицейские наряды. Автор находится под круглосуточной охраной усиленных полицейских нарядов Актер потерял сознание прямо на сцене. Прямо на сцене у актера случился обморок 2. Материалы на тему того, что такое  triple loss  и  distance metric learning . ""Distance Metric Learning for Large Margin Nearest Neighbor Classification""  http://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf Суть подхода выражается в следующей цитате оттуда: ""The algorithm attempts to increase the number of training examples with this property by learning a linear transformation of the input space that precedes kNN classification using Euclidean distances. The linear transformation is derived by minimizing a loss function that consists of two terms. The first term penalizes large distances between examples in the same class that are desired ask-nearest neighbors, while the second term penalizes small distances between examples with non-matching labels."" Таким образом, имея датасет с примерами синонимичных и несинонимичных пар, можно выводить такую метрику, чтобы синонимичные пары давали меньшее растояние между элементами пары, чем несинонимичные. У меня есть примерно 100,000 отобранных вручную пар синонимичных предложений. Для получения несинонимичных сэмплов задействуется простая процедура подбора случайных примеров - см.  исходный текст подготовки датасета . Для заданного предложения ищем случайные предложения, содержащие некоторое количество таких же слов. Это по задумке заставляет модель опираться не только на буквальную похожесть сравниваемых предложений, например как в негативном примере: Верный ответ узнай у учителя. Должен ли учитель сообщить правильный ответ? Еще ссылки по теме: https://stackoverflow.com/questions/38260113/implementing-contrastive-loss-and-triplet-loss-in-tensorflow https://towardsdatascience.com/lossless-triplet-loss-7e932f990b24 https://stackoverflow.com/questions/47551447/keras-triplet-loss-with-positive-and-negative-sample-within-batch https://github.com/adambielski/siamese-triplet 3. Реализация и результаты Базовая модель, с которой сравнивается triplet loss модель, представляет из себя нейросетку с сиамской архитектурой, в которой сверточно-рекуррентная часть строит эмбеддинг предложения, а классифицирующая часть беред два эмбеддинга предложений из пары и учится классифицировать их как ""синонимичны/не синонимичны"".  Исходный текст здесь . Она дает при валидации величину f1 около 0.95. Исходник нейросетка с triplet loss  лежит тут . На входе эта модель получает тройки предложений, в которых есть опорное предложение (anchor), синонимичное предложение (positive) и несинонимичное предложений (negative). Схема сетки выглядит совершенно примитивно, так как вся основная работа происходит в реализации функции triplet_loss: Особенность модели в том, что она сама по себе не умеет выдавать никаких показателей близости для двух заданных предложений. После обучения надо взять те слои модели, которые строят эмбеддинги (это LSTM слой). Чтобы оценить синонимичность двух предложений, прогоняем их через эту усеченную модельку, получаем два эмбеддинга. Затем для этих двух векторов рассчитываем евклидово расстояние. Более ничего модель делать не умеет. В результате мы можем, например, ранжировать список предложений по степени их синонимичности заданному. Для валидации мы берем тройку предложений из сэмпла, делаем расчет расстояний anchor-positive и anchor-negative, и если первое расстояние меньше - значит предложения более похожи, чем непохожи, и наоборот. Эта модель при валидации дает точность примерно 0.89. Модель с contrastive loss  в целом похожа на triplet loss, но на входе у нее задаются пары предложений и метки ""синонимичны/нет"". К сожалению, моя реализация стабильно выдает  NaN в качестве значения loss'ов при обучении, поэтому оценить ее качество не могу.",sent2vec||vector model||vector space model||нейросети||перефразировки||семантика
83,      Наглядно о текущих проблемах в чатботе  ," 1. Текущая реализация  чатбота  имеет примитивнейшие зачаточные функции проактивного диалога и knowledge mining'а. Но кроме ограниченности самих функций, проблему составляет и ""туповатость"" модели понимания (интерпретации), что видно по последнему вопросу чатбота, когда он не понял последний мой ответ: 2. Soft unification иногда ""гонит лажу"":",chatbot||чатбот
84,      Взаимная информация и алгоритм Леска для отбора ассоциаций: граф Бозон де Валуа  ,"  Что там с бозоном? У обычного человека, более-менее интересующегося околонаучными новостями, для слова "" бозон "" скорее всего ассоциируются "" Хиггс "",  "" коллайдер "" и  прочее . А что можно сказать по поводу следующего фрагмента: "" Происхождение Бозона неизвестно. Он родился не позже 800 года. Известно о нём не очень много. Его владения находились в Италии. "" Звучит странно? Странно. Тем не менее, это достоверный факт, насколько можно верить википедии - см. викистатью  Бозон Древний . Вообще, со словом ""бозон"" связано  множество викистатей , что делает вторую часть рассказа про взаимную информацию немного более интригующей. Взаимная информация и Википедия Как собрать информацию о том, с какими словами ассоциируется заданное слово? Скачаем дамп Википедии. Я обычно беру в XML формате, благо он очень просто парсится потоковым XML парсером или даже врукопашную через функционал стандартных строковых операций поиск-вырезание. В августе этого года распаковый файл ruwiki-latest-pages-articles.xml имел размер около 20 Гб, то есть вкусной информации там много. Каждая страница начинается тегом page . Заголовок статьи, который мы видим в википедии, оформлен тегом title. Содержимое статьи сидит внутри тега  text, его тоже нетрудно вытащить чисто строковыми операциями. Теперь берем слова заголовка и слова тела статьи (теги и вики-разметку вычищаем, конечно). Перебираем пары слов - первое слово из заголовка, второе из тела статьи. Для русской википедии желательно лемматизировать. Накапливаем частоты самих слов и частоты пар. Эта статистика нужна, чтобы вычислить потом  взаимную информацию  для каждой пары слов. Взаимная информация для пары слов показывает, насколько они связаны. Если отсортировать все 2-граммы при фиксированном первом слове по убыванию величины взаимной информации, то получим для слова ""бозон"" что-то вроде такого списка: бозон    взаимодействие    3,97367061825484E-06    110 бозон    частица    3,54734380896466E-06    99 бозон    флорида    2,00675274053238E-06    57 бозон    калибровочный    1,88544077616527E-06    39 бозон    амвросий    1,6800332438542E-06    40 бозон    хиггсовский    1,66107235059345E-06    29 бозон    каролина    1,61707258939835E-06    48 бозон    элементарный    1,55780812360871E-06    43 бозон    миссисипи    1,39087314664506E-06    36 бозон    масса    1,25770570109081E-06    50 бозон    стандартный    1,22869540247916E-06    41 бозон    модель    1,16914628660164E-06    48 бозон    квантовый    9,80003261048578E-07    31 бозон    алабама    9,22132459849188E-07    24 бозон    физик    9,17935188871866E-07    37 бозон    физика    8,91582333008874E-07    36 бозон    электронвольт    8,80786530663711E-07    18 бозон    заряд    8,26044452842102E-07    26 бозон    митрополит    8,01929214751853E-07    29 бозон    спин    7,97482386605151E-07    26 бозон    распад    7,96299593900728E-07    27 бозон    электромагнитный    7,66984165817137E-07    23 бозон    виргиния    7,12947024614312E-07    21 бозон    лептон    7,10239621974779E-07    15 бозон    кварк    7,08601349091444E-07    18 бозон    электрослабый    6,83616481760744E-07    14 бозон    слабый    6,73619857370767E-07    25 бозон    фундаментальный    6,59329938209836E-07    21 бозон    поле    6,2740136887719E-07    26 бозон    теория    6,26134436073209E-07    27 бозон    поля    6,25046725542973E-07    25 бозон    луизиана    6,2419057784623E-07    17 Третье поле как раз дает расчетную величину взаимной информации. Вроде бы неплохо, но из-за многозначности термина ""бозон"" в списке видна сильная ассоциация со словами типа ""флорида"". Это может мешать в некоторых случаях, например при генерации текста. Артефакты многозначности в Википедии Судя по всему, последовательность выгрузки статей Википедии соответствует последовательности ID этих статей в БД. Для многозначных терминов типа ""бозон"", когда есть превалирующее значение и множество более редких, это проявляется в том, что статья для ""Бозон Хиггса"" написана и выгружается в дамп намного раньше, чем другие статьи для бозона. Видимо, сначала викиавторы создали статью для самого ожидаемого значения, а потом, через значительное время, нашлись знатоки и других значений. На практике при сборке mutual information это может проявляться необычным образом при отладке. Представьте себе, что вы отлаживаете код. Разумеется, сначала вы ограничите количество викистатей, которые обрабатывает сборщик, какой-то небольшой величиной, например 100,000. Проверяете результаты. Для слова ""бозон"" они содержат только ожидаемые ассоциации типа ""физика"", ""взаимодействие"", ""коллайдер"" и т.д. Отладка закончена, вы снимаете ограничение на число статей, ждете 3 часа, получаете таблицу ассоциаций по полной Википедии и наблюдаете много странного мусора в разных статьях. Снова отлаживаете, и так до тех пор, пока не возникает подозрение, что мусор появляется, если повышать ограничение на число статей. Это не 100% достоверный факт, так что я не стал бы полагаться на него, но иметь в виду стоит. Отбор правильных ассоциаций и алгоритм Леска Итак, ассоциации у нас есть, но для многозначных слов они представляют из себя пересечение соответствующих ассоциативных облаков. Если у нас на вход пришла фраза, например ""Бозон в коллайдере"", возникает желание отсеять побочные смыслы слова ""бозон"" и оставить у него основное ассоциативное облако, полагаясь на контекст входной фразы. В данном случае контекстом будет слово ""коллайдер"". Такую задачу решает очень старый, и в какой-то степени самоочевидный  алгоритм Леска . Мы берем ассоциативные облака для слов входной фразы и оставляем те варианты, которые встречаются минимум в двух словах фразы (или дисконтируем вес неподтвержденных ассоциаций). Для слова ""коллайдер"" ассоциативное облако имеет вид примерно такой: коллайдер    протон    4,88508886544732E-06    100 коллайдер    пучок    4,34556205387541E-06    93 коллайдер    столкновение    3,98019142057503E-06    96 коллайдер    частица    3,883858943155E-06    97 коллайдер    адронный    3,7787451861958E-06    66 коллайдер    энергия    3,60533084038241E-06    100 коллайдер    ускоритель    2,92787951289753E-06    61 коллайдер    детектор    2,8502328317765E-06    59 коллайдер    бак    2,58382073438321E-06    73 коллайдер    протонный    2,37991425311809E-06    45 коллайдер    бозон    2,37441636150546E-06    48 коллайдер    элемент    2,36604600862001E-06    76 коллайдер    кварк    2,3581617306672E-06    48 коллайдер    эксперимент    1,74617760420082E-06    48 коллайдер    светимость    1,70743535275565E-06    37 коллайдер    физик    1,46755247187626E-06    48 коллайдер    глюонный    1,4615422841239E-06    25 коллайдер    физика    1,32882079043766E-06    44 коллайдер    большой    1,30949283016725E-06    52 коллайдер    сгусток    1,20316511171473E-06    23 коллайдер    ядерный    1,02551826305267E-06    32 коллайдер    магнит    1,01266575332571E-06    23 коллайдер    ядро    1,00129041617246E-06    31 коллайдер    новость    9,47266853291297E-07    32 коллайдер    свинец    9,45576987061381E-07    23 коллайдер    коллаборация    9,06797304056402E-07    17 Итогом пересечения облаков имеем, что для фразы ""бозон в коллайдере"" остаются следующие ассоциации: бозон ==> бозон взаимодействие частица элементарный физик физика кварк теория коллайдер адронный фотон в ==> в коллайдер ==> коллайдер частица адронный бозон кварк физик физика взаимодействие элементарный теория фотон А для фразы ""Бозон во Флориде"" получаем: бозон ==> бозон флорида каролина во ==> во флорида ==> флорида каролина А исходники? Исходные тексты сборщика mutial information на C#, а также прочие исходники для этого проекта (Python) тоже, видимо, выложу через какое время, в репозитории  https://github.com/Koziev/NLP_Comp .",unsupervised feature learning||статистика
85,      Датасет с ударениями для русского лексикона (>1.6 миллионов слов)  ," В репозиторий  https://github.com/Koziev/NLP_Datasets  выложен мой датасет с данными об  ударениях . Примерно такой объем был использован в коде лексического шаблонизатора для конкурса  ClassicAI . Поясненения есть в  README.md , сам упакованный датасет доступен  по ссылке",датасеты||лексика||русский язык||соревнования
86,      Полностью переписанный веб-сервис для чатбота  , Используется Flask плюс jinja для отрисовки тестовой страницы с диалоговой формой. Исходники  тут  и  тут . В браузере выглядит так:,chatbot||flask||web api||чатбот
87,      Черновой вариант модели интерпретации ответов пользователя в чатботе  ," Исходный текст аппликатора модели в чатботе  доступен в репозитории . То, что делает эта модель, можно пояснить таким примером диалога: B:> Здравствуй H:> как тебя зовут? B:> кеша B:> А как тебя зовут? H:>  илья B:> Приятно познакомиться. H:> как меня зовут? B:> илья Бот спрашивает собеседника ""А как тебя зовут"", рассчитывая пополнить свою базу знаний. Собеседник в ответ сообщает свое имя. Проблема в том, что само по себе одно имя собеседника не является фактом, который можно далее использовать в выводах ответов. Для этого слово-имя должно сопровождаться самим вопросом ""А как тебя зовут"". Вот тут-то и запускается модель интерпретации, которая сливает текст заданного вопроса и ответ собеседника в единую реплику "" Тебя зовут Илья "". Смена грамматического лица - необходимый эффект, посколько в базе фактов все хранится ""эгоцентрично"", с точки зрения чатбота. Результат интерпретации является уже полноценным фактом, который запоминается в  базе знаний . Последние две реплики диалога как раз показывают, как собеседник спрашивает у бота свое имя, и бот успешно отвечает - при этом  модель релевантности , реализующая ""soft attention"", определяет добавленный факт как самый релевантный заданному вопросу, а группа моделей генерации ответа отдают наружу необходимую часть текста факта.",chatbot||чатбот
88,      Альтернативный подход к генерации фраз для чатбота из classic.sberbank.ai  ," Вообще я планировал, что в каком-то виде алгоритм, или его части, созданный для  https://classic.sberbank.ai , будет использоваться в  чатботе  при генерации ответа. У него среди прочего есть такая интересная особенность, что он рандомизирован, и может выдавать разные ответы на каждую попытку - то, чего не хватает сейчас чат-боту. Например: Автор:  Пушкин . Тема:  голодная жирная кошка ловит вкусную серую мышку Результат №1: У персонажа кит животный;  Густая мышь на супе том:  И днем и ночью зек ученый  Все ходит по супу кругом;  Идет направо - рыб заводит,  Налево - ужас говорит.  Там персонаж: там кошка бродит,  Собака на супах сидит; Результат №2: Вся кошка ли голодным зеком  Озарена.  Вкуснейшим треском  Трещит голоднейшая печь.  Приятно думать у лежанки.  Но знаешь: не велеть ли в санки  Закуску вкусную запрячь? Задумка в том, чтобы иметь в чатботе базу ""типовых шаблонных ответов"", из которых можно получать для текущего контекста некую реплику ""по теме"".",генерация текста||перефразировки||чатбот
89,      Волшебство seq2seq нейросетки в чатботе - вот кто так еще умеет?  ," Тренер модели и тестирующая часть доступны в файле  nn_chargenerator.py . Готовая модель натренирована на моем датасете вопросов и ответов, она выложена  тут  (файлы nn_chargenerator.*). Ее назначение - генерация ответа чатбота при наличии нескольких предпосылок (от 0 до 3) и вопроса. В рассматриваемом случае предпосылок нет, текст вопроса содержит в себе все необходимое. Запускать в консоли надо так: python nn_chargenerator.py --run_mode query Ответы модели на вопросы ""Сколько букв в слове ...?"": Идея теста родилась случайно, когда я просматривал странички Вики с описаниями разных игр. Кроме вопросов на количество букв, можно будет попробовать обучить чатбот отвечать на вопросы такого вида: - Назови птиц, названия которых начинаются на 'во' - Названия каких животных оканчиваются на мягкий знак? ...",character language model||chatbot||игроботы||нейросети||чатбот
90,"      А вот как выглядит ""примерно правильное решение"" в исполнении естественного интеллекта  "," Продолжение темы "" Чатбот в первом классе: склонность понемногу ошибаться как отличительная черта "" возникло совершенно случайно, что делает его еще более ценным. Естественному интеллекту почти 7 лет, решал и потом снимал он сам, я просто сегодня случайно увидел в его фотках вот это:",забавные моменты
91,      Текущие улучшения в движке чатбота  ," Сейчас полный движок  чатбота , консольная версия которого запускается скриптом  console_chatbot.py , начал поддерживать такие диалоги: B:> Привет, буду рад поговорить H:> Как тебя зовут? B:> кеша B:> А как тебя зовут? H:> Меня зовут Илья. B:> Приятно познакомиться. H:> Сколько будет 2 плюс 2? B:> 4 H:> Меня как зовут? B:> илья H:> Сколько сейчас времени? B:> 17 часов 47 минут Реплики бота идут с B:>, реплики человека с H:> В памяти (базе знаний) чатбота заранее внесена некоторая информация, в частности то, что его зовут ""Кеша"". Информацию о том, что собеседника зовут Илья, бот узнает в ходе общения и запоминает и использует в выводах также же, как остальные факты, это видно по последнему вопросу и ответу. В  коде движка вывода ответов  нет никаких жестко запрограммированных правил или шаблонов распознавания вопросов о времени и т.д., весь диалог возникает в ходе оркестрации почти десятка моделей. Не хватает еще нескольких вещей: 1) Консолидация памяти для чистки устаревших, опровергнутых или уточненных фактов. 2) Интерпретация фраз для заполнения пропусков в репликацих, понимаемых на основе контекста. 3) Понимание эмоционального состояния собеседника для опознания иронии и т.д. Первый пункт в этом списке примерно понятно как реализовывать технически, второй надо додумывать, насчет третьего пока все очень туманно.",chatbot||генерация текста||чатбот
92,      Чатбот в первом классе: склонность понемногу ошибаться как отличительная черта  ," Проверяю результаты обучения  моделей чатбота  с добавленными арифметическими примерами. Опять просматривается  замеченная ранее  склонность давать ответ ""примерно похожий на то, что нужно"". Когда ответ подразумевает число, бот действительно выдает какое-то число, обычно близкое к верному: Premise[0]:  у меня было 2 абрикоса Premise[1]:  два абрикоса я отдал ире Question:     сколько теперь у меня абрикосов True answer:  0 Model answer: 1 Question:     что получится если из 1 вычесть 1 True answer:  0 Model answer: 1 Premise[0]:  ваня пил чай один раз утром и три раза вечером Question:     сколько раз ваня пил чай True answer:  4 Model answer: 3 Premise[0]:  на столе одна синяя ручка и девять красных Question:     сколько всего ручек на столе True answer:  10 Model answer: 6 Question:     сколько получится если 1 прибавить к 5 True answer:  6 Model answer: 5 Premise[0]:  на столе одна синяя ручка и одна красная Question:     сколько всего ручек на столе True answer:  2 Model answer: 4 Premise[0]:  на столе девять синих ручек и девять красных Question:     сколько всего ручек на столе True answer:  18 Model answer: 15 При этом никаких особых ""приспособлений"" и явного кодирования для арифметики в модели конечно нет, в чем легко убедится по  исходному тексту . С одной стороны, формально это не совсем то, что хотелось бы получать в результате нескольких часов обучения нейросетки на сотнях процессоров GPU. С другой, именно так себя ведут естественные реализации ИИ. Тот, кто занимался обучением арифметике маленьких детей, знает, что в зависимости от мотивации, настроения и просто опыта ребенок может ошибиться, ответить неверно назло или шутя, или просто быть невнимательным. Конечно, бот лишен всех этих аспектов поведения, поэтому его реакции более детерминированы и просты.",chatbot||нейросети||чатбот
93,      Улучшения в движке вывода ответов чатбота: арифметика и логика  ," Для  проекта вопросно-ответной системы  проверяю нейросетку, которая отвечает за выбор ответов ""да"" и ""нет"". Строки с приглашением ""H:"" - мой ввод с консоли, ответы бота помечены ""B:"". Важный момент - бот в явном виде не анализирует синтаксис и лексику, никаких прописанных кодом особых обработок арифметических вещей в нем нет, это исключительно артефакты нейросетки, обученной на наборе примеров.",chatbot||нейросети||чатбот
94,"      Большое обновление русского лексикона, морфологии и синтаксических правил в грамматическом движке  "," Закомитил в  https://github.com/Koziev/GrammarEngine  накопившиеся изменения: 1) Добавлено много новых словарных статей 2) Убраны некоторые составные слова типа ""мотор-генератор"" 3) Исправлены различные ошибки, обнаруженные при тестировании - неверные формы слов etc. 4) Для некоторых слов уточнены морфологические теги (модальность, падежная валентность etc.) 5) В синтаксический анализатор добавлена пара правил разбора. Также есть некоторые вещи, которые могут быть добавлены в словарь по результатам экспериментов в рамках соревнования  ClassicAI",Морфологический анализ||грамматический словарь||лексика||русский язык||синтаксический анализатор
95,"      Чем ближе структура диалога к естественной, тем сложнее с ним работать  "," Очень непросто оказалось ввести в  чатбот  некоторую проактивность, например (B - реплики бота, H - реплики человека): B:> Добрый день H:> Привет, как тебя зовут? B:> кеша B:> А как тебя зовут? H:> Меня зовут Илья. B:> Рад знакомству. Сейчас проект плавно переходит во вторую стадию - реализация  reasoning engine  и  интерпретация реплик . Reasoning engine  - эта модель, которая реализует вывод ответов на основе фактов и правил, например: T: Любой человек смертен. T: Сократ человек. Q: Смертен ли Сократ? A: Да В этом случае задача системы - вывести ответ ""Да"", хотя в явном виде факт ""Сократ смертен"" в базе фактов отсутствует. Интерпретация реплик  - это учет текущего контекста беседы, делающий ее естественной и привычной, диалог становится менее механичным. Простейший пример: - Привет - Привет, как тебя зовут? - Илья, а тебя? - Кеша Тут третья реплика ""- Илья, а тебя?"" на самом деле должна быть проинтерпретирована как ""Меня зовут Илья. А тебя как зовут?"". Раскрытие  анафоры , замена  эллипсисов  и некоторые прочие лингвистические заморочки - разные грани интерпретации.",chatbot||вербальный интерфейс||текущие планы||чат-боты
96,"      Сравнение оптимизаторов ""Follow The Moving Leader"" и ""Nesterov moment + Adam""  "," Для  задачи посимвольной генерации теста ответа в чатботе  сравниваю два алгоритма оптимизации: 1) штатный keras.optimizers.nadam, описанный тут  http://cs229.stanford.edu/proj2015/054_report.pdf 2) FTML из  https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/optimizers/ftml.py , описанный  тут . Сравнивается значение per instance accuracy, достигаемое при обучении нейросетки, то есть успехом считается генерация всей цепочки символов ответа без единой ошибки. Стоит заметить, что смена оптимизатора для keras-моделей в данном случае выполняется очень просто: достаточно подключить модуль через import keras_contrib.optimizers.ftml и затем при компиляции модели указать вместо 'nadam' экземпляр класса FTML - см. строки 461 и 462 в  коде . Как всегда, нейросетки при обучении очень стохастичны, и в данном случае ""на глазок"" сравнить эффект использования оптимизатора непросто. В  тетрадке  я вбил по 7 значений точности для каждого оптимизатора, выглядит это так: ftml = [0.8486, 0.8437, 0.8480, 0.8468, 0.8468, 0.8393, 0.8500] nadam = [0.8486, 0.8386, 0.8295, 0.8391, 0.8242, 0.8293, 0.8356] Видимо чтобы закрутить интригу, первые запуски каждого варианта дали совпадение до 4го знака после запятой после округления: 0.8486. Нам нужно выяснить, является ли наблюдаемое в ходе этих двух серий экспериментов отличие средних выборочных значений проявлением случайности, или отличие действительно обусловлено объективным влиянием выбранного оптимизатора. Используем  дисперсионный анализ , а именно штатную функцию  scipy.stats.f_oneway  для проверки нулевой гипотезы.  Нулевая гипотеза  в данном случае заключается в том, что отличие выборочных средних значений точности для FTML и nadam возникли случайно. Расчет дает pvalue=0.6%. Это значит, что отвергая нулевую гипотезу, мы ошибемся с вероятностью 0.6%. Говоря по-человечески, мы можем смело утверждать, что отличие точности модели при использовании этих оптимизаторов является неслучайным, и  FTML действительно в данном случае дает прирост в точности примерно на 1% .",anova||ftml||keras||keras-contrib||нейросети||статистика||чатбот
97,"      Когда ты джун-разработчик, а сеньор на проекте вдвое младше тебя /// шутка  ", И даже ложку тебе еще не доверяют:,забавные моменты
98,"      Как выглядит мина-ловушка в .NET Framework уровня ""enterprise""?  "," Мина образуется при сочетании двух вещей. 1. БД MS SQL, в которой сделана хранимая процедура на T-SQL, в которой сделан цикл, внутри которого заботливо оставлен PRINT. Ну чтобы в SSMS ручками запускать и удобненько диагностику читать. Надо, чтобы в тестах этот цикл выполнялся не очень много и не вызвал подозрений. 2. Прога, использующая  SqlConnection + SqlCommand  и вызывающая эту самую хранимку. В прекрасный июльский день деплоймент-инженер на удаленной площадке, разворачивая и тестируя софт в очередном боевом окружении, сообщает вам радостную весть - веб-сервис валится по OutOfMemory. Вы смотрите в лог, а там дружище log4net говорит, что падает при выполнении SqlCommand, которая делает просто вызов хранимки. Ну не может такого же быть, думаете вы. Хранимка выполняется на сервере? На сервере. Память выжирается на клиенте? На клиенте. Ваш коллега совершенно четко вам сообщает, что MSSQLSERVER кушает свои положенные 8 Гб и ни капли больше, в SSMS эта хранимка вызывается и отрабатывает без проблем. А жрет клиентский 32-битный процесс. А через денек вы натыкаетесь на описание, из которого следует, что в общем-то это - фича: "" SqlCommand ExecuteNonQuery throws OutOfMemoryException",.net||ms sql||забавные моменты
99,      Machine learning местами азартен /// офтопик  ," Например, когда досыпал фич в обучающий набор, и видишь, как тренер на машине с 62.7 Гб оперативки засасывает датасет, доходит до 62.3 Гб и начинает колебаться по 100 Мб туда-сюда... Только бы не шальной запрос к сервису, который там же висит.. Просто невозможно оторваться от htop'а:",machine learning||забавные моменты
100,"      ""Детский"" режим генерации ответа в чатботе  "," Есть у детей такая особенность - на вопрос, на который они не знают правильного ответа, часто отвечают не ""не знаю"", а выдумывают ответ, примерно похожий на правильный, чтобы не уронить самооценку. Например, спросите его про время на стрелочных часах, а он не умеет еще читать их, и будет лепить произвольные часы и минуты, главное, чтобы подходило под ""общую концепцию времени"". Именно это приходит на ум, когда вижу в логе валидации  нейросетевой модели генерации ответа  такие записи ("" True answer "" это ожидаемый эталонный ответ, "" Model answer "" это выдача модели.): Premise:      гастрольный тур займет 3 года Question:     сколько продлится гастрольный тур True answer:  3 года Model answer: 4 мес Premise:      первый спектакль состоялся 3 марта Question:     когда был первый спектакль True answer:  3 марта Model answer: 1 марта Premise:      сейчас 8 часов 46 минут Question:     сейчас сколько времени True answer:  8 часов 46 минут Model answer: 5 часов 46 минут Premise:      церемония вручения наград пройдет 16 июня Question:     когда будут вручаться награды True answer:  16 июня Model answer: 20 июня Premise:      экскурсия стоит 2000 рупий Question:     сколько стоит экскурсия True answer:  2000 рупий Model answer: 100 руб",chatbot||генеративная модель||генерация текста||чатбот
101,      Нелюбовь чатбота к букве 'п' (и еще про sklearn.metrics.classification_report)  ," Модель посимвольной генерации ответа чатбота была кратко описана  здесь , а ее исходный текст лежит  тут . Кроме финальной оценки качества модели через per instance accuracy (доля полностью правильно сгенерированных ответов, когда один неверный символ относит ответ к невалидным), я добавил туда расширенную диагностику с помощью  sklearn.metrics.classification_report , см. строки 693 и 694. Вот что она показывает: 
              precision    recall  f1-score   support

         \r       0.96      0.98      0.97     10418
          —       0.00      0.00      0.00         2
          5       0.97      0.98      0.97       241
                  0.95      0.91      0.93      4937
          %       1.00      1.00      1.00         1
          0       0.98      1.00      0.99       174
          ъ       1.00      1.00      1.00        16
          3       0.98      0.99      0.99       263
          б       0.93      0.96      0.95      1053
          а       0.97      0.97      0.97      6555
          г       0.95      0.94      0.94      1065
          в       0.95      0.95      0.95      2814
          е       0.96      0.96      0.96      4879
          д       0.95      0.95      0.95      2067
          з       0.94      0.93      0.93       934
          ж       0.94      0.95      0.94       493
          й       0.95      0.95      0.95       961
          и       0.96      0.96      0.96      5134
          л       0.96      0.96      0.96      2975
          к       0.96      0.95      0.95      3284
          н       0.96      0.96      0.96      4929
          м       0.95      0.95      0.95      2738
          п       0.92      0.92      0.92      1537
          4       0.98      0.99      0.98       243
          с       0.95      0.95      0.95      3676
          р       0.96      0.96      0.96      3787
          у       0.97      0.97      0.97      2802
          т       0.97      0.97      0.97      5224
          х       0.92      0.96      0.94       578
          ф       0.97      0.98      0.97       315
          ч       0.97      0.97      0.97      1412
          ц       0.96      0.98      0.97       402
          щ       0.95      0.97      0.96       185
          ш       0.95      0.97      0.96       660
          ы       0.98      0.98      0.98      2484
          6       0.98      0.96      0.97       130
          э       0.96      0.93      0.94       163
          ь       0.97      0.97      0.97      1001
          я       0.98      0.98      0.98      2809
          ю       0.96      0.96      0.96       567
          9       0.99      0.98      0.98       151
          8       1.00      0.97      0.98       120
          2       0.98      0.98      0.98       406
          7       1.00      0.96      0.98       140
          1       0.98      0.99      0.99       572
          о       0.96      0.96      0.96      7100

avg / total       0.96      0.96      0.96     92397
 Символ \r это специальный маркер конца ответа. Можно заметить, что худшая точность (0.92) наблюдается для буквы 'п'. Удивительно при этом, что это достаточно частотная буква, в частности для данного набора ответов она встречается 1537 раз. Разумеется, в тренировочном наборе она тоже весьма частотна, потому классификатор видел ее в разных контекстах много раз, и тем не менее вот такой bias... По поводу использованной функции  sklearn.metrics.classification_report , кстати, есть одна неприятная засада. Она на входе принимает опционально наименования классов, чтобы сделать отчет более читабельным. В данном случае названиями классов являются символы. Все прекрасно до тех пор, пока передаваемые в функцию  y_true  и  y_pred  содержат одинаковое по мощности множество классов. Но если в y_pred встречаются не все классы (всякое бывает, например маленький набор для валидации или сильный дисбаланс классов), то происходит следующее. наименования классов, заботливо передаваемые в аргументе  target_names , не будут правильно соотнесены с вариантами классов из y_pred, и в консоли появится предупреждение. Отчет будет содержать неправильно поименованные класса! Чтобы исключить такой неприятный ход событий, в строке 692 я пересекаю множества классов в y_true и y_pred, и затем сортирую их по возрастанию: class_names = [encode_char(id2outchar[y]) for y in sorted(set(y_test) | set(y_pred))] Полученный список class_names гарантирует консистентность результатов работы sklearn.metrics.classification_report.",chatbot||python||sklearn||генеративная модель||генерация текста||чатбот
102,      Генерация ответа чатбота: классификационная модель  ," Исходный код (Python, XGBoost)  лежит в репозитории . Файлы обученной на полном наборе вопросов и ответов модели лежат в папке  https://github.com/Koziev/chatbot/tree/master/tmp  и имеют имена xgb_answer_generator.* Что делает модель Модель посимвольно строит текст ответа, располагая текстом факта-предпосылки и заданного вопроса. Генерируемый текст должен быть орфографически и лексически валидным, по крайней мере хотелось бы этого достичь. В частности, модель должна уметь склонять существительные в случае, если в предпосылке и в ответе слово стоит в разной грамматической форме - см. пример далее. Примеры работы Модель можно запустить в режиме интерактивной проверки. Для этого в командной строке указывается ключ --run_mode query: python xgb_answer_generator.py --run_mode query Далее вводятся парами факты-предпосылки и вопросы, а модель выдает сгенерированный ответ, например: Premise:>  Миша дружит со Славой. Question:>  Кто друг Миши? Answer:  слава Premise:>  Миша пьет сок. Question:>  Сок кто пьет? Answer:  миша Premise:>  Ира вокруг песочницы бегает. Question:>  Кто бегает? Answer:  ира Иногда модель выбирает неверный формат ответа, например не тот режим глагольного управления: Premise:>  кошка охотится на мышей Question:>  кого ловит кошка? Answer:  на мышей Ну и так далее, вплоть до невнятного лепета, в котором только угадываются следы русской речи. Краткая идея модели Модель учится выбирать очередной символ для строки ответа, располагая следующей информацией: 1. Текст предпосылки - релевантного факта, найденного в базе знаний с помощью отдельной  модели детектора релевантности . В описываемом коде эта модель никак не участвует, в частности для консольного теста текст предпосылки вводится явно. 2. Текст вопроса, заданного собеседником чатботу. 3. Цепочка символов ответа, сгенерированная к данному моменту. Генерация начинается со специального символа, обозначаемого в коде константной BEG_CHAR, и заканчивается символом, присвоенным константе END_CHAR. Так как при обучении модель видит цепочку заведомо валидных символов, то имеем все достоинства и недостатки teacher forcing алгоритма. Тексты предпосылки и вопроса режутся на шинглы - перекрывающиеся символьные 3-граммы. На входе классификатора получается очень разреженная матрица. Выходом модели будет вектор длиной около 50, соответствующий символам кириллицы, цифрам и другим символам. Для генерации всего ответа начинаем с символа BEG_CHAR, получаем следующий символов, дописываем его в п.3 и повторяем классификацию до получения символа END_CHAR или по достижении предельной длины ответа во избежание зацикливания. Обучение модели длится на моей машине примерно 2-3 часа для максимальной глубины деревьев 6, если не использовать GPU.",character language model||chatbot||python||xgboost||генерация текста||градиентный бустинг
103,      Удобная сортировка текстовых датасетов с помощью LSA и t-SNE  ," По-моему, самый простой, полностью unsupervised, и удобный для визуального анализа способ сортировки  датасетов типа этого  получается вот так: 1) у нас есть текстовый файл, в каждой строке которого находится одно предложение. 2) выполняем  LSA  по символьным шинглам: 
vectorizer = TfidfVectorizer( max_features = None ,  ngram_range =( 3 ,  5 ),  min_df = 1 ,  analyzer = 'char' )
svd_model = TruncatedSVD( n_components =LSA_DIMS,  algorithm = 'randomized' ,  n_iter = 20 ,  random_state = 42 )
svd_transformer = Pipeline([( 'tfidf' , vectorizer), ( 'svd' , svd_model)])
svd_transformer.fit(tfidf_corpus)
phrase_ls = svd_transformer.transform(tfidf_corpus)

 3) выполняем встраивание получающегося списка векторов  phrase_ls  в одномерное пространство с помощью  t-SNE , так что близкие вектора предложений, полученные в п.2, будут примерно так же близки друг к другу, как в исходном LSA-пространстве (я задавал LSA_DIMS=60, но это влияет больше на общее время выполнения, чем на качество итоговых результатов): 
tsne = TSNE( n_components = 1 )
phrases_1d = tsne.fit_transform(phrase_ls)
 4) остается только отсортировать предложения по получившемуся ключу 1d встраивания и сохранить результат в файл. В результатах такой сортировки можно увидеть разные группы, например: Крови я не люблю. Азию я не люблю. Водку я не люблю. Чего я не люблю. Тусню я не люблю. Ниццу я не люблю. Пещеры я не люблю. Боевики я не люблю! Галлиду я не люблю! Лентяев я не люблю. или артефакты представления исходных фраз символьными шинглами, при котором  ненавижу  и  вижу  смешиваются: Я вообще стирку ненавижу. Я её прямо вижу! Я вижу легкий профиль. Каким я вижу генератор спрайтов Я вижу определенную стратегию. Я довольно часто вижу. Я вижу, начинается. А я ненавижу совок. Я вижу ее продолженье. Я часто вижу Вяземского. Дарта Сидиуса вижу я. Я вижу названия прокатчиков. Разрыв шаблона вижу я. А я ненавижу тыкву! Я вижу простую геометрию. Я ненавижу ваши игры! Я вижу бесконечное пространство. Полный код на Python'е доступен  тут .",lsa||vector model||vector space model
104,      Модуль поддержания разговора (smalltalk режим) для чатбота  ," В  кодовую базу чат-бота  добавлен небольшой модуль, которые позволяет в ответ на реплики пользователя, не являющиеся вопросами, отвечать для поддержания разговора (с условным названием  smalltalk режим  - см. также описание  светской беседы  в вики). В комплекте с общим  retrieval-based алгоритмом  чатбота и динамическим обновлением базы знаний из диалога получается более плавное общение (Q - мои реплики, A - ответы чат-бота): 
 Q:> привет
A:> Здравствуй

Q:> как тебя зовут?
A:> кеша

Q:> меня зовут Илья
A:> Привет!

Q:> я сегодня ел арбуз
A:> Арбуз очень вкусный был?

Q:> что я сегодня ел?
A:> арбуз
 Сам smalltalk режим срабатывает вот тут: 
 Q:> я сегодня ел арбуз
A:> Арбуз очень вкусный был?
 При этом в базу знаний вносится новый факт, сообщенный пользователем, так что в следующей итерации чатбот готов использовать этот новый факт без переобучения всех своих моделей: 
 Q:> что я сегодня ел?
A:> арбуз
 
",chatbot||чатбот
105,      Корпус русскоязычных диалогов и обменов репликами (неочищенный)  ," Для экспериментов с различными моделями для русскоязычного чат-бота. Пара сотен тысяч фраз, диалоги разной степени осмысленности и законченности, не субтитры. Текстовый файл",chatbot||question answering
106,      Extreme learning machine для рекуррентной сетки и быстрое получение эмбеддингов текстов  ," Случайно наткнулся на следующий необычный эффект при обучении рекуррентной нейросетки. Преамбула Занимаюсь тюнингом и экспериментами со своей реализацией Skip-Thoughts модели ( https://github.com/ryankiros/skip-thoughts ) на Keras. В принципе, у меня нейросетка достаточно точно воспроизводит архитектуру оригинальной статьи ( http://arxiv.org/abs/1506.06726 ), за исключением нескольких моментов: 1) тренируемся предсказывать только последующее предложение, а не предыдущее и последующее. 2) слова представлены фиксированными word2vec эмбеддингами, они не меняются в ходе обучения, так как это ухудшает точность. 3) есть early stopping по валидационному набору, поэтому обучение идет не заданное заранее число эпох. 4) размерность векторов слов и предложений значитально меньше, чем в оригинальной модели. Модель представляет из себя простую рекуррентную sequence 2 sequence сетку. Предложения берутся из большого русскоязычного корпуса с художественной литературой и всякой публицистикой. Исходный код можно найти в репозитории по ссылке  https://github.com/Koziev/chatbot/blob/master/PyModels/train_skip_thoughts.py Валидация эмбеддингов на задаче выбора предпосылки для вопроса Сами по себе значения loss'а изучаемой модели не информативны, так как ничего не говорят о качестве эмбеддингов, получаемых на кодирующей части seq2seq.  Поэтому я для оценки и сравнения с другими моделями использую специальный набор из вопросов и предпосылок-кандидатов. Модель должны выбрать верную предпосылку (см. для справки подход в Quick-Thought модели  https://github.com/lajanugen/S2V , описанной в статье  https://arxiv.org/pdf/1803.02893.pdf ). Таким образом, энкодер модели skip-thoughts выдает для любой цепочки слов вектор фиксированной длины. Взяв два предложения (вопрос и предпосылку-кандидат), мы определяем их релевантность через косинус между векторами-эмбеддингами (строка 461). Максимальное значение косинуса дает наиболее релевантную предпосылку (строка 466). Random projections или Extreme Learning Machine И вот в какой-то момент становится понятно, что если обучать skip-thoughts модель не до упора, когда срабатывает early stopping (примерно 20 эпох для миллиона пар предложений), а только несколько первых эпох, то точность выбора предпосылки через косинусную меру среди кандидатов растет! Оптимум может достигаться на 3-4 эпохах. И самое интересное - если рекуррентуню сетку со случайной начальной инициализацией весов  вообще не обучать , то она: 1) выдает некоторые эмбеддинги предложений (причем любой длины) 2) близкие по лексикону и словосочетаниям предложения прокачались через случайно инициализированные матрицы в LSTM элементах и дали близкие эмбеддинги. Получилось что-то типа Extreme Learning Machine ( https://en.wikipedia.org/wiki/Extreme_learning_machine ) для рекуррентной архитектуры, locality sensitive hashing ( https://ru.wikipedia.org/wiki/Locality-sensitive_hashing ) и Random Projections ( http://scikit-learn.org/stable/modules/random_projection.html ). Далее я проверил этот же подход для похожей на InferSent ( https://github.com/facebookresearch/InferSent ) задачи, когда эмбеддинги предложений получаются в ходе supervised обучения классификатора релевантности (исходный код на Python/Keras лежит тут  https://github.com/Koziev/chatbot/blob/master/PyModels/nn_relevancy.py ) с похожим результатом: необученный, случайно инициализированный рекуррентный энкодер выдает эмбеддинги текста, неплохо работающие с косинусной мерой.",embeddings||sent2vec||vector model||vector space model
107,      Изменения в модели wordchar2vector (посимвольный рекуррентный автоэнкодер)  ," Подробное описание модели:  https://github.com/Koziev/chatbot/blob/master/PyModels/trainers/README.wordchar2vector.md Исходники выложены в репо  https://github.com/Koziev/chatbot , в частности  код тренера  и  скрипт запуска обучения . 1. Посмотрев на исходники проекта ELMo ( Tensorflow implementation of contextualized word representations from bi-directional language models ) в части архитектуры для сверточной части, я сделал для каждой группы сверточных элементов разное число фильтров. То есть вместо: 
             nb_filters = 32

            for kernel_size in range(1, 4):
                conv_layer = Conv1D(filters=nb_filters,
                                    kernel_size=kernel_size,
                                    padding='valid',
                                    activation='relu',
                                    strides=1,
                                    name='shared_conv_{}'.format(kernel_size))(encoder)
 теперь код выглядит так: 
             for kernel_size, nb_filters in [(1, 16), (2, 32), (3, 64), (4, 128)]:
                conv_layer = Conv1D(filters=nb_filters,
                                    kernel_size=kernel_size,
                                    padding='valid',
                                    activation='relu',
                                    strides=1,
                                    name='shared_conv_{}'.format(kernel_size))(encoder)
 Заодно добавлены символьные тетраграммы. Увеличение кол-ва фильтров по мере увеличения ""размаха"" свертки отражает тот простой факт, что разных 3-грамм больше, чем 2-грамм, и так далее. 2. Оптимизация скорости заменой LSTM на GRU. Во многих местах (см. например  Skip-Thoughts Vectors ) утверждается, что для NLP задач GRU дает сопоставимую точность при меньшем количестве свободных параметров. Пробные запуски тренировки wordchar2vector с опцией --arch 'gru(cnn)' в общем это подтверждают. 3. Сделана попытка (не очень эффективная) улучшить сходимость в случае выхода на плато. Когда срабатывает early stopping (по умолчанию 20 эпох без улучшения точности), уменьшаем batch_size в два раза и продолжаем обучение. По задумке меньший размер batch_size должен увеличить стохастичность усредненного градиента и помочь выйти из локального минимума. На практике эффект получился совсем мизерный.",rnn||vector model||vector space model||word embedding
108,      Матрица соответствия шинглов в задаче определения релевантности факта и вопроса  ," Далее - пример того, как некоторые особенности технологии подготовки датасета, наложившись на свойства самого языка, могут проявить себя в NLP модели весьма необычным образом. Постановка задачи Модель должна определять релевантность предложения-факта (далее - ""предпосылка"") и предложения-вопроса. Релевантность включает в себя такие случаи, как: 1) тривиальные лексические перестановки, валидные в силу относительно свободного порядка слов в русском языке: "" продам диван абсолютно новый "" "" продам абсолютно новый диван "" Некоторые примеры таких пар можно найти в файлах в репозитории  https://github.com/Koziev/NLP_Datasets/tree/master/ParaphraseDetection/Data . 2) синтаксические перестановки и словообразовательные вариации, представляющие эквивалентное выражение семантики с использованием синтаксических и морфологических альтернатив русской грамматики: "" А поев, он сразу отойдет. "" "" Он поест и сразу отойдет. "" или "" Страдает и становится злым. "" "" От страданий становится злым. "" Если допустить определенные потери фактологических нюансов, то в эту категорию попадают и пары типа: "" они пытались решить проблему "" "" их попытка решить пороблему "" Потеря информации об относительном времени при замене личной формы глагола на однокоренное существительное во многих случаях вполне допустима. 3) вопросы к какому-то аспекту факта: "" Теща уехала к родственникам в Рязань. "" "" Куда теща уехала? "" 4) некоторые другие случаи, включающие в себя продуктивную синонимию типа "" бесследно - следов нет "" и так далее. Исходные тексты и датасет для воспроизведения Все необходимое лежит в репозитории  https://github.com/Koziev/chatbot . В частности, готовый датасет с релевантными и нерелевантными парами  https://github.com/Koziev/chatbot/blob/master/data/premise_question_relevancy.csv , сгенерированный кодом  https://github.com/Koziev/chatbot/blob/master/PyModels/prepare_relevancy_dataset.py Тетрадка с кодом исследования фичи доступна по ссылке:  https://github.com/Koziev/chatbot/blob/master/PyModels/%D0%9C%D0%B0%D0%BD%D0%B8%D0%BF%D1%83%D0%BB%D1%8F%D1%86%D0%B8%D0%B8%20%D1%81%20%D0%B2%D0%B8%D0%B7%D1%83%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B5%D0%B9%20%D1%88%D0%B8%D0%BD%D0%B3%D0%BB%D0%BE%D0%B2%D0%BE%D0%B3%D0%BE%20%D1%81%D0%BE%D0%BE%D1%82%D0%B2%D0%B5%D1%82%D1%81%D1%82%D0%B2%D0%B8%D1%8F%20%D0%BF%D1%80%D0%B5%D0%B4%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9.ipynb Обучение и валидация классификатора на базе XGBoost реализованы в файле  https://github.com/Koziev/chatbot/blob/master/PyModels/xgb_relevancy3.py Матрица соответствия шинглов Исследуемый вектор признаков получается таким способом (см. функцию get_shingle_image). На входе имеет две строки. Нарезаем их на шинглы - перекрывающиеся символьные 3-граммы. Получаем n1 и n2 шинглов соответственно, по количеству символов в строках. Далее заполняем матрицу n1*n2 значениями 1 и 0 согласно равенству соответствующих шимглов. Для предложений разной длины получаются матрицы разного размера.  Приведем их к одному размеру, представив как черно-белое изображение и использовав стандартный алгоритм масштабирования из библиотеки scikit-image  ( http://scikit-image.org/ ). В тетрадке реализовано приведение к размеру 16*16. Например, для двух предложений "" кошка отчаянно ловит серую мышку "" "" серую мышку хочет поймать кошка "" получаем такую матрицу соответствия шинглов: А после масштабирования: Яркости пикселов в получившейся матрице как раз и будут действительными числовыми признаками, которые будут подаваться на вход классификатора. Модель классификатора XGBoost Описанная процедура получения признаков полностью исключает из модели любую информацию о конкретных словах во фразах. Остается только информация о структуре преобразования одного предложения в другое. Для тривиального случая равных строк матрица соответствия будет просто диагональной. Тем не менее, классификатор, даже лишенный доступа к самим словам, достигает относительно неплохой точности - f1 score на валидации дает больше  0.9 . У меня есть сильные подозрения, что часть такой высокой точности объясняется достаточно небольшим набором правил получения вопроса для предпосылки в датасете. Эти структурные правила улавливаются классификатором даже без учета лексического наполнения текста. Я попробовал кластеризовать эти векторы признаков (k-means, см. тетрадку), но сходу ничего визуально осмысленного получить не удалось, тем не менее подозрение о причинах работоспособности модели остается.",chatbot||question answering||relevance||забавные моменты
109,      Генерация деепричастных форм из инфинитивов - SQL словарь + Python + xgboost  ,"  1. Постановка задачи В текущей версии  русской словарной базы  инфинитивные и деепричастные формы глаголов  хранятся как отдельные словарные статьи . Связь между ними задается через тезаурус. В результате такой декомпозиции не все инфинитивы имеют привязанные деепричастные формы. Перед запланированным рефакторингом словарной базы (слияние инфинитивов, деепричастий и глаголов в один грамматический класс) я бы хотел восполнить этот недостаток деепричастий. Прописывать деепричастные формы руками будет достаточно утомительно, а, учитывая достаточно регулярный способ образования из инфинитива, и непродуктивно. В конце концов, в словаре уже есть несколько тысяч примеров пар инфинитив-деепричастие, на базе которых можно статистически вывести правила образования деепричастных форм. Поэтому попробуем применить стандартные средства из арсенала машинного обучения для генерации деепричастных форм из инфинитивных. Этот же подход можно будет потом расширить и для остальных задач, связанных с генерацией форм слов из нормальных форм. 2. SQL Словарь русского языка SQL Словарь  - это таблицы слов с грамматическими метками, хранящиеся в обычной реляционной СУБД (MS SQL, MySQL, SQLite, Firebird, PostgreSQL) в виде, позволяющем выполнять штатные операции типа поиска нужной грамматической формы с помощью обычных SQL запросов (см.  примеры для существительных ). В частности, запрос, который выводит глагольные формы 1-го лица может выглядеть так: 
 select TOP 10 E.name, F.name
 -- выбираем глагольные словарные статьи
 from sg_class C
 join sg_entry E on E.id_class=C.id and C.name='ГЛАГОЛ'
 -- отбор глаголов совершенного вида
 join sg_entry_coord EC on EC.id_entry=E.id
 join sg_coord C1 on C1.id=EC.icoord and C1.name='ВИД'
 join sg_state S1 on S1.id=EC.istate and S1.id_coord=C1.id and S1.name='СОВЕРШ'
 -- формы глагола
 join sg_form F on F.id_entry=E.id
 -- отбираем формы 1го лица
 join sg_form_coord FC on FC.iform=F.iform and FC.id_entry=E.id
 join sg_coord C2 on C2.id=FC.icoord and C2.name='ЛИЦО'
 join sg_state S2 on S2.id=FC.istate and S2.id_coord=C2.id and S2.name='1'
 Он выдаст следующую информацию: 
 прирезать    прирежу
прирезать    прирежем
повиноваться    повинуюсь
повиноваться    повинуемся
врезать    врежу
врезать    врежем
перерезать    перережу
перерезать    перережем
вырезать    вырежу
вырезать    вырежем
 Усеченный SQL словарь русского языка можно взять на сайте. Либо сгенерировать установочные скрипты с помощью утилиты decompiler, скомпилировав ее из  С++ исходников  и взяв  готовую полную русскую словарную базу . Для MS SQL генерация заливочных скриптов в командной строке Windows делается так: decompiler.exe .\bin-windows64\dictionary.xml -outdir=.\tmp -sql ""mssql,mssql_bulk_insert,utf8,bom,lemmat izator,norules"" В указанном опцией outdir каталоге появятся файлы с sql-операторами и данные для BULK LOAD заливки, которые отправляем в экземпляр базы командой (предполагается, что инстанс базы с именем solarix доступен на localhost через win-аутентификацию): 
 set auth=-S localhost -d solarix -f 65001
set sqlcmd=""sqlcmd.exe""
set Z=%sqlcmd% -b -a 32767 %auth%

%Z% -i dictionary.sql -o mssql-dictionary.log
 3. Генерация обучающего датасета В словаре уже есть 24000 пар инфинитив-деепричастие. Следующий простейший запрос выдает этот список вместе с признаком глагольного вида, который нужен для правильной генерации формы ( компенсировать-компенсировав  и  компенсировать-компенсируя ): 
 select E_ap.name, E_inf.name, S.name
 from sg_entry E_ap
 join sg_class C_ap on C_ap.id=E_ap.id_class and C_ap.name='ДЕЕПРИЧАСТИЕ'
 join sg_link L on L.id_entry1=E_ap.id
 join sg_entry E_inf on E_inf.id=L.id_entry2
 join sg_class C_inf on C_inf.id=E_inf.id_class and C_inf.name='ИНФИНИТИВ'
 join sg_entry_coord EC on EC.id_entry=E_inf.id
 join sg_coord C on C.id=EC.icoord and C.name='ВИД'
 join sg_state S on S.id_coord=C.id and S.id=EC.istate
 Он выдаст примерно такие записи: 
 засыпая    засыпать    НЕСОВЕРШ
пасуя    пасовать    НЕСОВЕРШ
переливая    переливать    НЕСОВЕРШ
суровея    суроветь    НЕСОВЕРШ
покоившись    покоиться    НЕСОВЕРШ
дактилоскопируясь    дактилоскопироваться    НЕСОВЕРШ
наформовав    наформовать    СОВЕРШ
залакировавшись    залакироваться    СОВЕРШ
...
 Сохраняем этот резалтсет в текстовый файл с табуляциями в качестве разделителей с именем existing_adverbial_participles_and_infin itives.tsv. 4. Классификатор на базе XGBoost Для каждой пары инфинитив-деепричастие найдем общий префикс: 
 inf=засыпать    ap=засыпая    prefix=засып
inf=пасовать    ap=пасуя    prefix=пас
inf=переливать    ap=переливая    prefix=перелив
inf=очнуться    ap=очнувшись    prefix=очн
inf=закинуть    ap=закинув    prefix=закин
inf=суроветь    ap=суровея    prefix=суров
inf=покоиться    ap=покоившись    prefix=поко
inf=дактилоскопироваться    ap=дактилоскопируясь    prefix=дактилоскопир
inf=наформовать    ap=наформовав    prefix=наформов
 Части инфинитива и деепричастия справа от префикса дает нам правило генерации деепричастной формы из инфинитивной для новых инфинитивов. Этих правил относительно немного, несколько сотен пар, причем первая 20-ка дает половину использований (без учета частот самих слов): 
 rule        share    cumulative
4:вая             11.38    11.38
6:ваясь            6.68    18.05
4:вав              5.85    23.90
4:нув              3.45    27.35
6:руя              3.24    30.59
6:вавшись          2.95    33.54
8:руясь            1.79    35.34
6:нувшись          1.73    37.07
4:тив              1.39    38.46
4:рив              1.37    39.82
4:лив              1.35    41.17
4:ляя              1.32    42.50
4:тав              1.17    43.66
6:ляясь            1.16    44.82
4:нив              1.16    45.98
6:тившись          1.05    47.03
4:чив              1.00    48.03
4:кав              0.99    49.02
4:кая              0.97    49.99
4:чая              0.93     50.92 
 Будем обучать многоклассовый классификатор на базе XGBoost, который для заданной цепочки символов инфинитива выдаст номер правила, которое даст форму деепричастия. Исходный текст полной программы  доступен по ссылке . Последовательность действий стандартная: 1) подбираем оптимальное количество деревьев через кроссвалидацию и xgboost.cv 2) обучаем классификатор 3) применяем обученный классификатор на новые инфинитивы (см. следующий раздел), используем выбранные правила для генерации деепричастий. 5. Применение обученного классификатора для генерации деепричастий Опять используем SQL словарь, чтобы получить список инфинитивов без деепричастий: 
 select E_inf.name, S1.name
 from sg_entry E_inf
 join sg_class C_inf on C_inf.id=E_inf.id_class and C_inf.name='ИНФИНИТИВ'
 join sg_entry_coord EC_inf on EC_inf.id_entry=E_inf.id
 join sg_coord C1 on C1.id=EC_inf.icoord and C1.name='ВИД'
 join sg_state S1 on S1.id_coord=C1.id and S1.id=EC_inf.istate
 where not exists (select *
                           from sg_entry E_ap
                           join sg_class C_ap on C_ap.id=E_ap.id_class and C_ap.name='ДЕЕПРИЧАСТИЕ'
                           join sg_link L on L.id_entry1=E_ap.id and L.id_entry2=E_inf.id
                         )
 Он выдаст несколько тысяч инфинитивов с признаками глагольного вида: 
 португализироваться    СОВЕРШ
развиртуализироваться    НЕСОВЕРШ
реактивироваться    СОВЕРШ
самокастрироваться    СОВЕРШ
самопрезентоваться    НЕСОВЕРШ
сериализироваться    СОВЕРШ
факторизироваться    СОВЕРШ
экстрагироваться    НЕСОВЕРШ
...
 Сохраняем его в tab-separated values файле с именем adverbial_participles.tsv. Этот файл загружается  программой на питоне . К записям в нем применяется обученная модель классификации, в результате чего получается примерно такой текстовый файл: 
  дп( походя, НЕСОВЕРШ, походить )
 дп( кооптируя, НЕСОВЕРШ, кооптировать )
 дп( хаотизируя, НЕСОВЕРШ, хаотизировать )
 дп( хаотизировав, СОВЕРШ, хаотизировать )
 дп( романизировав, СОВЕРШ, романизировать )
 дп( сенсибилизируя, НЕСОВЕРШ, сенсибилизировать )
 дп( сенсибилизировав, СОВЕРШ, сенсибилизировать )
 дп( цифровизуя, НЕСОВЕРШ, цифровизовать )
 дп( цифровизовав, СОВЕРШ, цифровизовать )
...
 После визуальной верификации и коррекции можно добавлять эти новые деепричастия в  скрипт сборки русской словарной базы .",SQL словарь||machine learning||xgboost||деепричастие||лексика||лексикон||русский язык
110,      Большой рефактиринг C++ исходников грамматического движка  ," Закончил первый из двух запланированных больших рефакторингов для проекта  https://github.com/Koziev/GrammarEngine : теперь строковые классы  FString  и  UFString  являются прямыми наследниками std::string и std::wstring соответственно. Цель рефактиринга - заменить в коде все древние велосипеды на стандартные вещи, присутствующие либо в стандартной библиотеке, либо в Boost'е (например, всевозможные  алгоритмы для работы со строками ). Кроме чисто эстетических последствий это должно упростить любую интеграцию C++ кода движка - меньше преобразований для строковых типов, проще развивать код.",c++||грамматический словарь||исходники
111,      Сравнение оптимизаторов nadam и rmsprop с помощью F-теста  ," Еще одна серия  экспериментов  с  моделью для векторизации символьного представления слов . Сравним две штатных реализации  оптимизаторов в Keras  - rmsprop и nadam. Фиксируем batch_size значением 250, делаем несколько запусков обучения модели для каждого варианта оптимизатора (см. строку 356 в файле  wordchar2vector_trainer.py ). Эксперименты вычислительно очень затратны, по несколько часов на один прогон, поэтому объем выборок будет очень небольшой, всего несколько значений. Достоверно оценить нормальность распредения достигаемой точности моделей по таким выборкам затруднительно. Из общих соображений касательно стохастичности процесса обучения нейросеток тоже затрудняюсь что-то предположить. Поэтому остается применить стандартный статистический прием - закрыть глаза и произнести ""верю, что нормальное!"", и спокойно применять  f-тест Фишера . Выборки выглядят на данный момент так: 
nadam: [0.92000000000000004, 0.91900000000000004, 0.91799999999999993, 0.93000000000000005]
rmsprop: [0.88700000000000001, 0.80400000000000005, 0.83900000000000008] Итак, мы хотим понять, является ли наблюдаемое влияние оптимизатора на точность модели закономерным следствием свойств алгоритма, или разница в средних точностях является чисто случайным эффектом. Иначе говоря, у нас есть  нулевая гипотеза : выбор оптимизатора нейросетки для данной модели не влияет на точность. Альтернативная гипотеза будет звучать так: алгоритм nadam в среднем дает лучшую точность, чем rmsprop. Используем  реализацию одностороннего теста Фишера в scipy : 
 import scipy.stats

res = scipy.stats.f_oneway(samples_nadam, samples_rmsprop)
print('one-way p={}'.format(res.pvalue))
 Получаем: 
p=0.0120640226691 Таким образом, при уровне значимости 0.05 мы на основе полученного значения p можем смело (риск чуть выше 1%) отвергать нулевую гипотезу и принять, что  nadam действительно дает лучшее качество на данной модели на данных обучающих значениях в сравнении с rmsprop . Тетрадка с расчетами  выложена в репозиторий .",keras||neural nets||нейросети||статистика
112,      Коэффициент Пирсона для корреляции между batch_size и достигаемой точностью нейросетевой модели  ,"  Коэффициент Пирсона  получается около  -0.5 , то есть о линейной корреляции между размером батча и максимальной достигаемой точностью  нейросетки  говорить очень трудно. Расчет добавлен в  тетрадку , в самом конце. Визуально зависимость тоже почти не видна, есть только некий тренд на понижение, о чем говорит и знак коэффициента: Предыдущее сообщение по теме -  тут",neural nets||neuronet||статистика
113,      Визуализация влияния batch_size на качество модели wordchar2vector - ч.3  ," Продолжение поста  https://kelijah.livejournal.com/237155.html . То, что казалось достаточно очевидным и логичным, стало интересным при увеличении количества исходных данных. Я погонял обучение  модели  на новых batch_size и даже по 2 раза для некоторых batch_size, и получается вот такое облако для максимальной достигаемой точности при разных batch_size:",neural nets||neuronet||word embedding||word2vec||word2vector
114,      Theano 1.0.1 с cuda 9.0 поломан?  ," Что-то с новым  релизом Theano  1.0.1 нечисто. По крайней мере при работе с Cuda 9.0 под убунтой и вторым питоном. Уже на второй модели вижу, что сетка отказывается обучаться - тупо loss на валидации стоит на одном значении с точностью до 4го знака несколько эпох подряд и баста, привет early stopping. Версии: inkoziev@Ubuntu-1604-xenial-64-minimal:~ /polygon/AttrExtractor_srv/py$ python Python 2.7.12 (default, Dec  4 2017, 14:50:18) [GCC 5.4.0 20160609] on linux2 Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import theano Using cuDNN version 7101 on context None Mapped name None to device cuda0: GeForce GTX 1080 (0000:01:00.0) >>> print theano.__version__ 1.0.1 >>> При этом на этой же машине последний Tensorflow дает замечательные результаты для той же самой модели при запуске с KERAS_BACKEND=tensorflow. Хотя битва с tf у меня была длительная из-за того, что  Cuda 9.1 не поддерживается",keras||python||tensorflow||theano
115,      Визуализация влияния batch_size на качество модели wordchar2vector - ч.2  ," В комментарии к  предыдущему посту  коллега  p2004r  подсказал замечательную мысль по поводу того, что надо бы смотреть не на количество эпох, а на количество градиентов, которые увидела сетка при обучении. И получается вот такая замечательная картина. 1) Смотрим по-старому, динамика обучения в зависимости от числа эпох: 2) Теперь то же самое, но в зависимости от количества батчей (масштаб по OX сделан криво, поэтому цена деления такая странная - надо домножать на число сэмплов в обучающем датасете): То есть начиная с какого-то размера батча (>100 в данном случае) сетка обучается примерно с одинаковым темпом для разных batch_size. Разница только в том, что для каких-то значений обучение обрывается раньше, и максимальная точность не достигается. Новая тетрадка  выложена в репозиторий . PS: сделан расчет еще для нескольких batch_size и получился вот такой график максимально достижимой точности:",neural nets||neuronet||нейросети
116,      Визуализация влияния batch_size на качество модели wordchar2vector  ," Сама модель  описана тут , это просто seq2seq автоэнкодер для цепочек символов. Реализующий ее на Python+Keras код  лежит тут . Тетрадка для визуализации доступна по  этой ссылке . В ходе обучения в файле сохраняем instance accuracy - долю слов, которые точно восстановлены декодером. Эта метрика показана на графиках. На графиках видно, что есть некий оптимум в размере батча, и вообще batch_size для данной модели влияет очень сильно:",autoencoder||keras||neural nets||sequence2sequence||vector space model||word embedding||word2vec||word2vector
117,      Сравнение NVidia GTX 980 и GTX 1080 на задаче обучения нейросетки: 40% прироста производительности  ," Описание задачи:  https://github.com/Koziev/chatbot/blob/master/PyModels/trainers/README.wordchar2vector.md На питоне тренировка модели описана этим кодом:  https://github.com/Koziev/chatbot/blob/master/PyModels/trainers/wordchar2vector_trainer.py Итак, код идентичен, датасеты тоже. Немного отличаются версии Theano, CUDA и CudNN, возможно какие-то оптимизации дают дополнительное преимущество GTX 1080. Кроме того, хост с GTX 1080 имеет на борту i7-6700 @ 3.4 GHz, а GTX 980 работает с i7-4790K CPU @ 4.00GHz. Одна эпоха обучения нейросетки длится на  GTX 980  примерно  127 секунд , на  GTX 1080  примерно  78 секунд",gpu||gtx 1080||nvidia||нейросети
118,"      Установка Theano v.1.0 и ошибка ""pygpu was configured but could not be imported""  "," По горячим следам сегодняшней борьбы с установкой Theano v.1.0 на новом рабочем сервере с Ubuntu 16.04 и GTX 1080. Разрабы Theano окончательно  выпилили поддержку старого бэкэнда для работы с GPU , так что прописать device=gpu в конфиге, как это было в Theano 0.xx, уже не получается. Необходимо установить pygpu и libgpuarray, а в .theanorc писать уже device=cuda0 или типа того. Но даже после установки всех запчастей от NVidia (поставил самый распоследний драйвер, CUDA 9.1 и соответствующую CuDNN) попытка import theano заканчивается ошибкой с текстом ""pygpu was configured but could not be imported"". После часа протирания фар и стучания дверями, нашел работающий вариант - см. по ссылке  https://stackoverflow.com/questions/39297995/getting-pygpu-was-configured-but-could-not-be-imported-error-while-trying-with  комментарий, начинающийся c ""Install the blas library seems enaugh."". А комментарий выше содержит правильную инструкцию по собственно установке pygpu и libgpuarray. И чтобы 2 раза не вставать - еще пара полезных при установке nvidia cuda и cudnn ссылок: https://devtalk.nvidia.com/default/topic/1027213/cuda-setup-and-installation/unable-to-install-cuda/ https://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04",theano
119,"      Датасеты по сочетаемости слов в группах из 2, 3 и 4 слов (mutual information)  "," В репозитории  https://github.com/Koziev/NLP_Datasets/tree/master/MutualInfo  выложены датасеты со статистикой по устойчивым сочетаниям слов. Датасеты получены с помощью C# кода, выложенного  тут  (см.  описание ) и  урезаны  до 100,000 первых записей, так как выложить полные файлы размером более 2 Гб на гитхаб невозможно. Внутри файлов можно увидеть такие данные: в    _num_    году    0.001967549091205 до    сих    пор    0.00155391998123378 в    конце    концов    0.00105052231810987 тем    не    менее    0.00100939883850515 по    крайней    мере    0.000935689778998494 к    тому    же    0.000906699395272881 на    самом    деле    0.000905484252143651 во    всяком    случае    0.000725110352504998 на    этот    раз    0.000597159843891859 с    тех    пор    0.000531908415723592 _num_    млн    рублей    0.000472747866297141 в    настоящее    время    0.000471909705083817 на    следующий    день    0.000440214615082368 судя    по    всему    0.000434376997873187 ни    разу    не    0.000423699559178203 в    этом    году    0.000418924260884523",N-граммы||датасеты||статистика
120,      PyParser - обертка синтаксического парсера для Питона (пре-альфа)  ," Пока собрано и проверено только для Python 2.7 Windows 64 (Anaconda). Исходники парсера, сильно отрефакторенные, с новой иерархией для введения абстрагирования от способа вывода результатов парсинга, лежат в  репозитории . Сборка выполнена с помощью VisualStudio 2015, соответствующее решение Parser.sln лежит в  этой папке .  Обертка  для вызова C++ кода из питоновского сделана с помощью  boost::python . В проекте пока нет установки пакета, поэтому проверить и  использовать можно только руками. В  папке  лежат готовые бинарники pyparser.pyd и libdesr.dll. Разумеется, также нужны файлы словарной базы (можно взять из дистрибутива парсера,  выложенного тут ). Пример выполнения частеречной разметки на Питоне: from __future__ import print_function from pyparser import PyParser p = PyParser() p.load(u'e:/mvoice/lem/bin-windows64/dic tionary.xml', 0, -1) tokens = p.tag1(u'кошки спят на веранде', True, False) for token in tokens:     print(u'{}\t{}\t{}'.format(token[0], token[1], token[2])) Результат: Ленивые ленивый ПРИЛАГАТЕЛЬНОЕ кошки   кошка   СУЩЕСТВИТЕЛЬНОЕ спят    спать   ГЛАГОЛ на      на      ПРЕДЛОГ веранде веранда СУЩЕСТВИТЕЛЬНОЕ Парсер также может выдавать морфологические теги для каждого слова (падеж, число и т.д.). Синтаксический анализ и чанкинг пока не подцеплены. Подробная документация с всеми примерами и объяснением параметров будет сделана потом, когда будет готов стандартный установщик пакета. PS: добавлен скрипт setup.py для установки собранного модуля pyparser штатным механизмом питона. Для этого надо перейти внутрь каталога src копии репозитория (там лежит  setup.py  и прочие запчасти) и выполнить: pip install . Будет установлен пакет Solarix, в котором есть модуль pyparser.",boost::python||c++||part-of-speech tagging||python||исходники||русский язык||частеречная разметка
121,      Недобрые предчувствия по поводу package hell в питоне  ," Преамбула такая. Я делаю сервис, который занимается извлечением ключевых атрибутов из слабоструктурированных текстов. Предметная область - нормативно-справочная информация, машиностроение. Анализируемые тексты выглядят как короткие строки типа ""ПРОВОД БИФЭЗ-Н 3Х1,0 КР.3000 ТУ 16-505.945-76"". Извлекаемые атрибуты - короткие строки типа ""Стандарт на ТУ""=""ТУ 16-505.945-76"". Так как это часть ""кровавого энтерпрайза"", то кроме модной и приятной темы машинлёрнинга, нейросеток, GPU и прочего хипстерского набора, в проекте есть скучнотища в виде веб-сервиса для доступа и хранения эталонных образцов разбора в реляционной базе данных. Все это делаю на Питоне, стараясь оставаться в максимально менстримовой области используемых библиотек, поэтому Keras, Tensorflow, Flask, SqlAlchemy и т.д. И вот второй раз возникает проблема с работоспособностью конкретных версий питоновских пакетов с конкретным окружением. Первый раз это произошло в ходе испытаний  слоя CRF из keras_contrib , где в результате проблем с работой под Theano мне пришлось переключаться во-первых на Tensorflow, но самое главное - откатываться на конкретные версии Keras и keras-contrib, и наконец, переключится для тестов на третью ветку питона, ибо на 2.x tensorflow под Win не фурычит. Теперь ситуация потенциально хуже. Я проверяю работу из  SqlAlchemy  с базой данных Oracle 11g. Дело обстоит под Win64, в системе установлен 32-битный клиент Oracle (специфика основного софта компании). Ставлю  cx-Oracle  (текущая версия 6.1), пробую: # -*- coding: utf-8 -*- from __future__ import print_function import sqlalchemy oracle_db = sqlalchemy.create_engine('oracle://SCADM IN:********@SEMANTIC') connection = oracle_db.connect() result = connection.execute(""SELECT count(*) FROM RDM_OBJECTS"") for row in result:     print( row ) На строке с connect() получаю исключение с текстом ошибки ""'twophase' is an invalid keyword"" и стектрейс, ведущий куда-то вглубь. Ок, гуглим, находим  статью . Судя по объяснениям, где-то внутри cx_Oracle есть функция, проверяющая оракловую аутентификацию, которая раньше принимала аргумент twophase, а в 6.x версии аргумент выпилили под предлогом ""нафиг оно не нужно нигде"". А SqlAlchemy аргумент при вызове указывал. Советуют откатиться до cx_oracle 5.3. Пытаюсь откатиться - ошибка установки, pip отказыватся ставить cx_oracle==5.3! Этот путь закрыт. Второй совет - поднятся до бета-версий SQLAlchemy: 1.2.0b1 и cx_Oracle : 6.0b1. Пробую - все ставится, соединение к ораклу проходит, запрос выполняется, бинго! И вот на этом шаге любой человек, который как-то связан с деплойментом своего софта на других хостах (доступ к которым у меня физически вообще нет - таковы требования ИБ на предприятиях), должен сильно напрячься. Потому что начинаются манипуляции с версиями пакетов, необходимые для подгонки под текущее окружение, над которым у нас может не быть полного контроля. Во-вторых, должны напрячься QA-спецы. Потому что надо проверять работоспособность в условиях, когда установлены бета-версии пакетов, что обязательно повлечет в будущем переход на транковые версии и необходимость перенастройки тестового окружения. Для сравнения - ситуация с утилитой для Database Migration, которую я написал на C++. Она поддерживает операции с базами данных Oracle, SQL Server и FireBird. Доступ к БД сделан почти на самом нижнем уровне. Для оракла это OCI и  OTL , для FireBird - нативный клиент, SQL Server - старина ODBC. Так вот за несколько лет эксплуатации у разных клиентов в относительно разном окружении проблем с доступом к БД из-за DLL hell и версионированием этой части софта не было ни разу. Что, конечно, не отменяет прочих проблем разработки на C++. И, если уж сравнивать с C#. За три года разбора проблем с развертыванием веб-сервисов, написанных на WCF, неприятные проблемы с депройментом были пару раз. В том числе из-за версий .NET Framework, которые могут быть более старые, чем при разработке. И, например, log4net может отказаться нормально работать в таком окружении из-за своего внутреннего бага с завязкой на какую-то сборку и проблем с инициализацией.",c||c++||python||оффтопик
122,      Дистрибутив синтаксического парсера под win64  ," Архив (94 Мб) для MS Windows 64 со всеми актуальными моделями и русской словарной базой доступен по ссылке на странице  тут . Кроме того, выложен  исходный код нового тренера модели частеречной разметки , в которой добавлена поддержка conllu-корпусов из  http://universaldependencies.org/",дистрибутив||парсер
123,      Новая модель для синтаксического парсинга  ," Я немного расширил набор фич в модели синтаксического парсинга и сделал предварительный grid search по метапараметрам. Пока по предварительным замерами на валидации старая модель давет точность определения родителя примерно 96.83%, а новая модель дает минимум 98.54%. Файлы новой русской синтаксической модели (предварительные) выложены в репозиторий:  syntax.codebook  и  syntax.model . После того, как сработает early stopping в  тренере модели  я планирую погонять финальную версию на текстах и затем выложить дистр на  сайте",dependency parser||исходники||парсер||русский язык||синтаксис||синтаксический анализатор||синтаксический разбор
124,      Chunker - новая модель в парсере для разбора предложений на составляющие  ," Иногда анализ текста сводится к определению групп слов, образующих составляющие первого уровня относительно корня в терминах дерева зависимостей (см. описание  shallow parsing ). Например, для предложения: Совещание происходило на квартире генерала Науменко. можно выделить следующие группы (составляющие): 1)  Совещание 2)  происходило 3)  на квартире генерала Науменко Третья группа включает в себя четыре слова, образующих отдельную сущность - обстоятельство места. Если синтаксические связи  внутри  такой группы нам интересны, то можно попробовать ограничится определением границ групп. Это в общем случае проще с вычислительной точки зрения и, значит, быстрее. Теперь в  Парсере  есть специальный режим разбора, включаемого ключом -parser 2. Например: parser -verbose -tagger 0 -parser 2 -eol -d ../ru/dictionary.xml -i input.txt -o output.xml означает, что будет разобран текст в файле input.txt, каждая строка которого содержит отдельное предложение (-eol), и эти предложения будут подвергнуты частеречному анализу (-tagger 0) и разбивке на составляющие (-parser 2). Выходной XML файл будет содержать такую информацию:               Для каждого слова отдельный тег в группе   содержит атрибут is_chunk_starter, определяющий, является ли слово началом новой группы. В нашем случае видно, что предлог ""на"" начинает обстоятельство места, а остальные слова в этой группе помечены is_chunk_starter='0': Чанкер использует отдельную вероятностную модель на базе Conditional Random Fields - см. для справки  исходник на C# . Файлы готовой модели для русского языка можно скачать из репозитория - файлы  chunker.codebook  и  chunker.model . В коде парсера чанкер представлен C++ классом ChunkerModel - см.  ChunkerModel.h  и  ChunkerModel.cpp . В ближайшее время планирую потестировать парсер и затем выложить архив с полным готовым дистрибутивом  на сайте . Пока собранный свежий Parser.exe для win64 можно взять  здесь .",chunking||nlp||shallow parser||исходники||парсер||русский язык
125,      Тетрадка Colaboratory с экспериментами для вариационными и обычными автоэнкодерами для предложений  ," Рабочая тетрадка, которую я сейчас использую в Colaboratory для проверки различных архитектурных параметров двух генеративных текстовых моделей для чатбота: 1) простой сжимающий автоэнкодер на базе sequence2sequence архитектуры 2)  вариационный автоэнкодер  (немного переработан код отсюда  https://github.com/twairball/keras_lstm_vae/blob/master/lstm_vae/vae.py ) Тетрадь доступна по ссылке:  https://drive.google.com/file/d/1aWwJeve9yuH9RrrfO0gq5dpuPKxDw0cC/view?usp=sharing В тетрадке для удобства работы сделана загрузка готовых датасетов из моего гуглодиска внутрь докер-контейнера. Эти два файла ( vtexts.npz  и  word2vec.pkl ) были подготовлены скриптом  https://github.com/Koziev/pushkin/blob/master/prepare_vae_dataset.py , так что при необходимости можно взять другие  векторы слов вместо word2vec или тренироваться на другом наборе предложений. Код для автоэнкодеров в нормальном виде лежит тут:  https://github.com/Koziev/pushkin/blob/master/lstm_ae.py Обучение выглядит примерно так (осторожно, большой скрин):",autoencoder||unsupervised feature learning||variational autoencoder||vector model
126,      Большие братья смотрят за тобой! Но некоторые косят. (оффтопик)  ," На фоне "" Strava’s data lets anyone see the names (and heart rates) of people exercising on military bases "" конечно мелочь, но: Сделал заказ на Яндекс.Такси из дома с планшета - мое местоположение автоматически определилось с точностью до дома, жаль подъезд не подцепился в заказ.",забавные моменты
127,"      Colaboratory - бесплатно, медленно, сгодится для экспериментов с подбором гиперпараметров ML моделей  "," За три дня экпериментов с  Colaboratory  лично убедился что: 1) Заливка датасетов туда и обратно немного напрягает. 400-метровый CSV с датасетом скачивается внутрь контейнера из google drive минут 5. Воспользовался рецептом, описанным в официальном howto  здесь , то есть залил файлик в свой GD, определил его file ID через расшаривание по ссылке, скачал через googleapiclient и так далее. Потом перекачал скачанные байты во временный файл внутри контейнера. В общем, минут на 15-20, если делать все второй раз после превращения контейнера в тыкву по истечении 12 часов. 2) Для модели, размечающей данные с помощью рекуррентной сеточки с использованием  keras_contrib.layers.CRF , обучение на Tesla K80 в Colaboratory идет медленнее примерно в 2 раза в сравнении с железным 4-ядерным i7-4790 4 ГГц. Сравнил по времени, затраченному на одну эпоху обучения модели. Спасибо tensorflow, модель на CPU съедает все четыре ядра почти на 100%.",colaboratory||gpu||keras||keras-contrib||neural nets||python||tensorflow
128,      Запустил обучение модели wordchar2vector на Tesla K80 в гугловском Colaboratory  ," Описание халявы тут  https://habrahabr.ru/post/348058/ Запустил там обучение своей  модельки wordchar2vector  из репозитория  https://github.com/Koziev/chatbot : Судя по бенчмарку ETA работает это чудо примерно в 4-5 раз медленнее, чем моя железная GTX 980. Вообще ощущение, что физически эта штука там неслабо так делится между  халявщиками",chatbot||gpu||python||teska k80
129,"      Генерация ответов да/нет в чатботе - опять градиентный бустинг лучше, чем нейросетка  "," Описание задачи и решения для выбора ответов ""да"" и ""нет"" для заданных предпосылки и вопроса выложено  тут . Тренер модели на движке xgboost - в файле  https://github.com/Koziev/chatbot/blob/master/PyModels/xgb_yes_no.py . Точность примерно 99.8% Тренер для нейросетевого классификатора (Keras) - в файле  https://github.com/Koziev/chatbot/blob/master/PyModels/nn_yes_no.py",chatbot||python||xgboost||нейросети||чатбот
130,      Кривые обучения для модели wordchar2vector  ," Модель для  чатбота  была описана в  этом посте . С того времени в код были добавлены новые архитектуры нейросети, доработан механизм задания параметров при запуске из командной строки и расширена документация - теперь все детально расписано тут  https://github.com/Koziev/chatbot/blob/master/PyModels/trainers/README.wordchar2vector.md . Далее - сравнение разных архитектур нейросети в ходе обучения. Можно видеть, что конкретно на данной задаче более простой рекуррентный автоэнкодер на LSTM дает лучшее качество в сравнении с более сложными моделями. Причер вариант bidirectional LSTM в сравнении с обычным слоем LSTM практически не добавляет финальной точности - красная и желтая кривые: А вот сравнение двух моделей с одинаковой архитектурой (простой рекуррентный автоэнкодер с bidirectional LSTM), которые отличаются только параметром trainable у объекта класса keras.layers.Embedding. Другими словами, одна модель на всем протяжении обучения использует постоянные векторы для символов (начальная инициализация как 1-hot), вторая подстраивает эти векторы по ходу обучения. Подстройка векторов (розовая линия) позволяет сетке поначалу обучаться быстрее, но затем результат становится неотличим от варианта с фиксированными векторами;",chatbot||keras||vector model||vector space model||word2vector||чатбот
131,      Старина DLL hell вернулся  ," Он вернулся и поселился в экосистеме питона, где под него даже запилили костыледержалку virtualenv. Особенно часто я встречаю его при работе с tensorflow и вообще ML. Вот давеча прочесывал SO "" Why my tensorflow-gpu runs only on cpu?",забавные моменты
132,      Непонятная эффективность XGBoost модели для вычисления релевантности текста и вопроса  ," (продолжение темы про модели для  чат-бота , предыдущий текст  тут ) В репозиторий проекта выложены тренеры для двух альтернативных моделей, вычисляющих релевантность предпосылки и вопроса к этой предпосылке: nn_relevancy.py  - нейросетка; xgb_relevancy.py  - решение на базе XGBoost. Загадочной особенностью данной задачи является необъяснимая эффективность XGBoost, или неэффективность нейросетевого решения. На одном и том же датасете нейросетка дает на валидации стабильно точность в районе 0.96...0.97, а градиентный бустинг выбивает стабильно больше 0.99 при кратно меньших затратах времени. Постановка задачи Модель должна определять, задан ли вопрос к заданному тексту, или нет. Например, пример релевантной пары: T:  28-летний Алексей Орловецкий обвиняется в мошенничестве. Q:  В чем обвиняется Орловецкий? Ответ в данной модели не рассматривается вообще, поэтому следующие варианты признаются релевантными (ответ приведен в качестве пояснения): T:  Тихонов остается в сборной до Олимпиады. Q:  Остается ли Тихонов в сборной? A:  Да T:  Начало матча сложилось для гостей неудачно. Q:  Удачным ли было начало матча для гостей? A:  Нет Решение на XGBoost Выбран максимально простой способ представления текста предпосылки и вопроса - через шинглы, то есть символьные N-граммы заданной длины, взятые из текста со смещением в 1 символ. Длина шинглов настраивается через переменную SHINGLE_LEN, и сейчас имеет значение 3. В результате для одного предложения получается крайне разреженная матрица шириной около 10,000 столбцов, из которой только десяток или два заполнены. Далее делаем вот такую очевидную манипуляцию с векторами шинглов:    ps = set(premise_shingles)    qs = set(question_shingles)    common_shingles = ps & qs    notmatched_ps = ps - qs    notmatched_qs = qs - ps Получается разреженная матрица шириной примерно 30,000 столбцов. Именно она подается в качестве данных в XGBoost. Обычные вещи типа автоматического подбора количества шагов бустинга через early stopping в коде также есть. Таким образом, набор признков не содержит никаких синтетических фич типа косинуса между векторами для двух предложений или LSA-векторов. Тем не менее, при заданной максимальной глубине деревьев = 4 модель строит очень качественный вычислитель релевантности, и я пока не понимаю, как это работает.",chatbot||neural nets||python||xgboost||градиентный бустинг||исходники||чатбот
133,      Три варианта рекуррентно-сверточных сетей в задаче определения длины ответа  ," (предыдущий пост с описанием моделей  чат-бота  тут:  https://kelijah.livejournal.com/232313.html ) Код для тренировки вспомогательной модели, которая определяет число слов ответа для заданной предпосылки и вопроса выложен тут  https://github.com/Koziev/chatbot/blob/master/PyModels/nn_answer_length.py . Постановка задачи Задача заключается в следующем. Допустим, есть тройка предложений - предпосылка, вопрос и ответ: T:  Боевики курдских военизированных формирований занимают Киркук. Q:  Кто занимает Киркук? A:  Боевики курдских военизированных формирований В данном случае ответ содержит 4 слова. А в примере: T:  19 января Никите исполняется 5 лет. Q:  Сколько лет исполнилось Никите в январе? A:  5 ответ содержит одно слово. Задача сводится к стандартной классификации вариантов от 1 слова до 5-7 слов. Выбор варианта архитектуры Глобальный параметр NET_ARCH в программе позволяет выбрать одну из трех альтернативных архитектур, описанных далее. Самая точная из них - сверточные слои, поверх которых работают рекуррентные слои. На то есть вполне рациональная причина - на данную архитектуру очень хорошо ложатся языковые структуры в обрабатываемых сэмплах, в частности преимущественно короткие ребра в синтаксическом графе. Простейшее решение - один рекуррентный слой Самый простой способ решения - классический подход с использованием LSTM слоя (выделен зеленым фоном), который упакует цепочки слов предпосылки и вопроса в два вектора фиксированной длины. Затем эти векторы соединяем и обрабатывает несколькими полносвязными афинными слоями: Достигается точность ~0.89. Параллельные рекуррентные и сверточные слои Добавим на одном уровне с рекуррентным слоем несколько сверточных слоев (красноватый слой) с GlobalMaxPooling1D. Затем выходы всех слоев склеиваем и опять-таки направляем на классификатор: Достигаемая точность 0.95 Сверточные слои, поверх которых работает рекуррентный слой Идея, реализуемая в данной архитектуре, проста. Сверточные слои выделают словосочетания разного типа, включая синтаксические паттерны. Рекуррентный слой доставляет ""имена"" найденных паттернов к классификатору.  Некоторые люди  назвали бы группу сверточных слоев spatial pooler'ом, а рекуррентный слой - temporal pooler'ом, работающими в режиме supervised learning: Достигаемая точность - 0.99.",chatbot||convolutional networks||keras||language model||lstm||python||рекуррентные сети||чатбот
134,      Тренировка и использование модели посимвольного встраивания слов для чатбота  ," (Начало тут  https://kelijah.livejournal.com/231141.html ) Часть моделей  чат-бота  при работе используют разные способы векторизации слов. Один из использованных алгоритмов векторизации заключается в упаковке посимвольного представления слова с помощью сжимающего рекуррентного автоэнкодера: На вход подается цепочка символов слова. Эта цепочка упаковывается в вектор фиксированной длины с помощью LSTM-слоя. Вектор, получаемый на выходе этого слоя содержит всю информацию о символах, 2-граммах и т.д. в исходном слове. Это позволяет прочим моделям учитывать как семантическую, там и морфологическую близость слов. К примеру, слова ""использован"" и ""использовал"" в большинстве языковых контекстов образуют близкие по смыслу предложения благодаря общему корню. В других ситуация важную информацию несут суффиксы, окончания или приставки. Посимвольные встраивания слов доставляют эту информацию. Выходная часть автоэнкодера, как обычно, восстанавливает исходную цепочку символов слова из вектора. Для тренировки посимвольных встраиваний необходимо выполнить два шага. Во-первых, сгенерировать список слов. Эту задачу выполняет скрипт  prepare_wordchar_dataset.py . Он читает несколько других датасетов и текстовых файлов и сохраняет итоговый список слов в файле  ../tmp/known_words.txt . Вариант этого файла выложен в репозиторий, поэтому первый шаг можно пропустить. Во-вторых, запустить тренировку модели скриптом  wordchar2vector.py . Скрипт предлагает два режима выполнения - тренировка модели с нуля или загрузка ранее натренированной модели для векторизации нового списка слов. Второй режим позволяет быстро векторизовать лексикон после добавления новых предложений в исходные датасеты, не переучивая нейросеть. Тренировочный скрипт сохраняет на диске также саму модель (файлы с метаданными для восстановления нейросетки и веса). Поэтому новые слова в поступающих от собеседника фразах можно векторизовать на лету, если в готовом наборе векторов их еще нет. Тренировка модели сопровождается наглядной визуализацией текущего состояния модели:",autoencoder||chatbot||keras||lstm||python||vector space model||исходники||чатбот
135,      Предварительное сравнение точности CRFSuite и LSTM-CRF из keras.contrib  ," Задача - анализ строковых данных из номенклатурного справочника. Данные представляются цепочкой символов, разбивка на слова невозможна из-за специфики задачи. Каждому символу модель должна присвоить флаг в зависимости от того, относится ли символ к извлекаемой сущности. Сравниваемые модели используют одинаковый датасет с идентичной разбивкой на train/val. 1) Решение на базе классического NLP алгоритма на базе CRF использует реализацию  CRFSuite  и вручную выбранные фичи. Обучение длится примерно 20 часов. Достигаемая точность per char равна примерно  0.9947 2) Решение на базе  keras-contrib.CRF . Никаких ручных фич нет, на вход bidir  LSTM  слоя подаются векторы исходных символов, настраиваемые через  Embedding  (см.  референсную реализацию , я добавил туда лишь EarlyStopping и вычисление per instance accuracy). Обучение на GPU + Tensorflow идет примерно 1 час. Достигаемая точность per char равна  0.9988",crf||crfsuite||keras||keras-contrib||machine learning||python||нейросети
136,"      Война с keras.contrib.CRF, Theano и Tensorflow  "," По рабочей необходимости прочесываю все современные нейросетевые архитектуры и решения для выполнения sequence labeling. Сейчас боевое решение основано в том числе на старом добром CRFSuite через питоновскую обертку  python-crfsuite  и при разметке номенклатурных данных достигает неплохой точности от 99.5% до 97.8% в зависимости от категории извлекаемых данных. Среди архитектур, которые я пробовал, есть замечательная штука под названием LSTM+CRF. Взял топ результатов поиска реализаций в гугле, попробовал каждую, написанную под Tensorflow, Theano или Keras, в частности: https://github.com/Hironsan/anago https://github.com/LiyuanLucasLiu/LM-LSTM-CRF и еще парочку. В силу разных причин все они не захотели работать, я даже запостил соответствующих issue в одну из библиотек. Наконец,  keras_contrib.CRF . С этой реализацией тоже пока не выгорело, причем на разбирательство уже потрачено уйма рабочего времени. Прежде всего,  как выяснилось , реализация не работает с актуальной версией Keras. Но можно откатиться на Keras  2.0.6  и проблема решается. Но фактически обучение с KERAS_BACKEND=theano не идет, то есть видим вот такую безрадостную картинку: Среди открытых багов есть похожий  CRF is broken with Theano backend  , но запустить с Tensorflow 1.4.0 у меня пока тоже не получается - вылезает ошибка с размерностью тензоров. PS: под Ubuntu 16.04 удалось запустить нормальное обучение в варианте с Keras==2.0.6 и текущим Tensorflow. Вот такая она, цена поддержки разных бэкэндов в Keras:",keras||keras-contrib||lstm-crf||python||tensorflow||theano
137,      Исходники чатбота после рефакторинга  ," Текущие исходники кроме тренировочных скриптов выложены тут  https://github.com/Koziev/chatbot/tree/master/PyModels/bot Ядро диалоговой системы  отделено от фронтэнда, что позволило минимальными усилиями реализовать простые фронтэнды  в консоли  и  для Telegram :",chatbot||python||исходники||чат-боты||чатбот
138,      Исходники чат-бота (диалоговой системы): утилита для генерации вопросно-ответного датасета  ," Продолжение  https://kelijah.livejournal.com/231141.html . Исходный текст утилиты (C#, проект для VS Studio 2015) лежит тут  https://github.com/Koziev/chatbot/tree/master/CSharpCode/GenerateQA Далее подробное описание. Вспомогательная утилита для  чат-бота , реализованная на C# как консольная утилита для MS Windows. Генерирует датасет с тройками предложение ПРЕДПОСЫЛКА-ВОПРОС-ОТВЕТ, например: T: Памперсы имеют индикатор влагонасыщения Q: памперсы имеют что? A: индикатор влагонасыщения T: Памперсы имеют индикатор влагонасыщения Q: памперсы что имеют? A: индикатор влагонасыщения Больше примеров можно увидеть тут  https://github.com/Koziev/NLP_Datasets/blob/master/QA/premise_question_answer4.txt Используются результаты работы утилиты  https://github.com/Koziev/chatbot/tree/master/CSharpCode/ExtractFactsFromParsing Для морфологического разбора фактов используется API Грамматического Словаря ( http://solarix.ru/api/ru/list.shtml ), исходные тексты на C# и C++ лежат в отдельном репозитории здесь  https://github.com/Koziev/GrammarEngine/tree/master/src/demo/ai/solarix/engines Частеречная разметка требует наличия русской словарной базы. Можно взять готовые файлы здесь  https://github.com/Koziev/GrammarEngine/tree/master/src/bin-windows64  или собрать ее самостоятельно из исходных текстов, которые лежат здесь  https://github.com/Koziev/GrammarEngine/tree/master/src/dictionary.src Запуск Утилита запускается в консоли MS Windows. Необходимо указать путь к собранной русской словарной базе, путь к исходному файлу с фактами и путь к папке с результатами работы: GenerateQAFromParsing.exe -dict e:\MVoice\lem\bin-windows64\dictionary.x ml -input e:\polygon\paraphrasing\data\facts4.txt -output f:\tmp",chatbot||nlp||датасеты||исходники||морфологический разбор текста||русский язык||чат-боты||чатбот
139,      Исходники чат-бота (диалоговой системы)  ," Все исходники буду выкладывать в репозиторий  https://github.com/Koziev/chatbot В ЖЖ буду размещать подробное описание всех использованных моделей. Для затравки -  вспомогательная утилита  второго уровня, с помощью которой были сгенерированы некоторые датасеты в  этом репозитории , например  facts.txt . Вспомогательная программка для подготовки датасета, используемого при обучении чат-бота. На входе утилита берет результаты синтаксического и морфологического разбора, выполненного утилитой Parser ( http://solarix.ru/parser.shtml ). Исходники парсера лежат в отдельном репозитории ( https://github.com/Koziev/GrammarEngine/tree/master/src/demo/ai/solarix/argon/ParseText/Parser ). Результат работы - текстовый файл, в каждой строке которого содержится одно предложение, по возможности содержащее полный предикат с подлежащим-существительным. Например: Внутри ботинка имеются мягкие анатомические вставки. Обновлённая широкая рамка продлевает срок работы. Предоставляются отчётные документы, кассовый чек. Блондинка и брюнетка в качестве модели прилагаются  Запуск Утилита реализована как консольное приложение для MS Windows. Для запуска нужно указать путь к файлу с результатами частеречной разметки и папку, где будут сохранены результаты: -parsing f:\Corpus\parsing\ru\SENT7.parsing.txt -output f:\tmp",chatbot||исходники||чатбот
140,"      Актуальная русская словарная база с моделями POS Tagging, syntax parsing и лемматизации  ", Обучение всех моделей для русской словарной базы закончилось. Файлы моделей и прочие запчасти лежат в папке  https://github.com/Koziev/GrammarEngine/tree/master/src/bin-windows64,вероятностная модель||вероятностная русская морфология||лемматизатор||парсер||синтаксический анализатор||частеречная разметка
141,      Пробный диалоговый бот для Telegram  , После рафакторинга кода сделал пробный вариант чат-бота с использованием  python-telegram-bot :,chatterbot||нейросети||чат-боты
142,      Весело начался год собаки  ," Накручивая нейросетку поверх CRF для нормализации результатов разбора данных для ETL процедуры, случайно обнаружил, что модель для CRF разбила датасет в пропорции 20% на тренировку и 80% на валидацию. Спасибо остатку от деления на пять: 
 if  (isample %  5 ) ==  0 :
    X_train.append(x)
    y_train.append(y)
    attrstr_train.append(attrstr)
    values_train.append(attrval)
 else :
    X_val.append(x)
    y_val.append(y)
    attrstr_val.append(attrstr)
    values_val.append(attrval)
 При этом она обучалась около 2х часов, показывая в принципе неплохой результат. Вернул разбивку в нормальную пропорцию, запустил на рабочем сервере переобучение, ждем результатов...",machine learning||забавные моменты
143,      Динамическое обновление базы знаний в чат-боте  ," Retrieval-based модель чат-бота с inference engine на базе нейросетки позволяет, в отличие от генераторной модели, делать быстрое обновление базы знаний бота. Это можно описать как one-shot memory, когда новый факт сразу же учитывается в последующих циклах общения без переобучения нейросетки: В данном случае текущее время фиксируется в базе знаний как факт с текстом ""Сейчас HH часов MM минут"" и учитывается при ответе на вопросы типа ""сколько сейчас времени"". Кроме того, новый факт можно сразу добавить в базу знаний (""Бобик увидел на столе гребешок.""). Движок далее будет автоматически отвечать на вопросы касательно отдельных фасетов этого факта, опираясь в том числе на синтаксическую структуру. Попросту говоря, вопрос ""где ..."" заставляет движок искать в запомненном факте составляющую подходящего вида, например предложный паттерн с предлогом ""на"" и существительным в предложном падеже, и так далее. Текущий код на питоне имеет не особо приятный вид, так как полчился в ходе постоянных переделок моделей:  https://gist.github.com/Koziev/daaddbad468c766e1a834559ed3dae90",чат-боты
144,"      Актуальность, субъективность и субъектность в нейросетевой модели чат-бота  "," Вторая версия прототипа чат-бота, основанного на нейросетевых моделях диалога: Актуальность  - владение информацией о текущей ситации, в данном случае бот знает, что сегодня именно пятница благодаря тому, что в его базу знаний при старте добавляется особый факт ""Сегодня + день_недели"": 
 dw = [u'понедельник', u'вторник', u'среда', u'четверг', u'пятница', u'суббота', u'воскресенье'][datetime.datetime.today().weekday()]
store_fact( u'сегодня '+dw )
 
 Субъектность  - способность различать вопросы по поводу себя и окружающего мира, соответственно используя либо ""я""-модель, либо ""не я""-модель. В данном прототипе на самом деле есть целых 3 базы знаний - для ""я"" с фактами о самом боте, например его имя, ""собеседник"" для фактов о том, с кем бот беседует, и прочие факты о мире. Именно так появляются ответы на вопросы ""как тебя зовут"", ""как меня зовут"" и ""из чего делают сыр"". Субъективность  - побочный эффект наличия отдельной базы знаний для ""я""-модели, так что ответ на вопрос может отличаться в зависимости от направленности. Для обучения нейросетевых моделей использованы датасеты, выложенные в репозиторий  https://github.com/Koziev/NLP_Datasets .",chatterbot||база знаний||чат-боты
145,      Выложена полная актуальная словарная база русского языка  ," В репозитории  https://github.com/Koziev/GrammarEngine  обновлены исходники русской словарной базы. Новая версия содержит увеличенный примерно на 10% лексикон, множество исправлений в морфологической разметке слова, а также доработки в синтаксическом анализаторе.",russian lexicon||грамматический словарь||исходники||лексикон||русский язык
146,      Новый датасет для чат-бота - смена грамматического лица  ," Данные представляют собой пары предложений: 
 Я не проверял .    ты не проверял .
Я ищу работу !    ты ищешь работу !
Что я умею ?    Что ты умеешь ?
Чем я занимаюсь ?    Чем ты занимаешься ?
Ранее я писала ...    Ранее ты писала ...
 
 Все предложения имеют похожую синтаксическую структуру - подлежащие в виде местоимения ""я"", глагол-сказуемое согласован. Каждая запись содержит 2 предложения, разделенных символом табуляции. Второе предложение получено из первого сменой лица подлежащего и пересогласованием глагола. Планирую использовать эти данные для обучения сеточной модели, которая будет поддерживать режим ""вовлеченности"" для чат-бота, в частности - запоминать факты о собеседнике, которые он сам сообщает. Данные будут выкладываться здесь:  https://github.com/Koziev/NLP_Datasets/tree/master/ChangePerson",dataset||nlp||чат-боты
147,      Обновленные датасеты для тренировки чат-ботов  ," После нескольких итераций, в ходе которых исправлены некоторые ошибки и добавлены новые синтаксические конструкции, в репозиторий  https://github.com/Koziev/NLP_Datasets/tree/master/QA  выложены новые файлы с тройками ""предпосылка-вопрос-ответ"" с таким форматом: 
 T: Малышки успешно прошли актировку
Q: малышки успешно прошли что?
A: актировку

T: Малышки успешно прошли актировку
Q: малышки что успешно прошли?
A: актировку

T: Малышки успешно прошли актировку
Q: успешно прошли малышки что?
A: актировку

T: Брат пристально посмотрел на доктора
Q: на кого посмотрел брат?
A: на доктора

T: Брат пристально посмотрел на доктора
Q: на кого брат посмотрел?
A: на доктора

T: Брат пристально посмотрел на доктора
Q: посмотрел на кого брат?
A: на доктора
 Датасеты генерируются автоматически из корпуса предложений, который тоже выложен в репозитории  https://github.com/Koziev/NLP_Datasets/tree/master/Samples . Объем датасетов достаточно велик, примерно по 50 тысяч троек, чтобы тренировка deep learning моделей была достаточно эффективна.",dataset||nlp
148,"      Движок логического вывода на базе DNN моделей (""умный"" chatbot)  "," Далее - результаты работы тестовой версии chatbot'а на базе нейросетевого движка логического вывода: Схематично движок работает так. Пользователь вводит запрос (это может быть вопрос в техподдержку, или к виртуальному персонажу игры, или к поисковой системе). Движок ищет в базе знаний наиболее релевантную предпосылку, на основе которой можно построить ответ (в листинге отмечено как  best premise ). Далее берет эту предпосылку, добавляет текст вопроса и с помощью отдельной нейросетки строит ответ. В приведенном ниже сеансе работы можно видеть некоторые важные фичи, без которых chatbot бесполезен, например учет морфологии и семантической близости слов. 
 :> кто питается травой?
Best premise=коровы едят траву
коровы


:> питаются ли коровы травой?
Best premise=коровы едят траву
да


:> коровы питаются чем?
Best premise=коровы едят траву
траву


:> кто есть траву?
Best premise=коровы едят траву
коровы


:> траву кто кушает?
Best premise=коровы едят траву
коровы



:> что едят коровы?
Best premise=коровы едят траву
траву



:> ловят ли кошки мышей?
Best premise=кошка ловит мышку
да


:> мышей кто ловит?
Best premise=кошка ловит мышку
кошка
 
",chatterbot||deep learning||language model||nlp||вербальный интерфейс||семантика
149,      Выложил небольшие датасеты для question answering на русском языке  ," Датасеты получены в результате автоматической обработки и содержат подмножество возможных вопросов. Могут быть полезны для проверки идей в области question answering, для чего они собственно и сделаны. Файл  https://github.com/Koziev/NLP_Datasets/blob/master/QA/premise_question_answer4.txt  содержит до полусотни тысяч вопросов к предложениям из трех слов. Аналогичный датасет для четырехсловных предложений доступен по ссылке  https://github.com/Koziev/NLP_Datasets/blob/master/QA/premise_question_answer5.txt . Выглядит это так: 
 
T: Мама удивилась вопросу

Q: Мама удивилась чему?
A: вопросу

Q: Мама чему удивилась?
A: вопросу

Q: чему удивилась Мама?
A: вопросу

Q: чему Мама удивилась?
A: вопросу

Q: удивилась Мама чему?
A: вопросу

Q: удивилась чему Мама?
A: вопросу

Q: кто удивился вопросу?
A: Мама

Q: кто вопросу удивился?
A: Мама

Q: вопросу кто удивился?
A: Мама

Q: вопросу удивился кто?
A: Мама

Q: удивился вопросу кто?
A: Мама

Q: удивился кто вопросу?
A: Мама
 Метка T: определяет предпосылку, затем для одной предпосылки идет цепочка пар вопрос Q: и ответ A:",github||nlp
150,      Первая часть модели для чат-бота  ," Чисто сеточная deep learning модель для определения семантической близости фраз, с учетом русского словоизменения и примитивный просмотр knowledge base для поиска подтверждения/опровержения гипотезы (т.е. retrieval-based модель для бота): :> кошка ловит мышей. :> ловит ли кошка мышей? да :> ловит ли мышей кошка? да :> мыши ловят кошку? нет :> кошечка ловит мышек? да :> мышки ловят кошечку? нет :>",chatterbot||deep learning||нейросети||чат-боты
151,      небольшое ручное сравнение vanilla w2v и fasttext на русском 10Гб корпусе  ,"  Обучил word2vector и  fasttext  модели на одном и том же текстовом корпусе:10 Гб всяких текстов, включая социальные медиа, изобилующие опечатками и словообразовательным творчеством масс. Параметры для w2v: CBOW=0 WIN=5 DIM=32 MIN_COUNT=1 Параметры для fasttext: SIZE=64 WINDOW=5 CBOW=0 MIN_COUNT=1 Далее сравниваю выдаваемую похожесть для нескольких пар слов с помощью  1  и  2 . Результаты под катом. Можно заметить, что в некоторых случаях fasttext дает намного лучшие результаты ( борщ  и  борщец ), корректнее учитывая русские продуктивные суффиксы. Но исправление опечаток fasttext не тянет ( трактор  и  тракктор ). /usr/bin/python2.7 /home/eek/polygon/w2v/similarity.py Loading the w2v model... word1: трактор word2: тракторишка similarity= 0.15816610062 word1: трактор word2: бурбулятор similarity= 0.356227697608 word1: влево word2: вправо similarity= 0.998551493653 word1: борщ word2: борщец similarity= -0.00652037572231 word1: борщик word2: борщ similarity= 0.447010447054 word1: борщ word2: борщщ борщщ is out of vocabulary word1: влево word2: вправо similarity= 0.998551493653 word1: левее word2: правее similarity= 0.99435190581 word1: трактор word2: тракторишка similarity= 0.15816610062 word1: трактор word2: бурбулятор similarity= 0.356227697608 word1: трактор word2: тракктор тракктор is out of vocabulary word1: борщ word2: борщь similarity= 0.287167255134 word1: борщ word2: борщщ борщщ is out of vocabulary word1: борщ word2: борщец similarity= -0.00652037572231 word1: борщ word2: борщик similarity= 0.447010447054 word1: борщ word2: борщичок similarity= -0.159063823511 word1: борщ word2: борщичка similarity= -0.0411978963949 word1: боорщ word2: борщ боорщ is out of vocabulary /usr/bin/python2.7 /home/eek/polygon/w2v/similarity_fasttex t.py Loading fasttext model... word1: влево word2: вправо similarity= 0.990195501943 word1: левее word2: правее similarity= 0.968340252146 word1: трактор word2: тракторишка similarity= 0.858061257733 word1: трактор word2: бурбулятор similarity= 0.529129949624 word1: трактор word2: тракктор similarity= 0.00119637026748 word1: борщ word2: борщь similarity= 0.892426321114 word1: борщ word2: борщщ similarity= -0.0708572095993 word1: борщ word2: борщец similarity= 0.858236411389 word1: борщ word2: борщик similarity= 0.676512982214 word1: борщ word2: борщичок similarity= 0.781284887113 word1: борщ word2: борщичка similarity= 0.753470436758 word1: боорщ word2: борщ similarity= 0.02972435751",fasttext||vector model||vector space model||word2vec
152,      Enriching Word Vectors with Subword Information (aka fasttext)  ," Приятно, что идея строить векторные представления для частей слов, воплощенная в этой программке  https://github.com/Koziev/Word2Vec/blob/master/PyUtils/wordparts.py , была шагом в верном направлении, если внимательно посмотреть на статью "" Enriching Word Vectors with Subword Information",unsupervised feature learning||vector model||vector space model||word embedding||word2vec
153,      Репозиторий на github с датасетами для NLP  ," Выложил некоторые полезные датасеты сюда:  https://github.com/Koziev/NLP_Datasets : Перефразировки Частоты слов с учетом частей речи Леммы Приведение слов к нейтральной форме ""штучка-штука""",github||nlp||датасеты||исходники
154,"      Черновики по задаче ""Вопросно-ответная система на русском языке""  "," Отстрелялся в задаче "" Вопросно-ответная система на русском языке "". Исходники решения выложил в репозиторий  https://github.com/Koziev/NLP_Comp/tree/master/SDSJ_A Самый красивый, хотя и не самый точный, вариант - сеточная модель со сверточной и рекуррентной частями, написанная на питоне и Keras:  https://github.com/Koziev/NLP_Comp/blob/master/SDSJ_A/models/nn5.py",convolutional networks||keras||python||rnn||vector model||vector space model||исходники||соревнования
155,      Исходники утилиты для экспорта словаря в SQL базу  ," В  репозиторий  выложил  исходники и сборочные скрипты для утилиты decompiler . Делает она такую вещь. Загружает собранный компилятором словарь и генерирует набор SQL-команд для загрузки словаря в реляционную СУБД. В частности, можно залить словарь в SQLite таким набором действий. 1. Собираем русский словарь командой  russian.cmd 2. Запускаем экспорт словаря в SQL командой  sql-sqlite.cmd 3. В папке ../tmp появится несколько текстовых файло с именами dictionary.sql и так далее. 4. С помощью скрипта  load-sqlite.cmd , который просто вызывает консольную утилиту sqlite3, заливаем словарь в базу. Получится файл dictionary.sqlite размером около 2 Гб. 5. Берем любой GUI клиент для SQLite, например  http://sqlitebrowser.org/ , и с его помощью работаем с содержимым словарной базы,  описанной тут . Компиляция утилиты Под Windows есть  готовое решение  для VisualStudio 2015. Для Linux можно использовать  makefile  или запустить сборку всех утилит с помощью CMake и  скрипта .",SQL словарь||sqlite||грамматический словарь||исходники
156,      Подсветка ключевых слов в результатах поиска по текстовому корпусу  ," В  утилитке для полнотекстового поиска  прикрутил html highlighter, чтобы результаты поиска было удобнее анализировать визуально:",исходники||полнотекстовый поиск
157,      Индексирование и поиск в текстовом файле размером 70 Гб с помощью Lucene.NET  ," С помощью утилитки (проект для VS2015 на C# лежит  тут ) проиндексировал текстовый файл размером 70 Гб. Обработка длилась примерно 20 часов, из которых 5 или 6 часов длилась финальная оптимизация индекса с полным выеданием канала на диск. Общий объем индекса составил 90 Гб. С учетом того, что я сохранял индексируемые текстовые поля в индексе, получилось достаточно экономно. Поиск по этому индексу выполняется очень шустро, релевантность нормальная, memory footprint минимальный: Вся работа с индексом сделана через  Lucene.NET",.net||lucene.net||исходники||поисковый движок||полнотекстовый поиск
158,      Начал выкладывать компоненты лемматизатора в репозиторий  ," В репозитории грамматического словаря  https://github.com/Koziev/GrammarEngine  выложены все исходники и сборочные файлы для лемматизатор, см. каталог  https://github.com/Koziev/GrammarEngine/tree/master/src/demo/ai/solarix/engines/lemmatizator . Также выложен  C# wrapper  для вызова  API лемматизатора  из .NET код.",исходники||лемматизатор
159,      Утилита для полнотекстового поиска с индексированием (C# WPF+Lucene.NET + SQLite + nHibernate)  ," Делаю для себя, так как периодически возникает необходимость поискать какой-то фрагмент текста в больших текстовых файлах (гигабайты или десятки гигабайтов). Текущая версия - макет с минимальным функцилналом. Исходники на C# и проект для VS2015 лежат в репозитории  https://github.com/Koziev/CorpusSearch . Визуальная часть написана на WPF. Полнотекстовый индекс и поиск -  Lucene.NET . Хранение метаинформации о проиндексированных файлах -  Fluent NHibernate  с SQLite. Логирование -  log4net . В конфигурационном файле надо руками прописать путь к базе данных - см. строку Data Source=e:/tmp/CorpusSearch.sqlite.db; Также надо задать путь к папке, где будут складироваться индексы Lucene - см. строку <add key=""indexes"" value=""f:/temp/CorpusSearchIndexes"" />",c||lucene.net||nhibernate||sqlite||исходники||полнотекстовый поиск
160,      Сделай сам Вольфрам Математику: о пользе цветных маркеров  ," Вспомнил первый курс института, матан для решения одной из  задачек . Час времени утром до начала работы, несколько листов, две ручки и четыре маркера: И поле битвы:",забавные моменты
161,      Кто шутил про full-stack development?  ," Очередной спам от рекрутеров. Ну спам как спам, но под заголовком ""C++ developer"" идет: REQUIREMENTS - A good knowledge of C++, C#,  ASP.NET  and Microsoft Azure.  - Some experience with MySQL and Microsoft SQL Server. - A good knowledge of Javascript and Ajax. - Basic knowledge of IP networking protocols (preferable CCNA) - Knowledge of Linux environment (Debian, GIT, PHP, LAMP) - Basic knowledge of VMware ESXI server ... lot of other things ...",забавные моменты
162,      Сборка Грамматического Словаря с помощью CMake  ," Начал переделывать сборку утилит из C++ исходников  репозитория грамматического словаря  с помощью  CMake . Под убунтой процесс сборки сейчас выглядит так: Переходим в подкаталог build cd build Генерируем makefile'ы: cmake .. Запускаем сборку: make Наслаждаемся зелеными строчками, и после 15 минут сборки финал в каталогах exe64 и lib64 появляются бинарники. Теперь можно еще внести в скрипты сборку Парсера и русской словарной базы, чтобы сразу получить готовый к использованию комплект.",c++||cmake||исходники
163,      Autoencoders for word representations и ахитектура для встраивания доп. информации  ," Для  эксперимента WordRepresentations  делаю последний вариант получения векторного представления слов с помощью автоэнкодеров. Самая простая модель -  plain vanilla автоэнкодер  с архитектурой seq2seq. На входе у него для каждого слова задается цепочка 1-hot представлений символов. Далее цепочка векторов сжимается слоем LSTM элементов в вектор фиксированного размера (32), и LSTM-декодер восстанавливает исходную цепочку векторов символов. Обучив автоэнкодер на нескольких миллионах слов, можно отрезать декодер, оставив первую половину, и прогнать все слова через декодер, получив векторы слов. Тут все стандартно и просто. Возникает закономерный вопрос: если мы можем подавать на вход  сетки для решения задачи  непосредственно 1-hot представления символов, то есть ли смысл сначала обучать автоэнкодер, генерировать представления слов из него и использовать уже эти векторы? Экспериментальная проверка показывает, что смысла нет. Нейросетевой классификатор, использующий 1-hot представления символов, обозначаемый в  таблице результатов  как 'char_indeces', дает на 1 миллионе 3-грамм точность около 0.6745, тогда как векторы с автоэнкодера дают только 0.5616. Попытка улучшить автоэнкодер - встраивание морфологии Но ничто не мешает нам из вектора на ""скрытом"" слое автоэнкодера пытаться восстановить еще и другую информацию, в частности - битовый вектор с морфологическими признаками и даже w2v вектор слова. Таким способом можно ожидать, что декодер будет из исходного char surface представления слова получать дополнительную морфологическую и семантическую информацию. Архитектура сетки получается такая: На Keras  эта нейросетка  описывается так: 
input = Input( shape =( self .max_word_len,  self .nb_chars),  dtype = 'float32' ,  name = 'input_layer' )
encoder = LSTM( vector_size,  input_shape =( self .max_word_len,  self .nb_chars),  return_sequences = False  )(input)

decoder_word = RepeatVector( self .max_word_len)(encoder)
decoder_word = LSTM(vector_size,  return_sequences = True )(decoder_word)
decoder_word = TimeDistributed(Dense( self .nb_chars))(decoder_word)
decoder_word = Activation( 'softmax' ,  name = 'word' )(decoder_word)

decoder_tags = Dense( units =grammar_dict.get_tags_size(),  name = 'tags' )(encoder)

decoder_w2v = Dense( units =grammar_dict.get_w2v_size(),  activation = 'tanh' ,  name = 'w2v' )(encoder)


model = Model( inputs =input,  outputs =[decoder_word, decoder_tags, decoder_w2v])
model.compile( loss ={ 'word' : 'categorical_crossentropy' ,  'tags' : 'mse' ,  'w2v' : 'mse' },
               optimizer = 'rmsprop' ,
               metrics =[ 'accuracy' ])
 Обращаю внимание, что в качестве loss'ов передается словарь, и для каждого именованного выхода указана своя loss-функция. Сетка обучается не очень хорошо. На графике показаны значения loss на каждом из выходов сетки, val_word_loss - это ошибка восстановления символов слова, и так далее: Ошибка восстановления слов периодически скачет вверх, хотя тренд на понижение четко прослеживается. А вот для ошибки восстановления вектора тегов (val_tags_loss) и w2v вектора (val_w2v_loss) все плохо - уменьшения практически нет. Сначала я подумал, что причина кроется в небольшой величине ошибки val_tags_loss относительно val_word_loss - примерно в 10 раз меньше. То есть градиенты для коррекции декодера слова просто экранируют остальные градиенты. Чтобы проверить гипотезу, была объявлена модифицированная функция ошибки с масштабированием в 10 раз: 
 from  keras  import  backend  as  K

 def  loss_mse10(y_true, y_pred):
     return  10.0 *K.mean(K.square(y_pred - y_true),  axis =- 1 )

 И она задавалась для сетки для выхода 'tags'. Результат обучения с такой функцией ошибок: То есть ошибка успешно отмасштабирована, но обучение по данному аспекту не идет. Сверточная нейросеть и связь морфологии с морфемами Может быть, рекуррентная архитектура энкодера выдает плохие представления символьной информации, из которой декодер не может качественно восстановить битовый вектор морфологических тегов? Приверим это предположение, сделав отдельную нейросетку со  сверточной  архитектурой. Так как на входе у нас цепочка символов, то  сверточные слои  будут фактически выделять  морфемы , от которых по идее есть неплохая корреляция с морфологическими признаками (падеж, род etc). По крайней мере, можно надеяться на это из общих соображений. Слова имеют разную длину в символах, поэтому надо как-то приводить результаты применения сверток к единому размеру. Удобно делать это с помощью слоя GlobalMaxPooling1D, который ищем максимум для всего входного набора векторов и таким образом отбрасывает информацию о местоположении ""морфем"", оставляя только факт их наличия. Делаем сверточную нейросеть ( исходник на питоне для Keras тут ): 
input = Input( shape =( self .max_word_len,  self .nb_chars),  dtype = 'float32' ,  name = 'input_layer' )

nb_filters =  64 
 
conv_list = []
merged_size =  0
 
 for  kernel_size  in  range ( 2 ,  6 ):
    conv_layer = Conv1D( filters =nb_filters,
                         kernel_size =kernel_size,
                         padding = 'valid' ,
                         activation = 'relu' ,
                         strides = 1 )(input)
    conv_layer = GlobalMaxPooling1D()(conv_layer)
    conv_list.append(conv_layer)
    merged_size += nb_filters

merged = keras.layers.concatenate( inputs =conv_list)
 encoder  = Dense( units = int (merged_size/ 2 ),  activation = 'relu' )(merged)
encoder = Dense( units = int (merged_size/ 4 ),  activation = 'relu' )(merged)
encoder = Dense( units =vector_size,  activation = 'sigmoid' )(encoder)

decoder_tags = Dense( units =grammar_dict.get_tags_size(),  activation = 'relu'  )(encoder)
decoder_tags = Dense( units =grammar_dict.get_tags_size(),  activation = 'relu' ,  name = 'tags' )(decoder_tags)

model = Model( inputs =input,  outputs =decoder_tags)
model.compile( loss = 'mse' ,  optimizer = 'nadam'  )   #, metrics=['accuracy'])
 Графически это выглядит так: К сожалению, кроме более быстрого обучения, эта модель не отличается от рекуррентного прототипа с точки зрения проблем обучаемости: Улучшение на первой эпохе и затем плато с минимальными колебаниями.",autoencoder||char-rnn||character language model||convolutional networks||keras||machine learning||python||rnn||unsupervised feature learning||vector model||vector space model||word embedding||word2vec||рекуррентные сети||сверточные сети
164,      Сборка и использование C# wrapper'а грамматического движка в Ubuntu с .NET Core  ,"  Предисловие: wchar_t в API есть зло При разработке C API под Win и Linux всегда следует помнить, что фактический размер wchar_t не гарантируется стандартом, даже в рамках одной платформы, и разными компиляторами может реализовываться по-разному. Поэтому нет ничего удивительного, что wchar_t для gcc под Linux - это 4 байта, а для штатного компилятора в VisualStudio - 2 байта ( https://en.wikipedia.org/wiki/Wide_character ). Для удобства вызова API из C++ кода я все процедуры, принимающие или возвращающие строки, объявлял с wchar_t* в сигнатурах. Если стартовать проект сейчас, то я бы подумал насчет char16_t в  C++11 , но грамматический движок писался раньше, так что wchar_t на тот момент выглядел естественно. В общем, код на C++, которому нужна обработка текста, выделял у себя wchar_t* блок, затем дергал  процедуру в  solarix_grammar_engine.(dll|so)  и все работало прозрачно. Ну или второй вариант заключался в дополнительных процедурах, принимающих или отдающих utf-8 строки, что было более удобно для Linux. К чему это привело в .NET Core  PInvoke  под Linux? Чтобы вызвать процедуру в неуправляемом коде, на входе которой нужна строка, мы должны описать  правило маршалинга  из System.String в соответствующий C-тип. Для  преобразования в массив 16-битных символов, точнее говоря в  UTF-16  с возможными суррогатными парами, есть стандартное правило, которое отлично справляется с преобразованием в wchar_t* под Windows, поскольку по обеим сторонам присутствуют 2-байтные символы в utf16. А вот для преобразования из System.String в массив 4-байтных wchar_t готового правила маршалинга я не нашел, да и вряд ли оно будет простым, учитывая нюансы перекодирования UTF16 в UTF32 и обратно. В итоге враппер под Linux использует варианты процедур с представлением строк в кодировке utf-8, а для Windows остается штатный вариант с дефолтным маршалингом. Использование .NET Core под Ubuntu Перед использованием матриала установите .NET Core на свою систему. Для Ubuntu это делается предельно просто, через скачивание дистрибутива и запуск инсталяции. У меня на Ubuntu 16.04 все прошло без дополнительных вопросов. Подробности можно найти тут  https://www.microsoft.com/net/core . Теперь сборка запчастей. Сначала надо скомпилировать динамическую библиотеку solarix_grammar_engine.so (это plain C api) и установить ее в нужное место в системе, создав синонимы, примерно так: cp solarix_grammar_engine.so /usr/lib64 rm -f /usr/lib64/libgren.so rm -f /usr/lib64/libgren.so.1 rm -f /usr/lib64/libgren.so.1.0 ln -s /usr/lib64/solarix_grammar_engine.so /usr/lib64/libgren.so ln -s /usr/lib64/solarix_grammar_engine.so /usr/lib64/libgren.so.1 ln -s /usr/lib64/solarix_grammar_engine.so /usr/lib64/libgren.so.1.0 Сборка .NET wrapper Далее нужно подготовить проект для сборки .NET wrapper, который позволит вызывать динамическую библиотеку C API из C# через механизм PInvoke. Идем в папку  /home/eek/Solarix/GrammarEngine/src/demo/a i/solarix/engines/grammar_engine_fx . Там лежит исходный текст враппера  Grammar_Engine_fx.cs  и готовый проект для сборки под Linux gren.ubuntu.csproj. Другой файл проекта нужен для win-версии сборки под старый .NET Framework. Чтобы он не путался под ногами и не вызывал жалобы у команды dotnet, лишние проекты из этой папки лучше удалить. Просим NuGet подкачать и установить все необходимые компоненты .NET Core (по поводу команды dotnet и того, что она делает, читайте официальное руководство тут:  https://docs.microsoft.com/ru-ru/dotnet/core/tutorials/using-with-xplat-cli ): dotnet restore Теперь можно проверить, что враппер скомпилируется: dotnet build Успешное построение выглядит так: Сборка финальной программы Ок, теперь перейдем в  папку с консольной программой на C# , которая будет использовать грамматический движок через .NET обертку: cd ../../Grammar_Engine/SimpleGREN_FX Там лежит файл  Program.cs  и проект SimpleGREN_FX.csproj. Вы можете пересоздать проект с нуля командой: dotnet new console Но при этом файл Program.cs будет затерт, так что либо используйте мой проект, либо восстановитте потом Program.cs. Просим Nuget восстановить необходимые компоненты: dotnet restore И добавляем ссылку на .NET Wrapper: dotnet add SimpleGREN_FX.csproj reference ../../engines/grammar_engine_fx/gren.ubu ntu.csproj Собираем программу и запускаем: dotnet run Вы увидите в консоли что-то типа этого:",api||c||грамматический словарь||исходники
165,"      Английская, французская, японская, китайская словарные базы на github  "," В дополнение к  русской словарной базе , в  репозиторий  выложены словарная база (лексика, морфология, синтаксис) для английского языка. Для французского, японского и китайского языков словарная база содержит морфологические модели и лексику, синтаксическая модель для них не реализована. Сборка нужной словарной базы выполняется соответствующим скриптом в папке  .../src/scripts/dictionary english.cmd или english.sh french.cmd japanese.cmd chinese.cmd Морфологическая модель японского языка сделана в расчете на использование с парсерами типа  Cabocha  или  KNP",английский язык||грамматика||грамматический словарь||китайский язык||лексика||лексикон||японский язык
166,"      Выложены исходники русской морфологии, лексики и синтаксиса в репозиторий  "," В  репозиторий Грамматического Словаря  выложены  исходники русской словарной базы . Исходники почти полные, исключен только тезаурус и некоторое количество словарных статей. Инструкции по компиляции утилит и словарной базы лежат в  README.md",грамматический словарь||исходники||русский язык
167,      Доработки объектной модели в проекте WordRepresentations  ,"  1. В отдельный модуль  CorpusReaders.py  вынесено чтение строк из  текстового корпуса . Таким образом, теперь классы в модуле  DataVectorizers.py  не содержат привязки ни к местоположению корпуса, ни к его формату. Я сделал две реализации ""интерфейса"" BaseCorpusReader для чтения из зазипованного текстового файла ZippedCorpusReader и из простого текстового файла TxtCorpusReader. Нужный экземпляр передается в метод vectorize_dataset. Вариант с созданием через фабрику и тем более с использованием dependency injection пока считаю избыточным, создать читатель явным вызовом нужного конструктора и передать созданный экземпляр в один метод сейчас совершенно достаточным: # Создаем читатель для корпуса corpus_reader = CorpusReaders.ZippedCorpusReader('../dat a/corpus.txt.zip') #corpus_reader  = CorpusReaders.TxtCorpusReader(r'f:\Corpu s\Raw\ru\tokenized_w2v.txt') # Загружаем датасет dataset_generator = BaseVectorizer.get_dataset_generator(REP RESENTATIONS) X_data,y_data = dataset_generator.vectorize_dataset(corp us_reader=corpus_reader, ngram_order=NGRAM_ORDER, nb_samples=NB_SAMPLES) 2. Почистил сигнатуры методов с @classmethod, аргумент self заменил на cls, чтобы не резало глаз.",#corpus_reader||python||исходники
168,      Обновление char-level language model и подробная инструкция по использованию  ,"  Выложил в  репозиторий  всё, включая новые файлы модели, обученной на 2 миллионах сэмлах. Также добавил описание: Char-level Language Model на базе рекуррентных нейросетей Модель реализована на Python 2.x с использованием  фреймворка Keras  для построения нейросети. Обучение модели Обучение реализовано в  char_predictor.py . Для обучения модели необходим текстовый файл (plain text, utf-8). Какую-либо нормализацию текста выполнять не требуется. Модель сама составит список всех используемых символов. Путь к текстовому файла прописан в  char_predictor.py . Там же стоит вторая важная настройка - количество сэмплов в обучающем датасете. Чем большое сэмплов, тем лучше модель будет работать, но время обучения будет расти пропорционально. В ходе обучения программа сохраняет модельные данные на диске. Для nb_patterns = 2000000 обучение с использованием GPU NVidia GTX 980 длится примерно 5 часов, с учетом 5 отбрасываемых эпох до срабатывания early stopping. Проверка работы модели в консоли Консольный генератор текста реализован в  char_generator.py . Он загружает модельные данные из файлов, приготовленных в ходе обучения. далее можно вводить с клавиатуры цепочку символов (начало фразы), а модель выведет предполагаемое продолжение. Примерно так: >: поздравляю с новы поздравляю с новых настоящий собой мо >: сяду на пенек, съем пиро сяду на пенек, съем пиров накопления по нее >: цветы нужно поливать кажд цветы нужно поливать каждое серодоразисте так >: тише, мыши, кот на кры тише, мыши, кот на крыше и высоких своей т",char-rnn||character language model||keras||neuronet||python||генеративная модель||генерация текста||исходники
169,      Нейросеточка для дописывания строк  ," Играюсь с новой версией  модели языка на уровне символов  (код на питоне, в репозиторий залиты и файлы предобученной на небольшом корпусе модели). Программа позволяет ввести начало строки и затем дополняет ее парой десятков символов, используя модель для вычисления вероятностей нового символа по предшествующим 64 символам. Вот такие штуки получаются (болдом выделен вводимая в консоли затравка): eek@ubuntu:~/polygon/pushkin$ python char_generator.py >:  мойте руки пере мойте руки передать о среднем пробл >:  поздравляю с новы поздравляю с новыми войсками в из раз >:  кошка ловит мыш кошка ловит мышленности и населения >:  и стоило ли так напрягать и стоило ли так напрягать новым результате по >:  с добрым утр с добрым утромании военные высок >:  сяду на пенек, съем пиро сяду на пенек, съем пировой техников.",char-rnn||character language model||deep learning||keras||python||генеративная модель||генерация текста||нейросети
170,      В вашем ЯП мало синтаксического сахара? Перчику вам от Оракла.  ," Руки устают от многословности Java? Нет сил на C++ набрать { return a; } и глаза мокреют от зависти к шарповскому сахарку => a;? Я сейчас перевожу свою реализацию на питоне быстрого нечеткого поиска в БД с помощью  алгоритма Левенштейна  и  Trie . Перевожу на PL/SQL. PL/SQL - это такой динозавр в мире ЯП, потомок Ады. Если к IF .... THEN .... END IF; можно в конце концов привыкнуть, то вот  реализация ООП в PL/SQL  это настоящий хардкор. Синтаксический сахар хотите? Синтаксический перец вам в монитор! Вот пара классов на питоне: 
 class  Cursor( object ):
     def  __init__ ( self , node, pos, miss_count ):
         assert (node  is not  None )
         assert (miss_count>= 0.0 )
         self .node = node
         self .pos = pos
         self .miss_count = miss_count

     def  __str__ ( self ):
         return  u'node={} pos={} miss_count={}' .format( self .node.code,  self .pos,  self .miss_count)


 class  Cursors( object ):
     def  __init__ ( self ):
         self .cursors =  dict ()

     def  add( self , cursor):
        node_id =  id (cursor.node)
         if  node_id  in  self .cursors:
             if  cursor.miss_count <  self .cursors[node_id].miss_count:
                self .cursors[node_id] = cursor
         else :
             self .cursors[node_id] = cursor

     def  __iter__ ( self ):
         return  iter ( self .cursors.values())

     def  is_empty( self ):
         return  len ( self .cursors)== 0
 А теперь текущий черновик после перевода на PL/SQL: CREATE TYPE DUP_Cursor AS OBJECT (  node DUP_TrieNodeType,  pos INTEGER,  miss_count INTEGER ); CREATE TYPE DUP_CursorsList IS TABLE OF DUP_Cursor; create or replace type DUP_Cursors as object (  cursors DUP_CursorsList,  CONSTRUCTOR FUNCTION DUP_Cursors RETURN SELF AS RESULT,  MAP  MEMBER FUNCTION is_empty RETURN INTEGER,  MEMBER FUNCTION count_items RETURN INTEGER,  MEMBER FUNCTION get_item( i INTEGER ) RETURN DUP_Cursor,  MEMBER PROCEDURE add_item( new_cursor DUP_Cursor ) ); CREATE OR REPLACE TYPE BODY DUP_Cursors AS   CONSTRUCTOR FUNCTION DUP_Cursors RETURN SELF AS RESULT   AS   BEGIN     SELF.cursors := DUP_CursorsList();     RETURN;   END;   MAP MEMBER FUNCTION is_empty RETURN INTEGER IS   BEGIN     IF cursors.COUNT=0 THEN      RETURN 1;     ELSE      RETURN 0;     END IF;   END;  MEMBER FUNCTION count_items RETURN INTEGER IS   BEGIN     RETURN cursors.COUNT;   END;  MEMBER FUNCTION get_item( i INTEGER) RETURN DUP_Cursor IS   BEGIN     RETURN cursors(i);   END;  MEMBER PROCEDURE add_item( SELF IN OUT NOCOPY DUP_Cursors, new_cursor DUP_Cursor ) IS  i_found INTEGER;  BEGIN   i_found := -1;   FOR i in 1..cursors.COUNT LOOP    IF cursors(i).node.id = new_cursor.node.id THEN     IF cursors(i).miss_count > new_cursor.miss_count THEN      cursors(i).miss_count := new_cursor.miss_count;     END IF;     i_found := i;     EXIT;      END IF;   END LOOP;   IF i_found=-1 THEN    cursors.EXTEND;    cursors( cursors.COUNT ) := new_cursor;   END IF;    END; END; /",oracle||pl/sql||забавные мелочи
171,      memset: спящее зло  ," Делаю рефакторинг  своих старых исходников , и вот при сборке под новым gcc в Убунте увидел замечательный ворнинг по поводу вероятно неправильного порядка аргументов при вызове memset в строке 981 в файле  streams.h . Исправил. Было: memset( &p, sizeof(p), 0 ); Стало: memset( &p, 0, sizeof(p) );",c++||исходники
172,"      Представления слов: исправления, улучшения, сравнение Python / Java / C++ реализаций нейросетей  "," 1. В  Keras-реализации решения  нашел data leak из  валидационных данных в тренировочный набор (как обычно по причине копипасты фрагментов из своих же исходников). После исправления стал получать намного более консистентные результаты: точность на одинаковых данных для сопоставимых архитектур нейросетей в Keras+Theano и в Tensorflow решениях стала примерно равна. И даже решения на Deeplearning4j и Apache.SINGA дают примерно такие же значения! 2. Реализован совершенно новый алгоритм для получения sparse distributed representations для слов. В отличие от non-negative matrix factorization с L1-регуляризацией, используется k-means для подмножеств компонентов w2v векторов. Алгоритм требует намного меньше памяти, а по скорости примерно соответствует nnmf+l1. Но чтобы использовать SDR векторы слов длиной хотя бы 1024, пришлось переделывать решение для Keras, так как сразу сгенерировать тренировочную матрицу хотя бы для 1 миллиона троек слов в 32 Гб памяти невозможно. Сделал отдельное решение, использующее методы fit_generator и evaluate_generator, принимающие генераторы порций данных. Исходный текст нового решения лежит тут:  https://github.com/Koziev/WordRepresentations/blob/master/PyModels/wr_keras_sdr2.py 3. Сделал следующие улучшения в  java-решении, основанном на фреймворке deepleraning4j : 3.1. Сделано сохранение лучшей модели в файл по ходу тренировки (model checkpoint). Для этого в конце каждой эпохи делается оценка качества по валидационному набору, и если полученное значение точности превышает предыдущее, то сохраняем модель в файл. 3.2. Сделал early stopping, чтобы экономить время. Если модель на протяжении 10 эпох не улучшает точность при валидации, то прекращаем обучение. После этого загружается лучшая версия весов, сохраненная в ходе model checkpoint, и для ее делается финальная оценка качества по holdout набору. В ходе работы можно увидеть соответствующие сообщения в консоли: ==========================Scores======== ================================  # of classes:    2  Accuracy:        0.7707  Precision:       0.7720  Recall:          0.7707  F1 Score:        0.7784 ======================================== ================================ New best val_acc=0.7706575757575758 Model saved in /home/eek/polygon/WordRepresentations/da ta/deeplearning4j.model Start iteration #6 4. Доработал  решение на Apache.SINGA C++ . В частности, добавил экспоненциальное уменьшение скорости обучения. Модель дает на финальной валидации сравнимую с остальными точность. 5. Текущие результаты по моделям, после исправления data leak'а: wr_keras.py (Keras+Theano, Python) ================================== NB_SAMPLES=1,000,000  NGRAM_ORDER=2  net=MLP  w2v      acc=0.7719 NB_SAMPLES=1,000,000  NGRAM_ORDER=2  net=CNN  w2v      acc=0.7741 NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  w2v      acc=0.7709 NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=CNN  w2v      acc=0.7837 NB_SAMPLES=1,000,000  NGRAM_ORDER=4  net=MLP  w2v      acc=0.7468 NB_SAMPLES=1,000,000  NGRAM_ORDER=4  net=CNN  w2v      acc=0.7731 NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  w2v_tags acc=0.7921 NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=CNN  w2v_tags acc=0.7999 NB_SAMPLES=1,000,000  NGRAM_ORDER=4  net=MLP  w2v_tags acc=0.7653 NB_SAMPLES=1,000,000  NGRAM_ORDER=4  net=CNN  w2v_tags acc=0.7775 wr_keras_sdr2.py (Keras+Theano, Python) ======================================= NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  SDR2     acc=0.7596 wr_tensorflow3.py (Tensorflow, Python) ====================================== NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  w2v      acc=0.7475 NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  w2v_tags acc=0.7866 deeplearning4j (Java) ===================== NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  w2v      acc=0.7715 Apache.SINGA (C++) ================== NB_SAMPLES=1,000,000  NGRAM_ORDER=3  net=MLP  w2v      acc=0.7692",#6||c++||java||keras||language model||machine learning||neuronet||python||vector model||vector space model
173,      Решения на базе deeplearning4j (Java) MLP и vanilla MLP (C#) для WordRepresentations  ," Выложил в  репозиторий : https://github.com/Koziev/WordRepresentations/blob/master/JavaModels/WithDL4J/src/main/java/WordRepresentationsTest.java  - решатель на базе MLP, реализованного средствами библиотеки  deeplearning4j https://github.com/Koziev/WordRepresentations/blob/master/CSharpModels/MyBaseline/Program.cs",N-граммы||c||java||nlp
174,      Черновая реализация нейросетки на TensorFlow high-level API для бенчмарка WordRepresentations  , В порядке изучения TensorFlow сделал две модели на Питоне: 1. На базе  DNNClassifier  - файл  wr_tensorflow.py 2. Ручное формирование графа для  Estimator 'а - файл  wr_tensorflow3.py,keras||python||tensorflow||theano||vector model||vector space model
175,      Рефакторинг нейросетевого лемматизатора  ," В репозитории  https://github.com/Koziev/word2lemma  выполнена генеральная перепланировка и уборка. 1. Отрефакторил реализацию  обучения  и использования лемматизатора. Лемматизатор вынесен в  отдельный класс , чтобы было удобнее использовать его в разных экспериментах. Загрузка всех необходимых данных предобученной модели инкапсулирована в это классе, поэтому использование выглядит максимально просто: 
 from Lemmatizer import Lemmatizer

lemmatizer = Lemmatizer()
lemmatizer.load('../../../../data')

lemma = lemmatizer.predict(word)
 2. Консольный лемматизатор переделан на использование класса Lemmatizer. После запуска вводим с клавиатуры слова, они прогоняются через нейросетку и получающиеся леммы печатаются в консоли: 3. Сделан  игрушечный REST API  на базе  flask-restful . В простейшем варианте можно запускать под встроенным веб-сервером из консоли командой: python word2lemma_restapi.py Рест-сервис запустится: Далее можно в браузере сделать тестовый запрос через урл 127.0.0.1:5000/квазикошками, сервис вернет JSON с результатом лемматизации. В лисичке это выглядит вот так: Разумеется, сопутствующие накладные расходы на лемматизацию единственного слова достаточно велики, поэтому для лемматизации порции слов лучше реализовать в классе Lemmatizer особый метод, который векторизует все слова в одном тензоре, прогонит его через нейросетку и вернет порцию лемм. Что хотелось бы сделать еще: 1) реализовать модель средствами TensorFlow 2) причем не только на питоне, но и на C++.",python||sequence2sequence||исходники||лемматизатор||рекуррентные сети||русский язык
176,      Эксперимент с использованием reinforcement learning keras-rl для синтаксического парсинга  ," Используется размеченный treebank отсюда:  http://universaldependencies.org Reinforcement learning делается средствами  keras-rl Парсер - простая стековая машина, не поддерживающая непроективные ребра. Эксперимент пока неудачный, не могу добиться роста качества парсинга. Питоновский исходник выложил здесь:  https://github.com/Koziev/RI_Syntax",keras-rl||python||reinforcement learning||исходники||парсер||синтаксис||синтаксический анализатор||синтаксический разбор
177,      Сверточная архитектура нейросети для построения Language Model  ," Для  эксперимента с оценкой вариантов представления слов  добавил сверточную архитектуру - см. файл  wr_keras.py  и константу NET_ARCH. С поправкой на большую variance, характерную для сверточного варианта в сравнении с feed forward MLP, эта сетка бьет MLP с ощутимым запасом. Например, для 4-грамм имеем: 
 NB_SAMPLES=1,000,000  NGRAM_ORDER=4  net=MLP word_indeces  acc=0.7651
NB_SAMPLES=2,000,000  NGRAM_ORDER=4  net=MLP word_indeces  acc=0.7746
NB_SAMPLES=3,000,000  NGRAM_ORDER=4  net=MLP word_indeces  acc=0.7809
NB_SAMPLES=5,000,000  NGRAM_ORDER=4  net=MLP word_indeces  acc=0.8049
NB_SAMPLES=6,000,000  NGRAM_ORDER=4  net=MLP word_indeces  acc=0.8296
NB_SAMPLES=8,000,000  NGRAM_ORDER=4  net=MLP word_indeces  acc=0.8483

NB_SAMPLES=1,000,000  NGRAM_ORDER=4  net=ConvNet word_indeces  acc=0.8253
NB_SAMPLES=2,000,000  NGRAM_ORDER=4  net=ConvNet word_indeces  acc=0.8226
NB_SAMPLES=3,000,000  NGRAM_ORDER=4  net=ConvNet word_indeces  acc=0.7993
NB_SAMPLES=5,000,000  NGRAM_ORDER=4  net=ConvNet word_indeces  acc=0.8668
NB_SAMPLES=6,000,000  NGRAM_ORDER=4  net=ConvNet word_indeces  acc=0.8629
NB_SAMPLES=8,000,000  NGRAM_ORDER=4  net=ConvNet word_indeces  acc=0.8833 
",keras||language model||nlp||vector model||vector space model||word embedding
178,      Текущие результаты для keras/theano MLP модели в эксперименте с word representations  ," Репозиторий эксперимента:  https://github.com/Koziev/WordRepresentations Сделал условный grid search для основных гиперпараметров. Для 2-грамм и 3-грамм эксперимент закончен, для 4-грамм продолжается: 
 NB_SAMPLES=1,000,000  NGRAM_ORDER=2  w2v_tags  acc=0.8340
NB_SAMPLES=2,000,000  NGRAM_ORDER=2  w2v_tags  acc=0.8405
NB_SAMPLES=3,000,000  NGRAM_ORDER=2  w2v_tags  acc=0.8474
NB_SAMPLES=5,000,000  NGRAM_ORDER=2  w2v_tags  acc=0.8511
NB_SAMPLES=10,000,000 NGRAM_ORDER= 2   w2v_tags  acc=0. 8561 

NB_SAMPLES=1,000,000  NGRAM_ORDER=2  word_indeces  acc=0.7452
NB_SAMPLES=2,000,000  NGRAM_ORDER=2  word_indeces  acc=0.7619
NB_SAMPLES=3,000,000  NGRAM_ORDER=2  word_indeces  acc=0.7735
NB_SAMPLES=5,000,000  NGRAM_ORDER=2  word_indeces  acc=0.7835
NB_SAMPLES=6,000,000  NGRAM_ORDER=2  word_indeces  acc=0.7849
NB_SAMPLES=10,000,000 NGRAM_ORDER=2  word_indeces  acc=0.8103

NB_SAMPLES=1,000,000  NGRAM_ORDER=2  w2v  acc=0.7954
NB_SAMPLES=2,000,000  NGRAM_ORDER=2  w2v  acc=0.8010
NB_SAMPLES=3,000,000  NGRAM_ORDER=2  w2v  acc=0.8050
NB_SAMPLES=5,000,000  NGRAM_ORDER=2  w2v  acc=0.8065
NB_SAMPLES=6,000,000  NGRAM_ORDER=2  w2v  acc=0.8086
NB_SAMPLES=10,000,000 NGRAM_ORDER=2  w2v  acc=0.8132



NB_SAMPLES=1,000,000  NGRAM_ORDER=3  w2v_tags  acc=0.8528
NB_SAMPLES=2,000,000  NGRAM_ORDER=3  w2v_tags  acc=0.8585
NB_SAMPLES=3,000,000  NGRAM_ORDER=3  w2v_tags  acc=0.8662
NB_SAMPLES=5,000,000  NGRAM_ORDER=3  w2v_tags  acc=0.8738
NB_SAMPLES=6,000,000  NGRAM_ORDER=3  w2v_tags  acc=0.8760
NB_SAMPLES=8,000,000  NGRAM_ORDER= 3   w2v_tags  acc= 0.8774 

                      
NB_SAMPLES=1,000,000  NGRAM_ORDER=3  word_indeces  acc=0.7719
NB_SAMPLES=2,000,000  NGRAM_ORDER=3  word_indeces  acc=0.7807
NB_SAMPLES=3,000,000  NGRAM_ORDER=3  word_indeces  acc=0.7875
NB_SAMPLES=5,000,000  NGRAM_ORDER=3  word_indeces  acc=0.8250
NB_SAMPLES=6,000,000  NGRAM_ORDER=3  word_indeces  acc=0.8266
NB_SAMPLES=8,000,000  NGRAM_ORDER=3  word_indeces  acc=0.8328

NB_SAMPLES=1,000,000  NGRAM_ORDER=3  w2v  acc=0.8116
NB_SAMPLES=2,000,000  NGRAM_ORDER=3  w2v  acc=0.8140
NB_SAMPLES=3,000,000  NGRAM_ORDER=3  w2v  acc=0.8191
NB_SAMPLES=5,000,000  NGRAM_ORDER=3  w2v  acc=0.8280
NB_SAMPLES=6,000,000  NGRAM_ORDER=3  w2v  acc=0.8275
NB_SAMPLES=8,000,000  NGRAM_ORDER=3  w2v  acc=0.8289

NB_SAMPLES=1,000,000  NGRAM_ORDER=4  w2v_tags  acc=0.8376
NB_SAMPLES=2,000,000  NGRAM_ORDER=4  w2v_tags  acc=0.8575
NB_SAMPLES=3,000,000  NGRAM_ORDER=4  w2v_tags  acc=0.8701
NB_SAMPLES=5,000,000  NGRAM_ORDER=4  w2v_tags  acc=0.8789
NB_SAMPLES=6,000,000  NGRAM_ORDER=4  w2v_tags  acc=0.8751
NB_SAMPLES=8,000,000  NGRAM_ORDER= 4   w2v_tags  acc= 0.8805 
 Пояснение по смыслу параметров w2v, w2v_tags и word_indeces, которые встречаются в таблице результатов. w2v  - для слов в n-грамме берем word2vector представления, полученные обучением отдельной gensim-модели по очень большому корпусу. w2v_tags  - в добавок к w2v представлений слов мы добавляем бинарные флаги, соответствующие разным морфологическим признакам слов. Например, для именительного падежа есть свой битовый фраг, для множественного числа - свой. word_indeces  - используется слой  Embedding , который в онлайне настраивает векторное представление слов. Уже на этих результатах видны две интересные тенденции. Во-первых, использование отдельно обученной w2v модели лучше, чем online настройка встраиваний через Embedding. По мере роста обучающей выборки качество онлайн-встраиваний растет и в какой-то момент бьет стороннюю w2v модель. Во-вторых, 3-граммы дают лучшее качестве, чем 2-граммы, а 4-граммы - лучше, чем 3-граммы. Это немного неожиданный результат.",N-граммы||language model||vector model||vector space model||word embedding||word2vec
179,      Выложил черновики для HackerEarth Machine Learning Challenge #3  , Черновики и модели для  HackerEarth Machine Learning Challenge #3  выложил в  репозиторий,#3||catboost||keras||lightgbm||python||xgboost||соревнования
180,      Установка CPU TensorFlow под Windows x64  ,"  Официальная сборочная инструкция  немного устарела, так как ссылается на Python 3.5, тогда как сейчас с Анакодной ставится Python 3.6. Указанная там ссылка на дистр для 3.5 не будет ставится в 3.6. 1) Нужна Анаконда с питоном 3.x. Если уже установлена, то обновляем анаконду до текущей версии с питоном 3.6: conda update --all 2) Проверяем версию питона: python --version 3) Создаем рабочий каталог для игр с TF, активируем его в консольном окне, затем создаем виртуальное окружение: conda create -n tensorflow python=3.6 activate tensorflow 4) Ставим собственно tensorflow: pip install --ignore-installed --upgrade  https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp36-cp36m-win_amd64.whl 5) Проверяем, что tf жив: 
 import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))
",python||tensorflow||windows||установка
181,"      Решение бинарной классификационной задачи на C++ с помощью Apache.SINGA, tiny-dnn и OpenNN  "," 1. Выложил в  репозиторий эксперимента  cеточные модели для бинарной классификации на C++ в Apache.SINGA, OpenNN и tiny-dnn: TinyDNN_Model.cpp  - решатель на базе MLP, реализованного средствами библиотеки tiny-dnn (C++, проект для VS 2015) alexnet.cc  - решатель на базе нейросетки, реализованной средствами Apache.SINGA (C++, проект для VS 2015) main.cpp  - решатель на базе нейросетки, реализованной средствами OpenNN (C++, проект для VS 2015) Постарался максимально подробно описать собственные впечатления от этих библиотек с позиции человека, впервые пытающегося применить их для решения реальной задачи:  https://habrahabr.ru/post/335838/",c++||deep learning||language model||machine learning||nlp||статья||текущие планы
182,      Локализаторы Microsoft - на страже чистоты русского языка  ," Именно в локализациях продуктов MS можно увидеть нормативную, а не жаргонную лексику:",забавные мелочи
183,      Планы для https://github.com/Koziev/WordRepresentations: Nervana NEON и CNTK  , Хочу попробовать добавить в зоопарк решателей задачи  https://github.com/Koziev/WordRepresentations : 1) сеточную модель на базе библиотеки Nervana Neon ( https://github.com/NervanaSystems/neon ) 2) сеточную модель на базе CNTK ( https://docs.microsoft.com/en-us/cognitive-toolkit/ ) - как минимум evaluation код на C#. 3) сеточную модель на базе tiny-dnn C++ ( https://github.com/tiny-dnn/tiny-dnn,nlp||текущие планы
184,      Оценка представления слов через hashing trick в задаче определения валидности 3-грамм  ," В развитие бенчмарка, описанного здесь:  http://kelijah.livejournal.com/217608.html Добавил еще один вариант представления слов - через one hot после hashing trick ( https://en.wikipedia.org/wiki/Feature_hashing ). В качестве готовой реализации взял класс hashdictionary из gensim:  https://radimrehurek.com/gensim/corpora/hashdictionary.html. Главный бонус этого способа заключается в том, что можно не составлять заранее весь список слов, чтобы присвоить им уникальные id. Вместо этого мы сознательно идем на возможные коллизии, но заранее определяем максимальное количество разных id. Если задать это количество меньше, чем реальный размер лексикона в анализируемом корпусе, то будут коллизии. В исходниках ( https://github.com/Koziev/WordRepresentations ) добавлен класс HashingTrick_Vectorizer. Его метод vectorize_dataset возвращает sparse матрицу для X в результате векторизации слов через  gensim.corpora.hashdictionary.HashDictio nary. Итоговые результаты для для набора 1,000,000 3-грамм получаются такие: word2vector - 0.80 brown clustering - 0.70 char 1hot encoding - 0.71 random bit vectors (доля единиц 16%) - 0.696 hashing trick with 32,000 slots - 0.64",hashing trick||machine learning||python||vector model||vector space model||исходники
185,      Интеграция TortoiseSVN с VisualStudio (мелкая полезняшка)  ," Оказывается, подцепить svn, точнее  гуй с черепашкой , в VisualStudio, весьма просто:  https://tortoisesvn.net/visualstudio.html Сделал себе кастомную команду для коммитов - отработало без проблем, теперь можно не лазать в проводник, если нужно закомитить единственный исходничек в проекте:",ссылки
186,"      Инструменты для Sentiment Analysis: Редактор Оценок, сверточная сеточная модель, база оценок  "," Закомитил в репозиторий  https://github.com/Koziev/SentimentAnalysis  все свои черновики, разработанные примерно год назад. 1.  Редактор Оценок  - десктопная прога на C# WinForms, работающая с текстами в БД SQLite. Позволяет быстро расставлять и редактировать оценки, а также выгружать корпус в текстовый формат (CSV с табуляцией в качестве разделителя полей). Выглядит как и положено прототипу под MVP: Несмотря на непритязательный UI/UX, вполне юзабелен и позволил быстро разметить достаточно большой корпус в 200,000 отзывов, чтобы проверить некоторые модели. Основная фишка программы - хранение отзывов в SQLite и динамическая подгрузка в виртуальный ListView по мере прокрутки экранного списка, а также транзакционное сохранение изменений. Так что должно без проблем масштабироваться на миллионы записей в корпусе. Отзывы размечаются на 3 категории: +, - и нейтральные. Кстати, даже на скриншоте виден примерный уровень литературности и каноничности русского языка в отзывах - это реальность, с которой приходится сталкиваться лемматизаторам и парсерам. ""Питание брали только завтраки"" - это хороший тест на владение common sence для ИИ. 2.  Сеточная модель на Keras  - простая сверточная нейросетка. Работает достаточно эффективно.",c||convolutional networks||keras||nlp||sentiment||sentiment analysis||sqlite
187,      Консольная утилитка на C# под Ubuntu  ," Для проверки работоспособности идеи использования C# в качестве дополнительного инструмента решения задач из области machine learning, когда требуется массовая обработка данных в явных циклах и нет возможности избежать их в программе на питоне, решил попробовать запустить простую программку под Убунтой. Исходник программы тут:  https://github.com/Koziev/HackerEarth/blob/master/3/models/csharp/CSharpTools/FindSimilar/Program.cs Она читает данные из двух CSV файлов, считает для записей в первом файле crc64-хэши и затем ищет во втором файле вхождения таких же записей. Данных очень много, более 12 миллионов записей в  тренировочном наборе , так что использование тут компилируемого языка (ну или штуки типа  cython ) явно просится. Disclaimer: прошу .net/c# работодателей не считать этот код кандидатом для кодеревью перед хантингом, ибо писался на скорую руку. В общем, после установки тулсета от Mono: sudo apt-get install mono-dmcs без проблем и допнастроек компильнул прожку: eek@ubuntu:~/polygon/HackerEarch/3/model s/csharp/CSharpTools/FindSimilar$ dmcs Program.cs warning CS8001: SDK path could not be resolved Program.cs(156,24): warning CS0219: The variable `header' is assigned but its value is never used Compilation succeeded - 2 warning(s) Затем она отработала как надо: eek@ubuntu:~/polygon/HackerEarch/3/model s/csharp/CSharpTools/FindSimilar$ ./Program.exe Loading data from /home/eek/polygon/HackerEarch/3/input/tr ain.csv... Done, 12137810 train samples, 12137785 unique crc64 hashes Reading test samples from /home/eek/polygon/HackerEarch/3/input/te st.csv 3706907 test samples, 0 has duplicates in train dataset Расширение .exe у исполняемого файла, как я понимаю, ставится для обратной совместимости с win-кодом. А вот воспользоваться хипстерским VSCode для отладки мне пока не удалось. Установил .NET Core: https://www.microsoft.com/net/core#linuxubuntu Затем скачал и установил VSCode: https://losst.ru/ustanovka-visual-code-i-net-core-1-0-ubuntu-16-04 Поставил там внутри расширение для C#, но отладчик не ожил, выдает странную ошибку. Архитекторов явно покусали js фанатики, я потратил некоторое время, чтобы понять где в этом редакторе можно понастраивать свойства проекта (а там руками json конфиги надо править). Так что прямо чтобы как с VisualStudio под винду - скачал, установил и начал дебажить, у меня пока не получилось.",.net||csharp||linux||python
188,      Соревнование от SAS - банковский скоринг кредитных заявок (бинарная классификация)  ," Страничка конкурса:  http://sascompetitions.ru/competitions/forecasting-the-probability-of-non-repayment-of-loan Конкурс появился и в списке текущих соревнований  http://mltrainings.ru/?filter=active . Описание задачи немного мутное, но вроде бы все сводится к бинарной классификации без особых заморочек. Важный нюанс, который я выяснил в первом пробном сабмите, заключается в правильном форматировании файла сабмита. Записи в нем должны быть СТРОГО в порядке возрастания ID, иначе при сабмите получается нулевая оценка без каких-либо пояснений. Тренировочный датасет содержит более миллиона сэмплов, так что можно поиграть с разными моделями. Я планирую попробовать стэкинг из  brew  и  mlxtend",соревнования
189,      Нерешительность как побочный эффект взаимодействия actor-critic в reinforcement learning  ," Модель буквально боиться сделать следующий лаг, покачиваясь в нерешительности:",machine learning||nips 2017||reinforcement learning
190,      Глубина и ширина стека для full-stack developer'а  ," В течение дня: 1.  Python  - проверил и засабмитил на  https://www.crowdai.org/challenges/nips-2017-learning-to-run  пару моделей, которые обсчитались ночью. Добил и причесал ООП в  коде для проверки word representations , вроде ничего так получилось. 2.  PL/SQL  - поправил пару вещей в своем пакете для оракловой БД. 3. Задеплоил и настроил свой же self-hosted рест-сервис для тестеров под виндой. 4.  C#  - изменил логику работу метода в cвоем REST-сервисе, чтобы пофиксить баг. 5.  Java",
191,      Сравнение разных способов представления слов для NLP задачи построения языковой модели  ," В  слаке ODS  недавно проскочила тема про варианты представления категориальных переменных для решающих деревьев. В частности, приводилась ссылка  https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931 . А я как раз хотел еще раз поднять тему с использованием  Brown Clustering  представлений слов для NLP. Вот и получилось совместить оба вопроса в одном бенчмарке - см. далее подробности. Модельная задача Для заданной N-граммы нужно определить, допустима ли она в тексте на русском языке. Например, "" идти по воду "" - допустимо, а "" идти при воду "" - нет. Вообще говоря, есть хорошие и эффективные методы решения такой задачи, выдающие не просто бинарный ответ 1/0, а действительную оценку словосочетаний, например  KenLM . Так что нижеописанное является упрощением, чтобы бенчмарк был простым и понятным, а также легко расширялся для оценки новых способов представления слов при необходимости. Для бенчмарка главное удобство состоит в том, что мы можем генерировать датасет очень большого размера в полностью автоматическом режиме. Достаточно иметь более-менее чистый корпус текстов. Программная реализация бенчмарка  подразумевает, что текстовый корпус представлен plain text файлом в utf-8, в котором каждая строка содержит одно предложение. Слова должны быть разделены пробелами, знаки пунктуации удалены. Примерно вот так: рязанцы начали готовиться к битве однако вряд ли москвичи вперед пойдут возможность выбраться из такой ж послышались соленые прибаутки полковых зубоскалов а сани разметали и подожгли он снова повернулся к пешцам князь поднял глаза и застыл началось избиение началась паника у федора получилось удачней всех москвичи быстро отстали и вернулись кто нас так сегодня облапошил не мечом воюет головой если б ты не подошел помирать буду что вспомню Из корпуса читаются N-граммы заданного порядка (см. переменная NGRAM_ORDER). Так получается половина датасета, помечаемая как y=1. Вторая половина датасета с y=0 получается так. Берем N-грамму из первой половины и заменяем любое одно слово на произвольное слово. Если получившаяся N-грамма отсутствует в первой половине, то получившийся  негативный сэмпл  добавляем в датасет с y=0. Проверяемые варианты представления слова. Во всех случаях N-грамма представляется как результат ""склеивания"" представлений входящих в нее слов. 1) Векторизация с помощью word2vector модели - класс W2V_Vectorizer Для варианта w2v просто берутся векторы слов из заранее подготовленной word2vector модели. Для бенчмарка я взял модель с dim=32, win=5 и cbow=1. 2) Случайная векторизация - класс BinaryWord_Vectorizer Для варианта random_bitvector каждому слову приписывается случайный битовый вектор длиной 128, в котором случайно выставлено 16 единиц при остальных нулях. Самая бестолковая кодировка слов, поскольку случайные векторы абсолютно не отражают никаких свойств слов - ни семантику, ни морфологию, ни частотый рейтинг, ни даже character surface. Этот вариант взят для контраста с остальными более ""умными"" методами. По идее он не должен работать вообще, так как предполагает просто, что деревья просто запомнят коды слов в каком-то объеме. Но он работает и не так уж плохо. 3) Использование результатов Brown Clustering - класс BrownClusters_Vectorizer Используются результаты  кластеризации  корпуса с помощью  https://github.com/percyliang/brown-cluster . Вектор каждого слова берется из файла paths в результатах работы утилиты wcluster. Битовые векторы каждого слова дополняются справа пустыми значениями до одинаковой длины. Пустые разряды остаются незаполненными в генерируемой sparse матрице. Пример файла paths: 111101    служебном    4 111101    блистерном    4 111101    запечатанных    4 111101    родном    5 111101    женском    5 111101    общественном    5 111101    дилерском    5 111101    дорогом    6 111101    профессиональном    7 111101    старом    8 111101    прогулочном    8 111101    продуктовом    8 Я использовал 1000 кластеров. Очень быстрое замедление алгоритма при увеличении размера корпуса и числа классов делают метод не очень удобным, но в качестве альтернативы word2vector он все-таки интересен. 4) Склеивание 1-hot encoding для символов слова - класс Chars_Vectorizer Каждый символ, встречающийся в словаре, получает 1-hot представление. Векторы символов склеиваются в один длинный sparse вектор слова. В результате получается очень разряженная матрица. Слова при векторизации разворачиваем, чтобы последние символы всегда находились в начале. Это позволяет деревьям видеть русские флексии в фиксированных столбцах матрицы. Классификатор В качестве классификатора взят XGBoost с max_depth=6. Сгенерированный датасет (миллион записей) бьется на три примерно равные части. На первой части классификатор учится (training), используя вторую часть для определения момента достаточности набора деревьев (validation). Третья часть (holdout) используется для рассчета финальной точности бинарной классификации. Результаты Точность определения класса 3-граммы (возможна/невозможна) при обучении на 300,000 сэмплах. word2vector - 0.80 brown clustering - 0.70 char 1hot encoding - 0.71 random bit vectors (доля единиц 16%) - 0.696 Исходный текст бенчмарка Код на питоне лежит тут:  https://github.com/Koziev/WordRepresentations",language model||python||vector model||vector space model||xgboost
192,      Pentaho Data Integration: первое краткое знакомство  ," Ссылка:  http://www.pentaho.com/product/data-integration Краткое описание Kettle (дизайнер трансформаций и заданий):  http://wiki.pentaho.com/display/EAI/Pentaho+Data+Integration+(Kettle)+Tutorial Что это такое Потратил 2 дня на знакомство с этой замечательной системой обработки данных, точнее с той ее частью, которая отвечает за  ETL . ETL - это сокращение от  Extract Transform Load , то есть загрузка данных, их преобразование и сохранение в новом формате. Для человека, имеющего опыт работы и разработки под MS Access, Pentaho Data Integration выглядит именно как Access на стероидах. или на  анаболиках - система немного монструозна. Объяснение простое - она написана на Java. Что сразу очерчивает некоторые рамки аппетита к ресурсам. В частности, в виртуалке под vSphere с Windows 2008 с квотой в 2 Гб памяти графический дизайнер грузится неторопливо и работает достаточно размеренно, хотя явного дискомфорта не вызывает. Разве что отдельные нюансы самого гуя напоминают лишний раз, что это GUI на джаве - явно не нативное поведение окон и контролов. Фильтрация шагов по введенному названию вызывает неспешные перерисовки списка после ввода каждого символа, и для ""REST client"" можно наблюдать полуминутную мультипликацию с морганием палитры инструментов. Впрочем, мелочи. Решаемая PDI задача, если отбросить технические нюансы, проста и понятна. Есть разные источники данных, в том числе реляционные СУБД, веб-сервисы, простые текстовые файлы в формате CSV и так далее. Там есть ценные данные, которые нужны бизнесу для планирования тактики и стратегии. Чем больше бизнес, тем больше разнородных данных. Аналитика по этим разнородным источникам сводится к повторению одних и тех же шагов: прочитать (точнее, периодически перечитывать) данные из (1C, csv файла, пришедшего из филиала, из Excel документа из департамента стратегического планирования и т.д.), выделить из них подмножество (берем столбцы дата и стоимость акций MSFT, игнорируем остальное), соединяем с выдачей веб-сервиса, который анализирует сентимент IT-новостей в спектре центральных СМИ, джойним, сохраняем в другом месте - пусть это будет какой-нибудь JSON документ в MongoDB. Потом мы эти данные прогоним через регрессионную machine learning модель (см. Weka  http://wiki.pentaho.com/display/EAI/Weka+Forecasting ), наконец нарисуем красивый репорт (опять там же  https://www.profdata.com/reporting/ ) с рекомендациями - вставать в длинную и как много. Ну или типа того. Плюсы (*) Написано на Java, поэтому кроссплатформенно, если повезет с JRE, конечно. У меня со второго захода получилось установить нужную оракловую JRE и стартовать Kettle. (*) Для софтверной компании, разрабатывающей коробочный продукт для enterprise сегмента, Pentaho DI однозначно суперская вещь с точки зрения маркетинга. На некоторых частях документации концентрация баззводов и наименований модных решений соперничает с английскими артиклями. К примеру, раздел по Master DataManegement ( http://wiki.pentaho.com/display/EAI/Master+Data+Management-Concepts ) перечисляет все основные приемы - Data Quality, Data Cleansing, Validation, Harmonization, Standardization, Data Consolidation (Deduplication, Enrichment). Загрузить данные из веб-сервиса? Почти без проблем. Правда, я не смог подцепить свой SOAP веб-сервис, пентаха ругнулась на некое несоответствие формата в xml-оформлении конверта. С REST-сервисом все пошло веслее. (*) Широчайшая поддержка различных РСУБД в качестве источников данных и вариантов сохранения результатов. По-моему, больше чем в MS Access или SSIS. Интеграция с всевозможными NoSQL базами, есть SAP HANA и вся классика типа Oracle и MS SQL. Даже крошка SQLite присутствует. Я сходу сделал сохранение данных в SQLite и оно заработало без каких либо шероховатостей. Потом небольшая пляска со скачиваем Oracle JDBC драйвера и установкой его в нужном каталоге - удалось прочитать данные из оракловой таблицы. Хотя тут был первый неприятный опыт, так как кириллица в varchar2 полях пришла поломанная. То есть настройка локалей где-то на пути требует заботливых рук ветеринара. (*) Возможность цеплять SOAP и REST-сервисы. (*) Графический дизайнер для редактирования трансформаций и заданий - это, конечно, плюс для использования PDI не-разработчиками. (*) Графические программы (трансформации и заданий) сохраняются в XML формате и могут быть, таким образом, созданы и загружены через rest-api сторонними компонентами. (*) Интеграция с другими компонентами Pentaho, хотя я их не успел попробовать. Отчеты и анализ данных - это хорошо и всегда полезно в реальных бизнес-задачах. Минусы (*) Все написано на Java. Поэтому прожорливо и неповоротливо. Когда стартует  Carte  (сервис, предоставляющий rest-api для создания/запуска/мониторинга трансформаций и заданий), в логе видно, как он инициализирует кучку всяких приблуд - кэши, вспомогательные библиотеки. Выглядит монструозно. (*) Немного ненативный GUI. Хотя надо сказать, что эта ненативность гораздо нативнее, чем, к примеру, в PyCharm, который меня своими файловыми диалогами иногда ставит в тупик. (*) Конфигурирование java-style, через xml-конфиги. Лично мне это всегда доставляет боль, так как неимоверное время тратится, чтобы нагуглить и подобрать, какие параметры в каких конфигах надо выставить в волшебные значения, чтобы все завелось. Например, правильный конфиг для Carte, чтобы сервис увидел репозиторий с готовыми трансформациями, у меня получилось сделать не сразу, а через пару часов гугления и экспериментов. (*) Это графический язык программирования со всеми вытекающими. Чтобы понять, какой визуальный кирпичик надо подпихнуть и как его настроить для выполнения элементарного действия, приходится гуглить, зырить видюшки на ютубе, в общем чуствовать себя полным буратиной. Возможно, по мере набора компетенции этот фактор станет меньше, но по началу просто часы уходят на то, что в питоне делается за 10 минут. Спустя день мне удалось выстроить трансформацию, в которой данные загружаются из моего rest-сервиса в json-формате, немного модифицируются, затем запихиваются в другой rest-сервис. (*) Документация (вики) крайне скудна. Местами это просто скриншоты диалоговых окошек с перечислением подписей к контролам, то есть абсолютно бесполезная штука. (*) В документации говорится, что можно использовать Python для написания специальных трансформаций. У меня не получилось даже понять, как это сделать. Никаких следов переключения с JavaScript на другие ЯП в кирпичике SCRIPT найти не удалось. Нашел некий плагин, который должен добавить поддержку Jython. Скачал его с гитхаба, запустил сборку в java-системе сборки, после 10 минут скачивания зависимостей и  сборки эта редиска ругнулась ""Fatal error in java compiler"" и все. Представив, как этот процесс делать у клиентов удаленно с ограниченным доступом в инет, я решил что это плохой путь. (*) Редактор js-скриптов в трансформациях мягко говоря убог. Нет, конечно я могу писать без поддержки IDE, и иногда редактирую программы на питоне просто в Notepad++. Но в графическом дизайнере хотелось бы большей поддержки для js. За рамками исследованного Остались некотрые вещи, которые я просто увидел в документации, но не смог потрогать вживую. Во-первых, интеграция с различными системами доставки сообщений. Вроде бы есть встроенная интеграция с Java Message Service, но только в платной enterprise-версии. Есть некие плагины для интеграции с Apache Kafka, но как это все использовать - надо разбираться. Во-вторых, как обеспечивается гарантированная обработка данных в случае технической аварии на исполняющем хосте. Попросту, можно ли возобновить трансформацию, если произошел фатальный сбой на промежуточном шаге (oom к примеру).",
193,      NIPS 2017: Learning to Run: улучшенная модель  ," Подготовил новую модель для соревнования "" NIPS 2017: Learning to Run (Reinforcement learning environments with musculoskeletal models) "", организатором которого является Stanford Neuromuscular Biomechanics Laboratory:",deep learning||machine learning||nips||reinforcement learning||роботы||соревнования
194,      NIPS 2017: Learning to Run - сделал первый сабмит  , Засабмитил  своего киборга  сюда  https://www.crowdai.org/challenges/nips-2017-learning-to-run/leaderboards,deep learning||keras||keras-rl||machine learning||nips||python||reinforcement learning||роботы
195,       NIPS 2017: Learning to Run: первый полный шаг модели  , ,reinforcement learning
196,      Киборг учится держать равновесие (парочка видео)  ,"  В рамках задачи  NIPS 2017: Learning to Run  разбираюсь с reinforcement learning. Суть задачи — кинематическая модель человеческого тела (скелет+мускулы нижней части) должна пройти как можно дальше. Вектор состояния, которое видит ML модель, содержит геолокацию и скорости основных частей тела. Действия модели — градуальная активация двух десятков мышц в нижней части тела. Разумеется, хардкодить кинематику движений нельзя, да и не интересно. То есть подход из первого квейка с 3d оцифровкой моделей не годится. Требуется, чтобы модель выбирала активацию мускулов (силу и оркестрацию, так сказать) для максимизации финальной награды, которая зависит от пройденного расстояния и перенапряжения соединительных тканей в суставах. Вот так ведет себя киборг с полностью необученной моделью: То есть случайный процесс активации мышц ( https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process ) никак не препятствует потере равновесия. Активные мускулы рендерятся красненьким, расслабленные - синенькие. Шмяк. А вот что получается, если начинаем штрафовать модель за отклонение головы назад: Киборг отвел одну ногу назад, вторая хочет сделать большой шаг вперед.",reinforcement learning
